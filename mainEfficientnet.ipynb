{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.metrics.functional import classification\n",
    "\n",
    "import cv2\n",
    "import geffnet\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial import ConvexHull\n",
    "import inspect\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#model save\n",
    "import pickle\n",
    "from pickle import dump, load\n",
    "\n",
    "import tidalUtl.PrpUtl as prp\n",
    "import tidalUtl.EdaUtl as eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/tidalryoku/new-baseline-pytorch-moa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ver1__<br>\n",
    "baseline：CV:0.01465 LB:0.01874<br>\n",
    "__ver2__<br>\n",
    "Hyperopt, 2Layer：CV:0.01460 LB:0.01869<br>\n",
    "__ver3__<br>\n",
    "3Layer：CV:0.01464 LB:0.01868<br>\n",
    "__ver4__<br>\n",
    "MLSMOTE baseline：CV:0.01476 LB:0.01978<br>\n",
    "__ver5__<br>\n",
    "2Layer,refactoring：CV:0.01476 LB:0.01869<br>\n",
    "__ver6__<br>\n",
    "rankGauss：CV:0.01456 LB:0.01865<br>\n",
    "__ver7__<br>\n",
    "labelSmoothing：CV:0.01502 LB:0.01859<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"/home/tidal/ML_Data/MoA/lish-moa\"\n",
    "OUTPUT = \"/home/tidal/ML_Data/MoA/output\"\n",
    "#INPUT = \"/Users/hfuis/ML_Data/MoA/lish-moa\"\n",
    "#OUTPUT = \"/Users/hfuis/ML_Data/MoA/output\"\n",
    "\n",
    "SUBMIT = OUTPUT + \"/submittion/\"\n",
    "SAVEMODEL = OUTPUT + \"/model/Pytorch/\"\n",
    "SAVEOOF = OUTPUT + \"/OOF/Pytorch/\"\n",
    "SAVEDEEPINSIGHT = OUTPUT + \"/DeepInsightModel/\"\n",
    "SAVELOGSCALE = OUTPUT + \"/LogScaler/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading\n",
    "trainFeature = pd.read_csv(INPUT + '/train_features.csv')\n",
    "testFeature = pd.read_csv(INPUT + '/test_features.csv')\n",
    "trainTargetScored = pd.read_csv(INPUT + '/train_targets_scored.csv')\n",
    "sample_submission = pd.read_csv(INPUT + '/sample_submission.csv')\n",
    "drug = pd.read_csv(INPUT + '/train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in trainFeature.columns if col.startswith('g-')] #gから始まる列名のセット\n",
    "CELLS = [col for col in trainFeature.columns if col.startswith('c-')] #cから始まる列名のセット\n",
    "category_features = [\"cp_type\", \"cp_dose\"]\n",
    "numeric_features = [c for c in trainFeature.columns if c != \"sig_id\" and c not in category_features]\n",
    "all_features = category_features + numeric_features\n",
    "\n",
    "#efficientnet\n",
    "model_type = \"b3\"\n",
    "pretrained_model = f\"tf_efficientnet_{model_type}_ns\"\n",
    "#experiment_name = f\"deepinsight_efficientnet_v4_{model_type}\"\n",
    "num_workers = 2\n",
    "gpus = [0]\n",
    "\n",
    "if model_type == \"b0\":\n",
    "    batch_size = 128\n",
    "    infer_batch_size = 256\n",
    "    image_size = 224  # B0\n",
    "    drop_rate = 0.2  # B0\n",
    "    resolution = 224\n",
    "elif model_type == \"b3\":\n",
    "    batch_size = 48\n",
    "    infer_batch_size = 512\n",
    "    image_size = 300  # B3\n",
    "    drop_rate = 0.3  # B3\n",
    "    resolution = 300\n",
    "elif model_type == \"b5\":\n",
    "    batch_size = 8\n",
    "    infer_batch_size = 16\n",
    "    image_size = 456  # B5\n",
    "    drop_rate = 0.4  # B5\n",
    "    resolution = 456\n",
    "elif model_type == \"b7\":\n",
    "    batch_size = 2\n",
    "    infer_batch_size = 4\n",
    "    # image_size = 800  # B7\n",
    "    image_size = 772  # B7\n",
    "    drop_rate = 0.5  # B7\n",
    "    resolution = 772\n",
    "    \n",
    "# DeepInsight Transform\n",
    "perplexity = 5\n",
    "\n",
    "drop_connect_rate = 0.2\n",
    "fc_size = 512\n",
    "\n",
    "# Swap Noise\n",
    "swap_prob = 0.15\n",
    "swap_portion = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed固定\n",
    "def seed_everything(seed=42):\n",
    "    #data取得についてのランダム性固定\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #cudnnによる演算の安定化(評価値の安定)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter\n",
    "param_space = {'hidden_size1': 512, \n",
    "               'hidden_size2': 512, \n",
    "               'dropOutRate1': 0.20393004966355735, \n",
    "               'dropOutRate2': 0.39170486751620137,\n",
    "               'rankGauss_n_quantiles': 488.0393350201078,\n",
    "               'leakyReluSlope': 0.01973893854348531,\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFeatureEnc(trainFeature, testFeature):\n",
    "    train = trainFeature.copy()\n",
    "    test = testFeature.copy()\n",
    "    for df in [train, test]:\n",
    "        df['cp_type'] = df['cp_type'].map({'ctl_vehicle': 0, 'trt_cp': 1})\n",
    "        df['cp_dose'] = df['cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "        df['cp_time'] = df['cp_time'].map({24: 0, 48: 0.5, 72: 1})\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from DeepInsight Transform\n",
    "# https://github.com/alok-ai-lab/DeepInsight/blob/master/pyDeepInsight/image_transformer.py\n",
    "\n",
    "\n",
    "class LogScaler:\n",
    "    \"\"\"Log normalize and scale data\n",
    "\n",
    "    Log normalization and scaling procedure as described as norm-2 in the\n",
    "    DeepInsight paper supplementary information.\n",
    "    \n",
    "    Note: The dimensions of input matrix is (N samples, d features)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._min0 = None\n",
    "        self._max = None\n",
    "\n",
    "    \"\"\"\n",
    "    Use this as a preprocessing step in inference mode.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        # Min. of training set per feature\n",
    "        self._min0 = X.min(axis=0)\n",
    "\n",
    "        # Log normalized X by log(X + _min0 + 1)\n",
    "        X_norm = np.log(\n",
    "            X +\n",
    "            np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n",
    "            1).clip(min=0, max=None)\n",
    "\n",
    "        # Global max. of training set from X_norm\n",
    "        self._max = X_norm.max()\n",
    "\n",
    "    \"\"\"\n",
    "    For training set only.\n",
    "    \"\"\"\n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Min. of training set per feature\n",
    "        self._min0 = X.min(axis=0)\n",
    "\n",
    "        # Log normalized X by log(X + _min0 + 1)\n",
    "        X_norm = np.log(\n",
    "            X +\n",
    "            np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n",
    "            1).clip(min=0, max=None)\n",
    "\n",
    "        # Global max. of training set from X_norm\n",
    "        self._max = X_norm.max()\n",
    "\n",
    "        # Normalized again by global max. of training set\n",
    "        return (X_norm / self._max).clip(0, 1)\n",
    "\n",
    "    \"\"\"\n",
    "    For validation and test set only.\n",
    "    \"\"\"\n",
    "    def transform(self, X, y=None):\n",
    "        # Adjust min. of each feature of X by _min0\n",
    "        for i in range(X.shape[1]):\n",
    "            X[:, i] = X[:, i].clip(min=self._min0[i], max=None)\n",
    "\n",
    "        # Log normalized X by log(X + _min0 + 1)\n",
    "        X_norm = np.log(\n",
    "            X +\n",
    "            np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n",
    "            1).clip(min=0, max=None)\n",
    "\n",
    "        # Normalized again by global max. of training set\n",
    "        return (X_norm / self._max).clip(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepInsight Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テーブルデータをCNN用の画像に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from DeepInsight Transform\n",
    "# https://github.com/alok-ai-lab/DeepInsight/blob/master/pyDeepInsight/image_transformer.py\n",
    "\n",
    "#詳細な説明は以下\n",
    "# https://www.kaggle.com/markpeng/deepinsight-transforming-non-image-data-to-images\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib import pyplot as plt\n",
    "import inspect\n",
    "\n",
    "\n",
    "class DeepInsightTransformer:\n",
    "    \"\"\"Transform features to an image matrix using dimensionality reduction\n",
    "\n",
    "    This class takes in data normalized between 0 and 1 and converts it to a\n",
    "    CNN compatible 'image' matrix\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 feature_extractor='tsne',\n",
    "                 perplexity=30,\n",
    "                 pixels=100,\n",
    "                 random_state=None,\n",
    "                 n_jobs=None):\n",
    "        \"\"\"Generate an ImageTransformer instance\n",
    "\n",
    "        Args:\n",
    "            feature_extractor: string of value ('tsne', 'pca', 'kpca') or a\n",
    "                class instance with method `fit_transform` that returns a\n",
    "                2-dimensional array of extracted features.\n",
    "            pixels: int (square matrix) or tuple of ints (height, width) that\n",
    "                defines the size of the image matrix.\n",
    "            random_state: int or RandomState. Determines the random number\n",
    "                generator, if present, of a string defined feature_extractor.\n",
    "            n_jobs: The number of parallel jobs to run for a string defined\n",
    "                feature_extractor.\n",
    "        \"\"\"\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        if isinstance(feature_extractor, str):\n",
    "            fe = feature_extractor.casefold()\n",
    "            if fe == 'tsne_exact'.casefold():\n",
    "                fe = TSNE(n_components=2,\n",
    "                          metric='cosine',\n",
    "                          perplexity=perplexity,\n",
    "                          n_iter=1000,\n",
    "                          method='exact',\n",
    "                          random_state=self.random_state,\n",
    "                          n_jobs=self.n_jobs)\n",
    "            elif fe == 'tsne'.casefold():\n",
    "                fe = TSNE(n_components=2,\n",
    "                          metric='cosine',\n",
    "                          perplexity=perplexity,\n",
    "                          n_iter=1000,\n",
    "                          method='barnes_hut',\n",
    "                          random_state=self.random_state,\n",
    "                          n_jobs=self.n_jobs)\n",
    "            elif fe == 'pca'.casefold():\n",
    "                fe = PCA(n_components=2, random_state=self.random_state)\n",
    "            elif fe == 'kpca'.casefold():\n",
    "                fe = KernelPCA(n_components=2,\n",
    "                               kernel='rbf',\n",
    "                               random_state=self.random_state,\n",
    "                               n_jobs=self.n_jobs)\n",
    "            else:\n",
    "                raise ValueError((\"Feature extraction method '{}' not accepted\"\n",
    "                                  ).format(feature_extractor))\n",
    "            self._fe = fe\n",
    "        elif hasattr(feature_extractor, 'fit_transform') and \\\n",
    "                inspect.ismethod(feature_extractor.fit_transform):\n",
    "            self._fe = feature_extractor\n",
    "        else:\n",
    "            raise TypeError('Parameter feature_extractor is not a '\n",
    "                            'string nor has method \"fit_transform\"')\n",
    "\n",
    "        if isinstance(pixels, int):\n",
    "            pixels = (pixels, pixels)\n",
    "\n",
    "        # The resolution of transformed image\n",
    "        self._pixels = pixels\n",
    "        self._xrot = None\n",
    "\n",
    "    def fit(self, X, y=None, plot=False):\n",
    "        \"\"\"Train the image transformer from the training set (X)\n",
    "\n",
    "        Args:\n",
    "            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            y: Ignored. Present for continuity with scikit-learn\n",
    "            plot: boolean of whether to produce a scatter plot showing the\n",
    "                feature reduction, hull points, and minimum bounding rectangle\n",
    "\n",
    "        Returns:\n",
    "            self: object\n",
    "        \"\"\"\n",
    "        # Transpose to get (n_features, n_samples)\n",
    "        X = X.T\n",
    "\n",
    "        # Perform dimensionality reduction\n",
    "        x_new = self._fe.fit_transform(X)\n",
    "\n",
    "        # Get the convex hull for the points\n",
    "        chvertices = ConvexHull(x_new).vertices\n",
    "        hull_points = x_new[chvertices]\n",
    "\n",
    "        # Determine the minimum bounding rectangle\n",
    "        mbr, mbr_rot = self._minimum_bounding_rectangle(hull_points)\n",
    "\n",
    "        # Rotate the matrix\n",
    "        # Save the rotated matrix in case user wants to change the pixel size\n",
    "        self._xrot = np.dot(mbr_rot, x_new.T).T\n",
    "\n",
    "        # Determine feature coordinates based on pixel dimension\n",
    "        self._calculate_coords()\n",
    "\n",
    "        # plot rotation diagram if requested\n",
    "        if plot is True:\n",
    "            # Create subplots\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 7), squeeze=False)\n",
    "            ax[0, 0].scatter(x_new[:, 0],\n",
    "                             x_new[:, 1],\n",
    "                             cmap=plt.cm.get_cmap(\"jet\", 10),\n",
    "                             marker=\"x\",\n",
    "                             alpha=1.0)\n",
    "            ax[0, 0].fill(x_new[chvertices, 0],\n",
    "                          x_new[chvertices, 1],\n",
    "                          edgecolor='r',\n",
    "                          fill=False)\n",
    "            ax[0, 0].fill(mbr[:, 0], mbr[:, 1], edgecolor='g', fill=False)\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            plt.show()\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def pixels(self):\n",
    "        \"\"\"The image matrix dimensions\n",
    "\n",
    "        Returns:\n",
    "            tuple: the image matrix dimensions (height, width)\n",
    "\n",
    "        \"\"\"\n",
    "        return self._pixels\n",
    "\n",
    "    @pixels.setter\n",
    "    def pixels(self, pixels):\n",
    "        \"\"\"Set the image matrix dimension\n",
    "\n",
    "        Args:\n",
    "            pixels: int or tuple with the dimensions (height, width)\n",
    "            of the image matrix\n",
    "\n",
    "        \"\"\"\n",
    "        if isinstance(pixels, int):\n",
    "            pixels = (pixels, pixels)\n",
    "        self._pixels = pixels\n",
    "        # recalculate coordinates if already fit\n",
    "        if hasattr(self, '_coords'):\n",
    "            self._calculate_coords()\n",
    "\n",
    "    def _calculate_coords(self):\n",
    "        \"\"\"Calculate the matrix coordinates of each feature based on the\n",
    "        pixel dimensions.\n",
    "        \"\"\"\n",
    "        ax0_coord = np.digitize(self._xrot[:, 0],\n",
    "                                bins=np.linspace(min(self._xrot[:, 0]),\n",
    "                                                 max(self._xrot[:, 0]),\n",
    "                                                 self._pixels[0])) - 1\n",
    "        ax1_coord = np.digitize(self._xrot[:, 1],\n",
    "                                bins=np.linspace(min(self._xrot[:, 1]),\n",
    "                                                 max(self._xrot[:, 1]),\n",
    "                                                 self._pixels[1])) - 1\n",
    "        self._coords = np.stack((ax0_coord, ax1_coord))\n",
    "\n",
    "    def transform(self, X, empty_value=0):\n",
    "        \"\"\"Transform the input matrix into image matrices\n",
    "\n",
    "        Args:\n",
    "            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "                where n_features matches the training set.\n",
    "            empty_value: numeric value to fill elements where no features are\n",
    "                mapped. Default = 0 (although it was 1 in the paper).\n",
    "\n",
    "        Returns:\n",
    "            A list of n_samples numpy matrices of dimensions set by\n",
    "            the pixel parameter\n",
    "        \"\"\"\n",
    "\n",
    "        # Group by location (x1, y1) of each feature\n",
    "        # Tranpose to get (n_features, n_samples)\n",
    "        img_coords = pd.DataFrame(np.vstack(\n",
    "            (self._coords, X.clip(0, 1))).T).groupby(\n",
    "                [0, 1],  # (x1, y1)\n",
    "                as_index=False).mean()\n",
    "\n",
    "        img_matrices = []\n",
    "        blank_mat = np.zeros(self._pixels)\n",
    "        if empty_value != 0:\n",
    "            blank_mat[:] = empty_value\n",
    "        for z in range(2, img_coords.shape[1]):\n",
    "            img_matrix = blank_mat.copy()\n",
    "            img_matrix[img_coords[0].astype(int),\n",
    "                       img_coords[1].astype(int)] = img_coords[z]\n",
    "            img_matrices.append(img_matrix)\n",
    "\n",
    "        return img_matrices\n",
    "\n",
    "    def fit_transform(self, X, empty_value=0):\n",
    "        \"\"\"Train the image transformer from the training set (X) and return\n",
    "        the transformed data.\n",
    "\n",
    "        Args:\n",
    "            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            empty_value: numeric value to fill elements where no features are\n",
    "                mapped. Default = 0 (although it was 1 in the paper).\n",
    "\n",
    "        Returns:\n",
    "            A list of n_samples numpy matrices of dimensions set by\n",
    "            the pixel parameter\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X, empty_value=empty_value)\n",
    "\n",
    "    def feature_density_matrix(self):\n",
    "        \"\"\"Generate image matrix with feature counts per pixel\n",
    "\n",
    "        Returns:\n",
    "            img_matrix (ndarray): matrix with feature counts per pixel\n",
    "        \"\"\"\n",
    "        fdmat = np.zeros(self._pixels)\n",
    "        # Group by location (x1, y1) of each feature\n",
    "        # Tranpose to get (n_features, n_samples)\n",
    "        coord_cnt = (\n",
    "            pd.DataFrame(self._coords.T).assign(count=1).groupby(\n",
    "                [0, 1],  # (x1, y1)\n",
    "                as_index=False).count())\n",
    "        fdmat[coord_cnt[0].astype(int),\n",
    "              coord_cnt[1].astype(int)] = coord_cnt['count']\n",
    "        return fdmat\n",
    "\n",
    "    @staticmethod\n",
    "    def _minimum_bounding_rectangle(hull_points):\n",
    "        \"\"\"Find the smallest bounding rectangle for a set of points.\n",
    "\n",
    "        Modified from JesseBuesking at https://stackoverflow.com/a/33619018\n",
    "        Returns a set of points representing the corners of the bounding box.\n",
    "\n",
    "        Args:\n",
    "            hull_points : an nx2 matrix of hull coordinates\n",
    "\n",
    "        Returns:\n",
    "            (tuple): tuple containing\n",
    "                coords (ndarray): coordinates of the corners of the rectangle\n",
    "                rotmat (ndarray): rotation matrix to align edges of rectangle\n",
    "                    to x and y\n",
    "        \"\"\"\n",
    "\n",
    "        pi2 = np.pi / 2.\n",
    "\n",
    "        # Calculate edge angles\n",
    "        edges = hull_points[1:] - hull_points[:-1]\n",
    "        angles = np.arctan2(edges[:, 1], edges[:, 0])\n",
    "        angles = np.abs(np.mod(angles, pi2))\n",
    "        angles = np.unique(angles)\n",
    "\n",
    "        # Find rotation matrices\n",
    "        rotations = np.vstack([\n",
    "            np.cos(angles),\n",
    "            np.cos(angles - pi2),\n",
    "            np.cos(angles + pi2),\n",
    "            np.cos(angles)\n",
    "        ]).T\n",
    "        rotations = rotations.reshape((-1, 2, 2))\n",
    "\n",
    "        # Apply rotations to the hull\n",
    "        rot_points = np.dot(rotations, hull_points.T)\n",
    "\n",
    "        # Find the bounding points\n",
    "        min_x = np.nanmin(rot_points[:, 0], axis=1)\n",
    "        max_x = np.nanmax(rot_points[:, 0], axis=1)\n",
    "        min_y = np.nanmin(rot_points[:, 1], axis=1)\n",
    "        max_y = np.nanmax(rot_points[:, 1], axis=1)\n",
    "\n",
    "        # Find the box with the best area\n",
    "        areas = (max_x - min_x) * (max_y - min_y)\n",
    "        best_idx = np.argmin(areas)\n",
    "\n",
    "        # Return the best box\n",
    "        x1 = max_x[best_idx]\n",
    "        x2 = min_x[best_idx]\n",
    "        y1 = max_y[best_idx]\n",
    "        y2 = min_y[best_idx]\n",
    "        rotmat = rotations[best_idx]\n",
    "\n",
    "        # Generate coordinates\n",
    "        coords = np.zeros((4, 2))\n",
    "        coords[0] = np.dot([x1, y2], rotmat)\n",
    "        coords[1] = np.dot([x2, y2], rotmat)\n",
    "        coords[2] = np.dot([x2, y1], rotmat)\n",
    "        coords[3] = np.dot([x1, y1], rotmat)\n",
    "\n",
    "        return coords, rotmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train,testにターゲット値も連結__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collecting(trainFeature, testFeature, trainTargetScored):\n",
    "    #Pkey(sig_id)でfeatureとtargetを内部結合。\n",
    "    train = trainFeature.merge(trainTargetScored, on='sig_id')\n",
    "    test = testFeature.merge(sample_submission, on='sig_id')\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(param, trainFeature, testFeature, trainTargetScored):\n",
    "    \n",
    "    train, test = categoryFeatureEnc(trainFeature, testFeature)\n",
    "    \n",
    "    train, test = Collecting(train, test, trainTargetScored)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 93.6 ms, sys: 8.09 ms, total: 102 ms\n",
      "Wall time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainVsl, testVsl = preprocessing(param_space, trainFeature, testFeature, trainTargetScored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 1082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  cp_type  cp_time  cp_dose     g-0     g-1     g-2  \\\n",
       "0      id_000644bb2        1      0.0        0  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc        1      1.0        0  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a        1      0.5        0  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391        1      0.5        0 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3        1      1.0        1 -0.3254 -0.4009  0.9700   \n",
       "...             ...      ...      ...      ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed        1      0.0        1  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c        1      0.0        1 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4        0      0.5        1  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c        1      0.0        0  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b        1      1.0        0 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "          g-3     g-4     g-5  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ...                                      0   \n",
       "1      0.0604  1.0190  0.5207  ...                                      0   \n",
       "2     -0.0764 -0.0323  1.2390  ...                                      0   \n",
       "3      0.5288  4.0620 -0.8095  ...                                      0   \n",
       "4      0.6919  1.4180 -0.8244  ...                                      0   \n",
       "...       ...     ...     ...  ...                                    ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ...                                      0   \n",
       "23810  0.9905 -0.7178  0.6621  ...                                      0   \n",
       "23811 -0.7389  0.5505 -0.0159  ...                                      0   \n",
       "23812  0.2044  0.8531 -0.0343  ...                                      0   \n",
       "23813  0.7952 -0.3611 -3.6750  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 1082 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>-0.5743</td>\n",
       "      <td>3.3930</td>\n",
       "      <td>-0.6202</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>1.6240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5885</td>\n",
       "      <td>-0.2548</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3985</td>\n",
       "      <td>-0.1554</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>-0.6813</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0960</td>\n",
       "      <td>-1.7750</td>\n",
       "      <td>-0.3977</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>-1.3350</td>\n",
       "      <td>-0.2207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5174</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>-0.0428</td>\n",
       "      <td>-0.0800</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 1082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  cp_type  cp_time  cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0     id_0004d9e33        1      0.0        0 -0.5458  0.1306 -0.5135  0.4408   \n",
       "1     id_001897cda        1      1.0        0 -0.1829  0.2320  1.2080 -0.4522   \n",
       "2     id_002429b5b        0      0.0        0  0.1852 -0.1404 -0.3911  0.1310   \n",
       "3     id_00276f245        1      0.0        1  0.4828  0.1955  0.3825  0.4244   \n",
       "4     id_0027f1083        1      0.5        0 -0.3979 -1.2680  1.9130  0.2057   \n",
       "...            ...      ...      ...      ...     ...     ...     ...     ...   \n",
       "3977  id_ff7004b87        1      0.0        0  0.4571 -0.5743  3.3930 -0.6202   \n",
       "3978  id_ff925dd0d        1      0.0        0 -0.5885 -0.2548  2.5850  0.3456   \n",
       "3979  id_ffb710450        1      1.0        0 -0.3985 -0.1554  0.2677 -0.6813   \n",
       "3980  id_ffbb869f2        1      0.5        1 -1.0960 -1.7750 -0.3977  1.0160   \n",
       "3981  id_ffd5800b6        1      1.0        0 -0.5174  0.2953  0.3286 -0.0428   \n",
       "\n",
       "         g-4     g-5  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0     1.5500 -0.1644  ...                                    0.5   \n",
       "1    -0.3652 -0.3319  ...                                    0.5   \n",
       "2    -1.4380  0.2455  ...                                    0.5   \n",
       "3    -0.5855 -1.2020  ...                                    0.5   \n",
       "4    -0.5864 -0.0166  ...                                    0.5   \n",
       "...      ...     ...  ...                                    ...   \n",
       "3977  0.8557  1.6240  ...                                    0.5   \n",
       "3978  0.4401  0.3107  ...                                    0.5   \n",
       "3979  0.0152  0.4791  ...                                    0.5   \n",
       "3980 -1.3350 -0.2207  ...                                    0.5   \n",
       "3981 -0.0800  0.8702  ...                                    0.5   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0              0.5              0.5                0.5   \n",
       "1              0.5              0.5                0.5   \n",
       "2              0.5              0.5                0.5   \n",
       "3              0.5              0.5                0.5   \n",
       "4              0.5              0.5                0.5   \n",
       "...            ...              ...                ...   \n",
       "3977           0.5              0.5                0.5   \n",
       "3978           0.5              0.5                0.5   \n",
       "3979           0.5              0.5                0.5   \n",
       "3980           0.5              0.5                0.5   \n",
       "3981           0.5              0.5                0.5   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                           0.5                                    0.5   \n",
       "1                           0.5                                    0.5   \n",
       "2                           0.5                                    0.5   \n",
       "3                           0.5                                    0.5   \n",
       "4                           0.5                                    0.5   \n",
       "...                         ...                                    ...   \n",
       "3977                        0.5                                    0.5   \n",
       "3978                        0.5                                    0.5   \n",
       "3979                        0.5                                    0.5   \n",
       "3980                        0.5                                    0.5   \n",
       "3981                        0.5                                    0.5   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                 0.5        0.5                         0.5            0.5  \n",
       "1                 0.5        0.5                         0.5            0.5  \n",
       "2                 0.5        0.5                         0.5            0.5  \n",
       "3                 0.5        0.5                         0.5            0.5  \n",
       "4                 0.5        0.5                         0.5            0.5  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977              0.5        0.5                         0.5            0.5  \n",
       "3978              0.5        0.5                         0.5            0.5  \n",
       "3979              0.5        0.5                         0.5            0.5  \n",
       "3980              0.5        0.5                         0.5            0.5  \n",
       "3981              0.5        0.5                         0.5            0.5  \n",
       "\n",
       "[3982 rows x 1082 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>-0.8121</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>-0.3246</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.8086</td>\n",
       "      <td>-0.9798</td>\n",
       "      <td>-0.2084</td>\n",
       "      <td>-0.1224</td>\n",
       "      <td>-0.2715</td>\n",
       "      <td>0.3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.7592</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1105</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>-0.2012</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>1.5230</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>-0.6290</td>\n",
       "      <td>0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3890</td>\n",
       "      <td>-1.7450</td>\n",
       "      <td>-6.6300</td>\n",
       "      <td>-4.0950</td>\n",
       "      <td>-7.3860</td>\n",
       "      <td>-1.4160</td>\n",
       "      <td>-3.5770</td>\n",
       "      <td>-0.4775</td>\n",
       "      <td>-2.1500</td>\n",
       "      <td>-4.2520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2  \\\n",
       "0      id_000644bb2       trt_cp       24      D1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc       trt_cp       72      D1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a       trt_cp       48      D1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391       trt_cp       48      D1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3       trt_cp       72      D2 -0.3254 -0.4009  0.9700   \n",
       "...             ...          ...      ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed       trt_cp       24      D2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c       trt_cp       24      D2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4  ctl_vehicle       48      D2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c       trt_cp       24      D1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b       trt_cp       72      D1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "          g-3     g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912   \n",
       "1      0.0604  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957   \n",
       "2     -0.0764 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240   \n",
       "3      0.5288  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632   \n",
       "4      0.6919  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ...  0.1969  0.0262 -0.8121  0.3434  0.5372   \n",
       "23810  0.9905 -0.7178  0.6621  ...  0.4286  0.4426  0.0423 -0.3195 -0.8086   \n",
       "23811 -0.7389  0.5505 -0.0159  ...  0.5409  0.3755  0.7343  0.2807  0.4116   \n",
       "23812  0.2044  0.8531 -0.0343  ... -0.1105  0.4258 -0.2012  0.1506  1.5230   \n",
       "23813  0.7952 -0.3611 -3.6750  ... -3.3890 -1.7450 -6.6300 -4.0950 -7.3860   \n",
       "\n",
       "         c-95    c-96    c-97    c-98    c-99  \n",
       "0      0.6584 -0.3981  0.2139  0.3801  0.4176  \n",
       "1      0.4899  0.1522  0.1241  0.6077  0.7371  \n",
       "2     -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3     -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4     -0.3031  0.1094  0.2885 -0.3786  0.7125  \n",
       "...       ...     ...     ...     ...     ...  \n",
       "23809 -0.3246  0.0631  0.9171  0.5258  0.4680  \n",
       "23810 -0.9798 -0.2084 -0.1224 -0.2715  0.3689  \n",
       "23811  0.6422  0.2256  0.7592  0.6656  0.3808  \n",
       "23812  0.7101  0.1732  0.7015 -0.6290  0.0740  \n",
       "23813 -1.4160 -3.5770 -0.4775 -2.1500 -4.2520  \n",
       "\n",
       "[23814 rows x 876 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>-0.1430</td>\n",
       "      <td>-0.2067</td>\n",
       "      <td>-0.2303</td>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>-0.1852</td>\n",
       "      <td>-1.0310</td>\n",
       "      <td>-1.3670</td>\n",
       "      <td>-0.3690</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.4764</td>\n",
       "      <td>-1.3810</td>\n",
       "      <td>-0.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>-1.3840</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>-1.9530</td>\n",
       "      <td>-1.0140</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-0.1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>-0.1784</td>\n",
       "      <td>-1.1200</td>\n",
       "      <td>-0.4325</td>\n",
       "      <td>-0.9005</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-0.1305</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>-0.5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-0.1580</td>\n",
       "      <td>1.0510</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>-0.2962</td>\n",
       "      <td>-0.5313</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>1.8380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>-0.5743</td>\n",
       "      <td>3.3930</td>\n",
       "      <td>-0.6202</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>1.6240</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1790</td>\n",
       "      <td>-0.6422</td>\n",
       "      <td>-0.4367</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>-0.6539</td>\n",
       "      <td>-0.4791</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>-1.1280</td>\n",
       "      <td>-0.4167</td>\n",
       "      <td>-0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5885</td>\n",
       "      <td>-0.2548</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>-0.5888</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>1.2730</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>-0.2790</td>\n",
       "      <td>-0.0131</td>\n",
       "      <td>-0.0934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3985</td>\n",
       "      <td>-0.1554</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>-0.6813</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4418</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>-0.1862</td>\n",
       "      <td>0.4049</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.4666</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>-0.4205</td>\n",
       "      <td>-0.1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.0960</td>\n",
       "      <td>-1.7750</td>\n",
       "      <td>-0.3977</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>-1.3350</td>\n",
       "      <td>-0.2207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>-0.4473</td>\n",
       "      <td>-0.8192</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>-0.2618</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>-0.0484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5174</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>-0.0428</td>\n",
       "      <td>-0.0800</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>-0.0507</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>-0.4041</td>\n",
       "      <td>-0.4948</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>-0.1356</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2  \\\n",
       "0     id_0004d9e33       trt_cp       24      D1 -0.5458  0.1306 -0.5135   \n",
       "1     id_001897cda       trt_cp       72      D1 -0.1829  0.2320  1.2080   \n",
       "2     id_002429b5b  ctl_vehicle       24      D1  0.1852 -0.1404 -0.3911   \n",
       "3     id_00276f245       trt_cp       24      D2  0.4828  0.1955  0.3825   \n",
       "4     id_0027f1083       trt_cp       48      D1 -0.3979 -1.2680  1.9130   \n",
       "...            ...          ...      ...     ...     ...     ...     ...   \n",
       "3977  id_ff7004b87       trt_cp       24      D1  0.4571 -0.5743  3.3930   \n",
       "3978  id_ff925dd0d       trt_cp       24      D1 -0.5885 -0.2548  2.5850   \n",
       "3979  id_ffb710450       trt_cp       72      D1 -0.3985 -0.1554  0.2677   \n",
       "3980  id_ffbb869f2       trt_cp       48      D2 -1.0960 -1.7750 -0.3977   \n",
       "3981  id_ffd5800b6       trt_cp       72      D1 -0.5174  0.2953  0.3286   \n",
       "\n",
       "         g-3     g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94  \\\n",
       "0     0.4408  1.5500 -0.1644  ...  0.0981  0.7978 -0.1430 -0.2067 -0.2303   \n",
       "1    -0.4522 -0.3652 -0.3319  ... -0.1190 -0.1852 -1.0310 -1.3670 -0.3690   \n",
       "2     0.1310 -1.4380  0.2455  ... -0.2261  0.3370 -1.3840  0.8604 -1.9530   \n",
       "3     0.4244 -0.5855 -1.2020  ...  0.1260  0.1570 -0.1784 -1.1200 -0.4325   \n",
       "4     0.2057 -0.5864 -0.0166  ...  0.4965  0.7578 -0.1580  1.0510  0.5742   \n",
       "...      ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "3977 -0.6202  0.8557  1.6240  ... -1.1790 -0.6422 -0.4367  0.0159 -0.6539   \n",
       "3978  0.3456  0.4401  0.3107  ...  0.0210  0.5780 -0.5888  0.8057  0.9312   \n",
       "3979 -0.6813  0.0152  0.4791  ...  0.4418  0.9153 -0.1862  0.4049  0.9568   \n",
       "3980  1.0160 -1.3350 -0.2207  ...  0.3079 -0.4473 -0.8192  0.7785  0.3133   \n",
       "3981 -0.0428 -0.0800  0.8702  ...  0.0363  0.1708  0.5939 -0.0507  0.2811   \n",
       "\n",
       "        c-95    c-96    c-97    c-98    c-99  \n",
       "0    -0.1193  0.0210 -0.0502  0.1510 -0.7750  \n",
       "1    -0.5382  0.0359 -0.4764 -1.3810 -0.7300  \n",
       "2    -1.0140  0.8662  1.0160  0.4924 -0.1942  \n",
       "3    -0.9005  0.8131 -0.1305  0.5645 -0.5809  \n",
       "4     1.0900 -0.2962 -0.5313  0.9931  1.8380  \n",
       "...      ...     ...     ...     ...     ...  \n",
       "3977 -0.4791 -1.2680 -1.1280 -0.4167 -0.6600  \n",
       "3978  1.2730  0.2614 -0.2790 -0.0131 -0.0934  \n",
       "3979  0.4666  0.0461  0.5888 -0.4205 -0.1504  \n",
       "3980  0.1286 -0.2618  0.5074  0.7430 -0.0484  \n",
       "3981 -0.4041 -0.4948  0.0757 -0.1356  0.5280  \n",
       "\n",
       "[3982 rows x 876 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config about Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configは辞書化しておく。\n",
    "def Config_about_Fitting(train, test, target, folds):\n",
    "    confFitting = {}\n",
    "    \n",
    "    #Fitするときに\"y\"として使う列の列名配列\n",
    "    confFitting[\"target_cols\"] = target.drop('sig_id', axis=1).columns.values.tolist()\n",
    "    #Fitするときに\"X\"として使う列の列名配列\n",
    "    #kfold, id等はここで削除。\n",
    "    feature_cols = [c for c in folds.columns if c not in confFitting[\"target_cols\"]]\n",
    "    confFitting[\"feature_cols\"] = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "    #特徴量、ターゲットのサイズ\n",
    "    confFitting[\"num_features\"]=len(confFitting[\"feature_cols\"])\n",
    "    confFitting[\"num_targets\"]=len(confFitting[\"target_cols\"])\n",
    "    \n",
    "    return confFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fitTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitPreprocessingModel(param, train, test, valid, fold, seed):\n",
    "    \n",
    "    #LOG SCALER\n",
    "    train_all_features = train[all_features].copy().values\n",
    "    valid_all_features = valid[all_features].copy().values\n",
    "    test_all_features = test[all_features].copy().values\n",
    "    \n",
    "    all_scaler = LogScaler()\n",
    "    train_all_features = all_scaler.fit_transform(train_all_features)\n",
    "    test_all_features = all_scaler.transform(test_all_features)\n",
    "    valid_all_features = all_scaler.transform(valid_all_features)\n",
    "    \n",
    "    train[all_features] = train_all_features\n",
    "    test[all_features] = test_all_features\n",
    "    valid[all_features] = valid_all_features\n",
    "    \n",
    "    dump(all_scaler, open(f\"{SAVELOGSCALE}/seed{seed}_fold{fold}_LogScaleTransformer.pkl\", 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    #DeepInsight\n",
    "    all_it = DeepInsightTransformer(feature_extractor='tsne_exact',\n",
    "                                    pixels=resolution,\n",
    "                                    perplexity=5,\n",
    "                                    random_state=1120,\n",
    "                                    n_jobs=-1)\n",
    "    all_it.fit(train_all_features, plot=False)\n",
    "    \n",
    "    dump(all_it, open(f\"{SAVEDEEPINSIGHT}/seed{seed}_fold{fold}_DeepInsightTransformer.pkl\", 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return all_scaler, all_it, train, test, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoAImageSwapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 features,\n",
    "                 labels,\n",
    "                 transformer,\n",
    "                 swap_prob=0.15,\n",
    "                 swap_portion=0.1):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transformer = transformer\n",
    "        self.swap_prob = swap_prob\n",
    "        self.swap_portion = swap_portion\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        normalized = self.features[index, :]\n",
    "\n",
    "        # Swap row features randomly\n",
    "        normalized = self.add_swap_noise(index, normalized)\n",
    "\n",
    "        normalized = np.expand_dims(normalized, axis=0)\n",
    "\n",
    "        # Note: we are setting empty_value=1 to follow the setup in the paper\n",
    "        image = self.transformer.transform(normalized, empty_value=1)[0]\n",
    "\n",
    "        # Resize to target size\n",
    "        gene_cht = cv2.resize(image, (image_size, image_size),\n",
    "                              interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert to 3 channels\n",
    "        image = np.repeat(gene_cht[np.newaxis, :, :], 3, axis=0)\n",
    "\n",
    "        return {\"x\": image, \"y\": self.labels[index, :]}\n",
    "\n",
    "    def add_swap_noise(self, index, X):\n",
    "        if np.random.rand() < self.swap_prob:\n",
    "            swap_index = np.random.randint(self.features.shape[0], size=1)[0]\n",
    "            # Select only gene expression and cell viability features\n",
    "            swap_features = np.random.choice(\n",
    "                np.array(range(3, self.features.shape[1])),\n",
    "                size=int(self.features.shape[1] * self.swap_portion),\n",
    "                replace=False)\n",
    "            X[swap_features] = self.features[swap_index, swap_features]\n",
    "\n",
    "        return X\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "class MoAImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels, transformer):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        normalized = self.features[index, :]\n",
    "        normalized = np.expand_dims(normalized, axis=0)\n",
    "\n",
    "        # Note: we are setting empty_value=1 to follow the setup in the paper\n",
    "        image = self.transformer.transform(normalized, empty_value=1)[0]\n",
    "\n",
    "        # Resize to target size\n",
    "        gene_cht = cv2.resize(image, (image_size, image_size),\n",
    "                              interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert to 3 channels\n",
    "        image = np.repeat(gene_cht[np.newaxis, :, :], 3, axis=0)\n",
    "\n",
    "        return {\"x\": image, \"y\": self.labels[index, :]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels, transformer):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        normalized = self.features[index, :]\n",
    "        normalized = np.expand_dims(normalized, axis=0)\n",
    "\n",
    "        # Note: we are setting empty_value=1 to follow the setup in the paper\n",
    "        image = self.transformer.transform(normalized, empty_value=1)[0]\n",
    "\n",
    "        # Resize to target size\n",
    "        gene_cht = cv2.resize(image, (image_size, image_size),\n",
    "                              interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert to 3 channels\n",
    "        image = np.repeat(gene_cht[np.newaxis, :, :], 3, axis=0)\n",
    "\n",
    "        return {\"x\": image, \"y\": -1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/rwightman/gen-efficientnet-pytorch/blob/master/geffnet/efficientnet_builder.py#L672\n",
    "def initialize_weight_goog(m, n='', fix_group_fanout=True):\n",
    "    # weight init as per Tensorflow Official impl\n",
    "    # https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_model.py\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        if fix_group_fanout:\n",
    "            fan_out //= m.groups\n",
    "        m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1.0)\n",
    "        m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        fan_out = m.weight.size(0)  # fan-out\n",
    "        fan_in = 0\n",
    "        if 'routing_fn' in n:\n",
    "            fan_in = m.weight.size(1)\n",
    "        init_range = 1.0 / math.sqrt(fan_in + fan_out)\n",
    "        m.weight.data.uniform_(-init_range, init_range)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def initialize_weight_default(m, n=''):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1.0)\n",
    "        m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight,\n",
    "                                 mode='fan_in',\n",
    "                                 nonlinearity='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "    def forward(self, x, target, smoothing=0.001):\n",
    "        confidence = 1. - smoothing\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        bcs_loss = nn.BCEWithLogitsLoss()(x, target)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = confidence * bcs_loss + smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "#nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: Fitting, Evaluation, Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoAEfficientNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_model_name,\n",
    "            training_set=(None, None),  # tuple\n",
    "            valid_set=(None, None),  # tuple\n",
    "            test_set=None,\n",
    "            transformer=None,\n",
    "            num_classes=206,\n",
    "            in_chans=3,\n",
    "            drop_rate=0.,\n",
    "            drop_connect_rate=0.,\n",
    "            fc_size=512,\n",
    "            learning_rate=1e-3,\n",
    "            weight_init='goog'):\n",
    "        super(MoAEfficientNet, self).__init__()\n",
    "\n",
    "        self.train_data, self.train_labels = training_set\n",
    "        self.valid_data, self.valid_labels = valid_set\n",
    "        self.test_data = test_set\n",
    "        self.transformer = transformer\n",
    "\n",
    "        self.backbone = getattr(geffnet, pretrained_model)(\n",
    "            pretrained=True,\n",
    "            in_chans=in_chans,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_connect_rate=drop_connect_rate,\n",
    "            weight_init=weight_init)\n",
    "\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(self.backbone.classifier.in_features, fc_size,\n",
    "                      bias=True), nn.ELU(),\n",
    "            nn.Linear(fc_size, num_classes, bias=True))\n",
    "\n",
    "        if self.training:\n",
    "            for m in self.backbone.classifier.modules():\n",
    "                initialize_weight_goog(m)\n",
    "\n",
    "        # Save passed hyperparameters\n",
    "        self.save_hyperparameters(\"pretrained_model_name\", \"num_classes\",\n",
    "                                  \"in_chans\", \"drop_rate\", \"drop_connect_rate\",\n",
    "                                  \"weight_init\", \"fc_size\", \"learning_rate\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[\"x\"]\n",
    "        y = batch[\"y\"]\n",
    "        x = x.float()\n",
    "        y = y.type_as(x)\n",
    "        logits = self(x)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y, reduction=\"mean\")\n",
    "\n",
    "        self.log('train_loss',\n",
    "                 loss,\n",
    "                 on_step=True,\n",
    "                 on_epoch=True,\n",
    "                 prog_bar=True,\n",
    "                 logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch[\"x\"]\n",
    "        y = batch[\"y\"]\n",
    "        x = x.float()\n",
    "        y = y.type_as(x)\n",
    "        logits = self(x)\n",
    "\n",
    "        val_loss = F.binary_cross_entropy_with_logits(logits,\n",
    "                                                      y,\n",
    "                                                      reduction=\"mean\")\n",
    "\n",
    "        self.log('val_loss',\n",
    "                 val_loss,\n",
    "                 on_step=True,\n",
    "                 on_epoch=True,\n",
    "                 prog_bar=True,\n",
    "                 logger=True)\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = batch[\"x\"]\n",
    "        y = batch[\"y\"]\n",
    "        x = x.float()\n",
    "        y = y.type_as(x)\n",
    "        logits = self(x)\n",
    "        return {\"pred_logits\": logits}\n",
    "\n",
    "    def test_epoch_end(self, output_results):\n",
    "        all_outputs = torch.cat([out[\"pred_logits\"] for out in output_results],\n",
    "                                dim=0)\n",
    "        print(\"Logits:\", all_outputs)\n",
    "        pred_probs = F.sigmoid(all_outputs).detach().cpu().numpy()\n",
    "        print(\"Predictions: \", pred_probs)\n",
    "        return {\"pred_probs\": pred_probs}\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        #         self.train_dataset = MoAImageDataset(self.train_data,\n",
    "        #                                              self.train_labels,\n",
    "        #                                              self.transformer)\n",
    "        self.train_dataset = MoAImageSwapDataset(self.train_data,\n",
    "                                                 self.train_labels,\n",
    "                                                 self.transformer,\n",
    "                                                 swap_prob=swap_prob,\n",
    "                                                 swap_portion=swap_portion)\n",
    "\n",
    "        self.val_dataset = MoAImageDataset(self.valid_data, self.valid_labels,\n",
    "                                           self.transformer)\n",
    "\n",
    "        self.test_dataset = TestDataset(self.test_data, None, self.transformer)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataloader = DataLoader(self.train_dataset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      pin_memory=True,\n",
    "                                      drop_last=False)\n",
    "        print(f\"Train iterations: {len(train_dataloader)}\")\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataloader = DataLoader(self.val_dataset,\n",
    "                                    batch_size=infer_batch_size,\n",
    "                                    shuffle=False,\n",
    "                                    num_workers=num_workers,\n",
    "                                    pin_memory=True,\n",
    "                                    drop_last=False)\n",
    "        print(f\"Validate iterations: {len(val_dataloader)}\")\n",
    "        return val_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_dataloader = DataLoader(self.test_dataset,\n",
    "                                     batch_size=infer_batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=num_workers,\n",
    "                                     pin_memory=True,\n",
    "                                     drop_last=False)\n",
    "        print(f\"Test iterations: {len(test_dataloader)}\")\n",
    "        return test_dataloader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        print(f\"Initial Learning Rate: {self.hparams.learning_rate:.6f}\")\n",
    "        optimizer = optim.Adam(self.parameters(),\n",
    "                               lr=self.hparams.learning_rate,\n",
    "                               weight_decay=weight_decay)\n",
    "\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                         T_max=T_max,\n",
    "                                                         eta_min=0,\n",
    "                                                         last_epoch=-1)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds(train, target):\n",
    "    folds = train.copy()\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "    \n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "        folds.loc[v_idx, 'kfold'] = int(f)\n",
    "    \n",
    "    folds['kfold'] = folds['kfold'].astype(int)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds_drug_id(train, target):\n",
    "    ###drug_idを考慮####\n",
    "    \n",
    "    targets = target.columns[1:]\n",
    "    \n",
    "    # foldsにdrug_id付与\n",
    "    folds = train.copy()\n",
    "    folds = folds.merge(drug, on='sig_id', how='left') \n",
    "    \n",
    "    # LOCATE DRUGS\n",
    "    vc = folds.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc<=18].index.sort_values()\n",
    "    vc2 = vc.loc[vc>18].index.sort_values()\n",
    "    \n",
    "    # STRATIFY DRUGS 18X OR LESS\n",
    "    dct1 = {}; dct2 = {}\n",
    "    skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, \n",
    "              random_state=42)\n",
    "    tmp = folds.groupby('drug_id')[targets].mean().loc[vc1]\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.index[idxV].values}\n",
    "        dct1.update(dd)\n",
    "    \n",
    "    # STRATIFY DRUGS MORE THAN 18X\n",
    "    skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, \n",
    "              random_state=42)\n",
    "    tmp = folds.loc[folds.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "        dct2.update(dd)\n",
    "    \n",
    "    # ASSIGN NFOLDS\n",
    "    folds['kfold'] = folds.drug_id.map(dct1)\n",
    "    folds.loc[folds.kfold.isna(),'kfold'] =\\\n",
    "        folds.loc[folds.kfold.isna(),'sig_id'].map(dct2)\n",
    "    folds.kfold = folds.kfold.astype('int8')\n",
    "    \n",
    "    folds = folds.drop('drug_id', axis=1)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 446 ms, sys: 141 ms, total: 587 ms\n",
      "Wall time: 586 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1083 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  cp_type  cp_time  cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2        1      0.0        0  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc        1      1.0        0  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a        1      0.5        0  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391        1      0.5        0 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3        1      1.0        1 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0 -0.1944 -1.0120  ...             0                0                  0   \n",
       "1  1.0190  0.5207  ...             0                0                  0   \n",
       "2 -0.0323  1.2390  ...             0                0                  0   \n",
       "3  4.0620 -0.8095  ...             0                0                  0   \n",
       "4  1.4180 -0.8244  ...             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0                0          0                           0              0   \n",
       "1                0          0                           0              0   \n",
       "2                0          0                           0              0   \n",
       "3                0          0                           0              0   \n",
       "4                0          0                           0              0   \n",
       "\n",
       "   kfold  \n",
       "0      4  \n",
       "1      2  \n",
       "2      4  \n",
       "3      0  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 1083 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Preprocessing Data\n",
    "trainVsl, testVsl = preprocessing(param_space, trainFeature, testFeature, trainTargetScored)\n",
    "#CV folds\n",
    "foldsVsl = CV_folds_drug_id(trainVsl, trainTargetScored)\n",
    "\n",
    "foldsVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = foldsVsl\n",
    "fold = 1\n",
    "seed = 1\n",
    "\n",
    "confFitting = Config_about_Fitting(trainVsl, testVsl, trainTargetScored, foldsVsl)\n",
    "\n",
    "trn_idx = train[train['kfold'] != fold].index\n",
    "val_idx = train[train['kfold'] == fold].index\n",
    "\n",
    "train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "x_train, y_train  = train_df[confFitting[\"feature_cols\"]], train_df[confFitting[\"target_cols\"]].values\n",
    "x_valid, y_valid =  valid_df[confFitting[\"feature_cols\"]], valid_df[confFitting[\"target_cols\"]].values\n",
    "x_test = testVsl[confFitting[\"feature_cols\"]]\n",
    "\n",
    "all_scaler, all_it, x_train, x_test, x_valid = fitPreprocessingModel(param_space, x_train, x_test, x_valid, fold, seed)\n",
    "x_train = x_train.values\n",
    "x_valid = x_valid.values\n",
    "x_test = x_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22767025, 0.        , 0.        , ..., 0.79393538, 0.79876771,\n",
       "        0.79984828],\n",
       "       [0.22767025, 0.22767025, 0.        , ..., 0.79129452, 0.805272  ,\n",
       "        0.80891332],\n",
       "       [0.22767025, 0.13317856, 0.        , ..., 0.78101351, 0.74262202,\n",
       "        0.80767969],\n",
       "       ...,\n",
       "       [0.        , 0.13317856, 0.22767025, ..., 0.8095312 , 0.8069063 ,\n",
       "        0.79878791],\n",
       "       [0.22767025, 0.        , 0.        , ..., 0.80791556, 0.76826941,\n",
       "        0.78981189],\n",
       "       [0.22767025, 0.22767025, 0.        , ..., 0.77303284, 0.71617717,\n",
       "        0.62710859]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19045, 875)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4769, 875)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    0,     1,     2,     3,     5,     6,     7,     8,    10,\n",
       "               12,\n",
       "            ...\n",
       "            23801, 23803, 23806, 23807, 23808, 23809, 23810, 23811, 23812,\n",
       "            23813],\n",
       "           dtype='int64', length=19045)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19045, 206)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scaler, all_it, train, test, valid = fitPreprocessingModel(param, train, test, valid, fold, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(confFitting, Tester, fold, seed, param,\n",
    "                 folds, train, test, target):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = folds\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[confFitting[\"feature_cols\"]], train_df[confFitting[\"target_cols\"]].values\n",
    "    x_valid, y_valid =  valid_df[confFitting[\"feature_cols\"]], valid_df[confFitting[\"target_cols\"]].values\n",
    "    x_test = testVsl[confFitting[\"feature_cols\"]]\n",
    "    \n",
    "    #データセットをイメージ化するトランスフォーマー。\n",
    "    #ここでLogScaleも実施。\n",
    "    all_scaler, all_it, x_train, x_test, x_valid = fitPreprocessingModel(param_space, x_train, x_test, x_valid, fold, seed)\n",
    "    x_train = x_train.values\n",
    "    x_valid = x_valid.values\n",
    "    x_test = x_test.values\n",
    "    \n",
    "    #model class 定義\n",
    "    model = MoAEfficientNet(\n",
    "        model_path,\n",
    "        pretrained_model_name=pretrained_model,\n",
    "        training_set=(x_train, y_train),  # tuple\n",
    "        valid_set=(x_valid, y_valid),  # tuple\n",
    "        test_set=x_test,\n",
    "        transformer=all_it,\n",
    "        drop_rate=drop_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        fc_size=fc_size,\n",
    "        weight_init='goog')\n",
    "    \n",
    "    #データセット定義(データセットをイメージ化)\n",
    "    model.setup()\n",
    "    \n",
    "    trainloader = model.train_dataloader()\n",
    "    validloader = model.val_dataloader()\n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        gpus=gpus,\n",
    "        distributed_backend=\"dp\",  # multiple-gpus, 1 machine\n",
    "        precision=16)\n",
    "    \n",
    "    \n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    #scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "    #                                          max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    ##### 評価関数 ######\n",
    "    train_loss_fn = LabelSmoothingCrossEntropy()\n",
    "    valid_loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, train_loss_fn, trainloader, DEVICE)\n",
    "        valid_loss, valid_preds = valid_fn(model, valid_loss_fn, validloader, DEVICE)\n",
    "        if Tester:\n",
    "            print(\"EPOCH: {:03}: | train_loss: {:.3f}: | valid_loss: {:.3f}\".format(epoch, train_loss, valid_loss))\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                if Tester:\n",
    "                    print('Early stopping. Best Val loss: {:.3f}'.format(best_loss))\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    \n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(Tester, NFOLDS, seed, param,\n",
    "               folds, train, test, target, confFitting):\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        oof_, pred_ = run_training(confFitting, Tester, fold, seed, param,\n",
    "                                   folds, train, test, target)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    " def CV_Evaluation(confFitting, oof, train, target):\n",
    "    #CV score : OOFの評価結果。\n",
    "    #OOF(学習モデルによるtrain dataの予測)\n",
    "    train[confFitting[\"target_cols\"]] = oof\n",
    "    #target(予測結果)：ここで処理「cp_type = ctl_vehicleのレコードを削除」で抜けたところに0を入れている。\n",
    "    valid_results = trainTargetScored.drop(columns=confFitting[\"target_cols\"]).merge(train[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    \n",
    "    y_true = trainTargetScored[confFitting[\"target_cols\"]].values\n",
    "    y_pred = valid_results[confFitting[\"target_cols\"]].values\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(confFitting[\"num_targets\"]):\n",
    "        score_ = log_loss(y_true[:, i], y_pred[:, i]) #問題の評価指標によって変わる。\n",
    "        score += score_ / target.shape[1]\n",
    "        \n",
    "    print(\"CV log_loss: \", score)\n",
    "    \n",
    "    #OOF save\n",
    "    np.save(SAVEOOF + 'oof', y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特になし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Submit(confFitting, predictions, test):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Exec(param):\n",
    "    \n",
    "    #Tester(True/False)\n",
    "    Tester = True\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds_drug_id(train, trainTargetScored)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 0 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.018\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.567: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "Early stopping. Best Val loss: 0.017\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.571: | valid_loss: 0.051\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.022\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 1 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.565: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.018\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.052\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "Early stopping. Best Val loss: 0.017\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.565: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "Early stopping. Best Val loss: 0.017\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.052\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.026\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 2 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.572: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.022\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.018\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "Early stopping. Best Val loss: 0.017\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.571: | valid_loss: 0.050\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.051\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.019\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "Early stopping. Best Val loss: 0.017\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.050\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 3 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.019\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.018\n",
      "Early stopping. Best Val loss: 0.018\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.566: | valid_loss: 0.046\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "Early stopping. Best Val loss: 0.017\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.567: | valid_loss: 0.045\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.566: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.053\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "Early stopping. Best Val loss: 0.017\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 4 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.046\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.018\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.566: | valid_loss: 0.057\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "Early stopping. Best Val loss: 0.017\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.567: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.566: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 5 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.054\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.018\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.018\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.020\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.566: | valid_loss: 0.044\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.018\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.567: | valid_loss: 0.046\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.022\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.018\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.017\n",
      "CV log_loss:  0.01580344356749381\n",
      "sub.shape(3982, 207)\n",
      "score: 0.01580344356749381\n",
      "CPU times: user 14min 20s, sys: 6.75 s, total: 14min 27s\n",
      "Wall time: 11min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score= Exec(param_space)\n",
    "print(\"score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 0 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.017\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.567: | valid_loss: 0.051\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.571: | valid_loss: 0.053\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.022: | valid_loss: 0.016\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 1 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.565: | valid_loss: 0.054\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.017\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.565: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.565: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.567: | valid_loss: 0.051\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.023\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 2 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.050\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.050\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.052\n",
      "EPOCH: 001: | train_loss: 0.032: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.022: | valid_loss: 0.016\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 3 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.044\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.571: | valid_loss: 0.050\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 4 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.567: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.571: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.050\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.022: | valid_loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.021: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 024: | train_loss: 0.022: | valid_loss: 0.017\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 5 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.570: | valid_loss: 0.051\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.027: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.567: | valid_loss: 0.045\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.053\n",
      "EPOCH: 001: | train_loss: 0.032: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.031: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.026: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.025: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.024: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.024: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.023: | valid_loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 019: | train_loss: 0.023: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 021: | train_loss: 0.022: | valid_loss: 0.017\n",
      "EPOCH: 022: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.022: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.021: | valid_loss: 0.016\n",
      "CV log_loss:  0.014961652542748904\n",
      "sub.shape(3982, 207)\n",
      "CPU times: user 14min 32s, sys: 6.98 s, total: 14min 39s\n",
      "Wall time: 11min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score= Exec(param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.014961652542748904\n"
     ]
    }
   ],
   "source": [
    "print(\"score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(confFitting, param, test, target, fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "  \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed):\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        pred_ = run_predict(confFitting, param, test, target, fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitPredict(confFitting, predictions, test, prefix):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}{prefix}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    #folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        predictions_ = run_k_fold_predict(confFitting, train, test, target, param, Tester, NFOLDS, seed)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    # 課題提出\n",
    "    prefix = \"Pytorch\"\n",
    "    SubmitPredict(confFitting, predictions, test, prefix)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub.shape(3982, 207)\n",
      "CPU times: user 18.5 s, sys: 12.8 s, total: 31.3 s\n",
      "Wall time: 6.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Predict(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperopt\n",
    "from hyperopt import fmin, tpe, hp, rand, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOptExec(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    #Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:                                          \n",
      "0.014981391207012364                                  \n",
      "CV log_loss:                                                                         \n",
      "0.01504250432043703                                                                  \n",
      "CV log_loss:                                                                         \n",
      "0.015004835293169368                                                                 \n",
      "CV log_loss:                                                                         \n",
      "0.015002514832957038                                                                 \n",
      "CV log_loss:                                                                         \n",
      "0.015008986227264749                                                                 \n",
      "CV log_loss:                                                                         \n",
      "0.014993115273980633                                                                   \n",
      "CV log_loss:                                                                           \n",
      "0.015004305432533609                                                                   \n",
      "CV log_loss:                                                                           \n",
      "0.015005235605759781                                                                   \n",
      "CV log_loss:                                                                           \n",
      "0.01505112173070906                                                                    \n",
      "CV log_loss:                                                                           \n",
      "0.014989767496596161                                                                   \n",
      "CV log_loss:                                                                           \n",
      "0.015010978983541678                                                                  \n",
      "CV log_loss:                                                                          \n",
      "0.015006924959817869                                                                  \n",
      "CV log_loss:                                                                          \n",
      "0.01498752231737257                                                                   \n",
      " 87%|████████▋ | 13/15 [2:14:54<20:46, 623.49s/trial, best loss: 0.014981391207012364]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_space = {'hidden_size1': 512, \n",
    "               'hidden_size2': 512, \n",
    "               'dropOutRate1': 0.20393004966355735, \n",
    "               'dropOutRate2': 0.39170486751620137,\n",
    "               'rankGauss_n_quantiles': 488.0393350201078,\n",
    "               'leakyReluSlope': hp.uniform('leakyReluSlope', 1e-3, 1e-1),\n",
    "              }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "hopt = fmin(fn = HOptExec, \n",
    "            space = param_space, \n",
    "            algo = tpe.suggest, \n",
    "            max_evals = 15, \n",
    "            #timeout = 8.9 * 60 * 60, \n",
    "            trials = trials, \n",
    "           )\n",
    "\n",
    "print(hopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
