{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.metrics.functional import classification\n",
    "\n",
    "import cv2\n",
    "import geffnet\n",
    "import math\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial import ConvexHull\n",
    "import inspect\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#model save\n",
    "import pickle\n",
    "from pickle import dump, load\n",
    "\n",
    "import tidalUtl.PrpUtl as prp\n",
    "import tidalUtl.EdaUtl as eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/tidalryoku/new-baseline-pytorch-moa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ver1__<br>\n",
    "baseline：CV:0.01465 LB:0.01874<br>\n",
    "__ver2__<br>\n",
    "Hyperopt, 2Layer：CV:0.01460 LB:0.01869<br>\n",
    "__ver3__<br>\n",
    "3Layer：CV:0.01464 LB:0.01868<br>\n",
    "__ver4__<br>\n",
    "MLSMOTE baseline：CV:0.01476 LB:0.01978<br>\n",
    "__ver5__<br>\n",
    "2Layer,refactoring：CV:0.01476 LB:0.01869<br>\n",
    "__ver6__<br>\n",
    "rankGauss：CV:0.01456 LB:0.01865<br>\n",
    "__ver7__<br>\n",
    "labelSmoothing：CV:0.01502 LB:0.01859<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"/home/tidal/ML_Data/MoA/lish-moa\"\n",
    "OUTPUT = \"/home/tidal/ML_Data/MoA/output\"\n",
    "#INPUT = \"/Users/hfuis/ML_Data/MoA/lish-moa\"\n",
    "#OUTPUT = \"/Users/hfuis/ML_Data/MoA/output\"\n",
    "\n",
    "SUBMIT = OUTPUT + \"/submittion/\"\n",
    "SAVEMODEL = OUTPUT + \"/model/pytorchLightning_Efficientnet\"\n",
    "\n",
    "SAVEDEEPINSIGHT = OUTPUT + \"/DeepInsightModel/\"\n",
    "SAVELOGSCALE = OUTPUT + \"/LogScaler/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading\n",
    "trainFeature = pd.read_csv(INPUT + '/train_features.csv')\n",
    "testFeature = pd.read_csv(INPUT + '/test_features.csv')\n",
    "trainTargetScored = pd.read_csv(INPUT + '/train_targets_scored.csv')\n",
    "sample_submission = pd.read_csv(INPUT + '/sample_submission.csv')\n",
    "drug = pd.read_csv(INPUT + '/train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in trainFeature.columns if col.startswith('g-')] #gから始まる列名のセット\n",
    "CELLS = [col for col in trainFeature.columns if col.startswith('c-')] #cから始まる列名のセット\n",
    "category_features = [\"cp_type\", \"cp_dose\"]\n",
    "numeric_features = [c for c in trainFeature.columns if c != \"sig_id\" and c not in category_features]\n",
    "all_features = category_features + numeric_features\n",
    "\n",
    "#efficientnet\n",
    "model_type = \"b3\"\n",
    "pretrained_model = f\"tf_efficientnet_{model_type}_ns\"\n",
    "#experiment_name = f\"deepinsight_efficientnet_v4_{model_type}\"\n",
    "num_workers = 2\n",
    "gpus = [0]\n",
    "\n",
    "if model_type == \"b0\":\n",
    "    batch_size =  128#128\n",
    "    infer_batch_size =  128#256\n",
    "    image_size = 224  # B0\n",
    "    drop_rate = 0.2  # B0\n",
    "    resolution = 224\n",
    "elif model_type == \"b3\":\n",
    "    batch_size = 32\n",
    "    infer_batch_size = 64\n",
    "    image_size = 300  # B3\n",
    "    drop_rate = 0.3  # B3\n",
    "    resolution = 300\n",
    "elif model_type == \"b5\":\n",
    "    batch_size = 8\n",
    "    infer_batch_size = 16\n",
    "    image_size = 456  # B5\n",
    "    drop_rate = 0.4  # B5\n",
    "    resolution = 456\n",
    "elif model_type == \"b7\":\n",
    "    batch_size = 2\n",
    "    infer_batch_size = 4\n",
    "    # image_size = 800  # B7\n",
    "    image_size = 772  # B7\n",
    "    drop_rate = 0.5  # B7\n",
    "    resolution = 772\n",
    "    \n",
    "# DeepInsight Transform\n",
    "perplexity = 5\n",
    "\n",
    "drop_connect_rate = 0.2\n",
    "fc_size = 512\n",
    "\n",
    "# Swap Noise\n",
    "swap_prob = 0.15\n",
    "swap_portion = 0.1\n",
    "\n",
    "SAVEOOF = f\"{OUTPUT}/OOF/Efficientnet{model_type}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed固定\n",
    "def seed_everything(seed=42):\n",
    "    #data取得についてのランダム性固定\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #cudnnによる演算の安定化(評価値の安定)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter\n",
    "param_space = {'hidden_size1': 512, \n",
    "               'hidden_size2': 512, \n",
    "               'dropOutRate1': 0.20393004966355735, \n",
    "               'dropOutRate2': 0.39170486751620137,\n",
    "               'rankGauss_n_quantiles': 488.0393350201078,\n",
    "               'leakyReluSlope': 0.01973893854348531,\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFeatureEnc(trainFeature, testFeature):\n",
    "    train = trainFeature.copy()\n",
    "    test = testFeature.copy()\n",
    "    for df in [train, test]:\n",
    "        df['cp_type'] = df['cp_type'].map({'ctl_vehicle': 0, 'trt_cp': 1})\n",
    "        df['cp_dose'] = df['cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "        df['cp_time'] = df['cp_time'].map({24: 0, 48: 0.5, 72: 1})\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from DeepInsight Transform\n",
    "# https://github.com/alok-ai-lab/DeepInsight/blob/master/pyDeepInsight/image_transformer.py\n",
    "\n",
    "\n",
    "class LogScaler:\n",
    "    \"\"\"Log normalize and scale data\n",
    "\n",
    "    Log normalization and scaling procedure as described as norm-2 in the\n",
    "    DeepInsight paper supplementary information.\n",
    "    \n",
    "    Note: The dimensions of input matrix is (N samples, d features)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._min0 = None\n",
    "        self._max = None\n",
    "\n",
    "    \"\"\"\n",
    "    Use this as a preprocessing step in inference mode.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        # Min. of training set per feature\n",
    "        self._min0 = X.min(axis=0)\n",
    "\n",
    "        # Log normalized X by log(X + _min0 + 1)\n",
    "        X_norm = np.log(\n",
    "            X +\n",
    "            np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n",
    "            1).clip(min=0, max=None)\n",
    "\n",
    "        # Global max. of training set from X_norm\n",
    "        self._max = X_norm.max()\n",
    "\n",
    "    \"\"\"\n",
    "    For training set only.\n",
    "    \"\"\"\n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Min. of training set per feature\n",
    "        self._min0 = X.min(axis=0)\n",
    "\n",
    "        # Log normalized X by log(X + _min0 + 1)\n",
    "        X_norm = np.log(\n",
    "            X +\n",
    "            np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n",
    "            1).clip(min=0, max=None)\n",
    "\n",
    "        # Global max. of training set from X_norm\n",
    "        self._max = X_norm.max()\n",
    "\n",
    "        # Normalized again by global max. of training set\n",
    "        return (X_norm / self._max).clip(0, 1)\n",
    "\n",
    "    \"\"\"\n",
    "    For validation and test set only.\n",
    "    \"\"\"\n",
    "    def transform(self, X, y=None):\n",
    "        # Adjust min. of each feature of X by _min0\n",
    "        for i in range(X.shape[1]):\n",
    "            X[:, i] = X[:, i].clip(min=self._min0[i], max=None)\n",
    "\n",
    "        # Log normalized X by log(X + _min0 + 1)\n",
    "        X_norm = np.log(\n",
    "            X +\n",
    "            np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n",
    "            1).clip(min=0, max=None)\n",
    "\n",
    "        # Normalized again by global max. of training set\n",
    "        return (X_norm / self._max).clip(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepInsight Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テーブルデータをCNN用の画像に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from DeepInsight Transform\n",
    "# https://github.com/alok-ai-lab/DeepInsight/blob/master/pyDeepInsight/image_transformer.py\n",
    "\n",
    "#詳細な説明は以下\n",
    "# https://www.kaggle.com/markpeng/deepinsight-transforming-non-image-data-to-images\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib import pyplot as plt\n",
    "import inspect\n",
    "\n",
    "\n",
    "class DeepInsightTransformer:\n",
    "    \"\"\"Transform features to an image matrix using dimensionality reduction\n",
    "\n",
    "    This class takes in data normalized between 0 and 1 and converts it to a\n",
    "    CNN compatible 'image' matrix\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 feature_extractor='tsne',\n",
    "                 perplexity=30,\n",
    "                 pixels=100,\n",
    "                 random_state=None,\n",
    "                 n_jobs=None):\n",
    "        \"\"\"Generate an ImageTransformer instance\n",
    "\n",
    "        Args:\n",
    "            feature_extractor: string of value ('tsne', 'pca', 'kpca') or a\n",
    "                class instance with method `fit_transform` that returns a\n",
    "                2-dimensional array of extracted features.\n",
    "            pixels: int (square matrix) or tuple of ints (height, width) that\n",
    "                defines the size of the image matrix.\n",
    "            random_state: int or RandomState. Determines the random number\n",
    "                generator, if present, of a string defined feature_extractor.\n",
    "            n_jobs: The number of parallel jobs to run for a string defined\n",
    "                feature_extractor.\n",
    "        \"\"\"\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        if isinstance(feature_extractor, str):\n",
    "            fe = feature_extractor.casefold()\n",
    "            if fe == 'tsne_exact'.casefold():\n",
    "                fe = TSNE(n_components=2,\n",
    "                          metric='cosine',\n",
    "                          perplexity=perplexity,\n",
    "                          n_iter=1000,\n",
    "                          method='exact',\n",
    "                          random_state=self.random_state,\n",
    "                          n_jobs=self.n_jobs)\n",
    "            elif fe == 'tsne'.casefold():\n",
    "                fe = TSNE(n_components=2,\n",
    "                          metric='cosine',\n",
    "                          perplexity=perplexity,\n",
    "                          n_iter=1000,\n",
    "                          method='barnes_hut',\n",
    "                          random_state=self.random_state,\n",
    "                          n_jobs=self.n_jobs)\n",
    "            elif fe == 'pca'.casefold():\n",
    "                fe = PCA(n_components=2, random_state=self.random_state)\n",
    "            elif fe == 'kpca'.casefold():\n",
    "                fe = KernelPCA(n_components=2,\n",
    "                               kernel='rbf',\n",
    "                               random_state=self.random_state,\n",
    "                               n_jobs=self.n_jobs)\n",
    "            else:\n",
    "                raise ValueError((\"Feature extraction method '{}' not accepted\"\n",
    "                                  ).format(feature_extractor))\n",
    "            self._fe = fe\n",
    "        elif hasattr(feature_extractor, 'fit_transform') and \\\n",
    "                inspect.ismethod(feature_extractor.fit_transform):\n",
    "            self._fe = feature_extractor\n",
    "        else:\n",
    "            raise TypeError('Parameter feature_extractor is not a '\n",
    "                            'string nor has method \"fit_transform\"')\n",
    "\n",
    "        if isinstance(pixels, int):\n",
    "            pixels = (pixels, pixels)\n",
    "\n",
    "        # The resolution of transformed image\n",
    "        self._pixels = pixels\n",
    "        self._xrot = None\n",
    "\n",
    "    def fit(self, X, y=None, plot=False):\n",
    "        \"\"\"Train the image transformer from the training set (X)\n",
    "\n",
    "        Args:\n",
    "            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            y: Ignored. Present for continuity with scikit-learn\n",
    "            plot: boolean of whether to produce a scatter plot showing the\n",
    "                feature reduction, hull points, and minimum bounding rectangle\n",
    "\n",
    "        Returns:\n",
    "            self: object\n",
    "        \"\"\"\n",
    "        # Transpose to get (n_features, n_samples)\n",
    "        X = X.T\n",
    "\n",
    "        # Perform dimensionality reduction\n",
    "        x_new = self._fe.fit_transform(X)\n",
    "\n",
    "        # Get the convex hull for the points\n",
    "        chvertices = ConvexHull(x_new).vertices\n",
    "        hull_points = x_new[chvertices]\n",
    "\n",
    "        # Determine the minimum bounding rectangle\n",
    "        mbr, mbr_rot = self._minimum_bounding_rectangle(hull_points)\n",
    "\n",
    "        # Rotate the matrix\n",
    "        # Save the rotated matrix in case user wants to change the pixel size\n",
    "        self._xrot = np.dot(mbr_rot, x_new.T).T\n",
    "\n",
    "        # Determine feature coordinates based on pixel dimension\n",
    "        self._calculate_coords()\n",
    "\n",
    "        # plot rotation diagram if requested\n",
    "        if plot is True:\n",
    "            # Create subplots\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 7), squeeze=False)\n",
    "            ax[0, 0].scatter(x_new[:, 0],\n",
    "                             x_new[:, 1],\n",
    "                             cmap=plt.cm.get_cmap(\"jet\", 10),\n",
    "                             marker=\"x\",\n",
    "                             alpha=1.0)\n",
    "            ax[0, 0].fill(x_new[chvertices, 0],\n",
    "                          x_new[chvertices, 1],\n",
    "                          edgecolor='r',\n",
    "                          fill=False)\n",
    "            ax[0, 0].fill(mbr[:, 0], mbr[:, 1], edgecolor='g', fill=False)\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            plt.show()\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def pixels(self):\n",
    "        \"\"\"The image matrix dimensions\n",
    "\n",
    "        Returns:\n",
    "            tuple: the image matrix dimensions (height, width)\n",
    "\n",
    "        \"\"\"\n",
    "        return self._pixels\n",
    "\n",
    "    @pixels.setter\n",
    "    def pixels(self, pixels):\n",
    "        \"\"\"Set the image matrix dimension\n",
    "\n",
    "        Args:\n",
    "            pixels: int or tuple with the dimensions (height, width)\n",
    "            of the image matrix\n",
    "\n",
    "        \"\"\"\n",
    "        if isinstance(pixels, int):\n",
    "            pixels = (pixels, pixels)\n",
    "        self._pixels = pixels\n",
    "        # recalculate coordinates if already fit\n",
    "        if hasattr(self, '_coords'):\n",
    "            self._calculate_coords()\n",
    "\n",
    "    def _calculate_coords(self):\n",
    "        \"\"\"Calculate the matrix coordinates of each feature based on the\n",
    "        pixel dimensions.\n",
    "        \"\"\"\n",
    "        ax0_coord = np.digitize(self._xrot[:, 0],\n",
    "                                bins=np.linspace(min(self._xrot[:, 0]),\n",
    "                                                 max(self._xrot[:, 0]),\n",
    "                                                 self._pixels[0])) - 1\n",
    "        ax1_coord = np.digitize(self._xrot[:, 1],\n",
    "                                bins=np.linspace(min(self._xrot[:, 1]),\n",
    "                                                 max(self._xrot[:, 1]),\n",
    "                                                 self._pixels[1])) - 1\n",
    "        self._coords = np.stack((ax0_coord, ax1_coord))\n",
    "\n",
    "    def transform(self, X, empty_value=0):\n",
    "        \"\"\"Transform the input matrix into image matrices\n",
    "\n",
    "        Args:\n",
    "            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "                where n_features matches the training set.\n",
    "            empty_value: numeric value to fill elements where no features are\n",
    "                mapped. Default = 0 (although it was 1 in the paper).\n",
    "\n",
    "        Returns:\n",
    "            A list of n_samples numpy matrices of dimensions set by\n",
    "            the pixel parameter\n",
    "        \"\"\"\n",
    "\n",
    "        # Group by location (x1, y1) of each feature\n",
    "        # Tranpose to get (n_features, n_samples)\n",
    "        img_coords = pd.DataFrame(np.vstack(\n",
    "            (self._coords, X.clip(0, 1))).T).groupby(\n",
    "                [0, 1],  # (x1, y1)\n",
    "                as_index=False).mean()\n",
    "\n",
    "        img_matrices = []\n",
    "        blank_mat = np.zeros(self._pixels)\n",
    "        if empty_value != 0:\n",
    "            blank_mat[:] = empty_value\n",
    "        for z in range(2, img_coords.shape[1]):\n",
    "            img_matrix = blank_mat.copy()\n",
    "            img_matrix[img_coords[0].astype(int),\n",
    "                       img_coords[1].astype(int)] = img_coords[z]\n",
    "            img_matrices.append(img_matrix)\n",
    "\n",
    "        return img_matrices\n",
    "\n",
    "    def fit_transform(self, X, empty_value=0):\n",
    "        \"\"\"Train the image transformer from the training set (X) and return\n",
    "        the transformed data.\n",
    "\n",
    "        Args:\n",
    "            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            empty_value: numeric value to fill elements where no features are\n",
    "                mapped. Default = 0 (although it was 1 in the paper).\n",
    "\n",
    "        Returns:\n",
    "            A list of n_samples numpy matrices of dimensions set by\n",
    "            the pixel parameter\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X, empty_value=empty_value)\n",
    "\n",
    "    def feature_density_matrix(self):\n",
    "        \"\"\"Generate image matrix with feature counts per pixel\n",
    "\n",
    "        Returns:\n",
    "            img_matrix (ndarray): matrix with feature counts per pixel\n",
    "        \"\"\"\n",
    "        fdmat = np.zeros(self._pixels)\n",
    "        # Group by location (x1, y1) of each feature\n",
    "        # Tranpose to get (n_features, n_samples)\n",
    "        coord_cnt = (\n",
    "            pd.DataFrame(self._coords.T).assign(count=1).groupby(\n",
    "                [0, 1],  # (x1, y1)\n",
    "                as_index=False).count())\n",
    "        fdmat[coord_cnt[0].astype(int),\n",
    "              coord_cnt[1].astype(int)] = coord_cnt['count']\n",
    "        return fdmat\n",
    "\n",
    "    @staticmethod\n",
    "    def _minimum_bounding_rectangle(hull_points):\n",
    "        \"\"\"Find the smallest bounding rectangle for a set of points.\n",
    "\n",
    "        Modified from JesseBuesking at https://stackoverflow.com/a/33619018\n",
    "        Returns a set of points representing the corners of the bounding box.\n",
    "\n",
    "        Args:\n",
    "            hull_points : an nx2 matrix of hull coordinates\n",
    "\n",
    "        Returns:\n",
    "            (tuple): tuple containing\n",
    "                coords (ndarray): coordinates of the corners of the rectangle\n",
    "                rotmat (ndarray): rotation matrix to align edges of rectangle\n",
    "                    to x and y\n",
    "        \"\"\"\n",
    "\n",
    "        pi2 = np.pi / 2.\n",
    "\n",
    "        # Calculate edge angles\n",
    "        edges = hull_points[1:] - hull_points[:-1]\n",
    "        angles = np.arctan2(edges[:, 1], edges[:, 0])\n",
    "        angles = np.abs(np.mod(angles, pi2))\n",
    "        angles = np.unique(angles)\n",
    "\n",
    "        # Find rotation matrices\n",
    "        rotations = np.vstack([\n",
    "            np.cos(angles),\n",
    "            np.cos(angles - pi2),\n",
    "            np.cos(angles + pi2),\n",
    "            np.cos(angles)\n",
    "        ]).T\n",
    "        rotations = rotations.reshape((-1, 2, 2))\n",
    "\n",
    "        # Apply rotations to the hull\n",
    "        rot_points = np.dot(rotations, hull_points.T)\n",
    "\n",
    "        # Find the bounding points\n",
    "        min_x = np.nanmin(rot_points[:, 0], axis=1)\n",
    "        max_x = np.nanmax(rot_points[:, 0], axis=1)\n",
    "        min_y = np.nanmin(rot_points[:, 1], axis=1)\n",
    "        max_y = np.nanmax(rot_points[:, 1], axis=1)\n",
    "\n",
    "        # Find the box with the best area\n",
    "        areas = (max_x - min_x) * (max_y - min_y)\n",
    "        best_idx = np.argmin(areas)\n",
    "\n",
    "        # Return the best box\n",
    "        x1 = max_x[best_idx]\n",
    "        x2 = min_x[best_idx]\n",
    "        y1 = max_y[best_idx]\n",
    "        y2 = min_y[best_idx]\n",
    "        rotmat = rotations[best_idx]\n",
    "\n",
    "        # Generate coordinates\n",
    "        coords = np.zeros((4, 2))\n",
    "        coords[0] = np.dot([x1, y2], rotmat)\n",
    "        coords[1] = np.dot([x2, y2], rotmat)\n",
    "        coords[2] = np.dot([x2, y1], rotmat)\n",
    "        coords[3] = np.dot([x1, y1], rotmat)\n",
    "\n",
    "        return coords, rotmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train,testにターゲット値も連結__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collecting(trainFeature, testFeature, trainTargetScored):\n",
    "    #Pkey(sig_id)でfeatureとtargetを内部結合。\n",
    "    train = trainFeature.merge(trainTargetScored, on='sig_id')\n",
    "    test = testFeature.merge(sample_submission, on='sig_id')\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(param, trainFeature, testFeature, trainTargetScored):\n",
    "    \n",
    "    train, test = categoryFeatureEnc(trainFeature, testFeature)\n",
    "    \n",
    "    train, test = Collecting(train, test, trainTargetScored)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.4 ms, sys: 44 ms, total: 97.4 ms\n",
      "Wall time: 96.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainVsl, testVsl = preprocessing(param_space, trainFeature, testFeature, trainTargetScored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 1082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  cp_type  cp_time  cp_dose     g-0     g-1     g-2  \\\n",
       "0      id_000644bb2        1      0.0        0  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc        1      1.0        0  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a        1      0.5        0  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391        1      0.5        0 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3        1      1.0        1 -0.3254 -0.4009  0.9700   \n",
       "...             ...      ...      ...      ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed        1      0.0        1  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c        1      0.0        1 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4        0      0.5        1  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c        1      0.0        0  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b        1      1.0        0 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "          g-3     g-4     g-5  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ...                                      0   \n",
       "1      0.0604  1.0190  0.5207  ...                                      0   \n",
       "2     -0.0764 -0.0323  1.2390  ...                                      0   \n",
       "3      0.5288  4.0620 -0.8095  ...                                      0   \n",
       "4      0.6919  1.4180 -0.8244  ...                                      0   \n",
       "...       ...     ...     ...  ...                                    ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ...                                      0   \n",
       "23810  0.9905 -0.7178  0.6621  ...                                      0   \n",
       "23811 -0.7389  0.5505 -0.0159  ...                                      0   \n",
       "23812  0.2044  0.8531 -0.0343  ...                                      0   \n",
       "23813  0.7952 -0.3611 -3.6750  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 1082 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>-0.5743</td>\n",
       "      <td>3.3930</td>\n",
       "      <td>-0.6202</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>1.6240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5885</td>\n",
       "      <td>-0.2548</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3985</td>\n",
       "      <td>-0.1554</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>-0.6813</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0960</td>\n",
       "      <td>-1.7750</td>\n",
       "      <td>-0.3977</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>-1.3350</td>\n",
       "      <td>-0.2207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5174</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>-0.0428</td>\n",
       "      <td>-0.0800</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 1082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  cp_type  cp_time  cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0     id_0004d9e33        1      0.0        0 -0.5458  0.1306 -0.5135  0.4408   \n",
       "1     id_001897cda        1      1.0        0 -0.1829  0.2320  1.2080 -0.4522   \n",
       "2     id_002429b5b        0      0.0        0  0.1852 -0.1404 -0.3911  0.1310   \n",
       "3     id_00276f245        1      0.0        1  0.4828  0.1955  0.3825  0.4244   \n",
       "4     id_0027f1083        1      0.5        0 -0.3979 -1.2680  1.9130  0.2057   \n",
       "...            ...      ...      ...      ...     ...     ...     ...     ...   \n",
       "3977  id_ff7004b87        1      0.0        0  0.4571 -0.5743  3.3930 -0.6202   \n",
       "3978  id_ff925dd0d        1      0.0        0 -0.5885 -0.2548  2.5850  0.3456   \n",
       "3979  id_ffb710450        1      1.0        0 -0.3985 -0.1554  0.2677 -0.6813   \n",
       "3980  id_ffbb869f2        1      0.5        1 -1.0960 -1.7750 -0.3977  1.0160   \n",
       "3981  id_ffd5800b6        1      1.0        0 -0.5174  0.2953  0.3286 -0.0428   \n",
       "\n",
       "         g-4     g-5  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0     1.5500 -0.1644  ...                                    0.5   \n",
       "1    -0.3652 -0.3319  ...                                    0.5   \n",
       "2    -1.4380  0.2455  ...                                    0.5   \n",
       "3    -0.5855 -1.2020  ...                                    0.5   \n",
       "4    -0.5864 -0.0166  ...                                    0.5   \n",
       "...      ...     ...  ...                                    ...   \n",
       "3977  0.8557  1.6240  ...                                    0.5   \n",
       "3978  0.4401  0.3107  ...                                    0.5   \n",
       "3979  0.0152  0.4791  ...                                    0.5   \n",
       "3980 -1.3350 -0.2207  ...                                    0.5   \n",
       "3981 -0.0800  0.8702  ...                                    0.5   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0              0.5              0.5                0.5   \n",
       "1              0.5              0.5                0.5   \n",
       "2              0.5              0.5                0.5   \n",
       "3              0.5              0.5                0.5   \n",
       "4              0.5              0.5                0.5   \n",
       "...            ...              ...                ...   \n",
       "3977           0.5              0.5                0.5   \n",
       "3978           0.5              0.5                0.5   \n",
       "3979           0.5              0.5                0.5   \n",
       "3980           0.5              0.5                0.5   \n",
       "3981           0.5              0.5                0.5   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                           0.5                                    0.5   \n",
       "1                           0.5                                    0.5   \n",
       "2                           0.5                                    0.5   \n",
       "3                           0.5                                    0.5   \n",
       "4                           0.5                                    0.5   \n",
       "...                         ...                                    ...   \n",
       "3977                        0.5                                    0.5   \n",
       "3978                        0.5                                    0.5   \n",
       "3979                        0.5                                    0.5   \n",
       "3980                        0.5                                    0.5   \n",
       "3981                        0.5                                    0.5   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                 0.5        0.5                         0.5            0.5  \n",
       "1                 0.5        0.5                         0.5            0.5  \n",
       "2                 0.5        0.5                         0.5            0.5  \n",
       "3                 0.5        0.5                         0.5            0.5  \n",
       "4                 0.5        0.5                         0.5            0.5  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977              0.5        0.5                         0.5            0.5  \n",
       "3978              0.5        0.5                         0.5            0.5  \n",
       "3979              0.5        0.5                         0.5            0.5  \n",
       "3980              0.5        0.5                         0.5            0.5  \n",
       "3981              0.5        0.5                         0.5            0.5  \n",
       "\n",
       "[3982 rows x 1082 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>-0.8121</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>-0.3246</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.8086</td>\n",
       "      <td>-0.9798</td>\n",
       "      <td>-0.2084</td>\n",
       "      <td>-0.1224</td>\n",
       "      <td>-0.2715</td>\n",
       "      <td>0.3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.7592</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1105</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>-0.2012</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>1.5230</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>-0.6290</td>\n",
       "      <td>0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3890</td>\n",
       "      <td>-1.7450</td>\n",
       "      <td>-6.6300</td>\n",
       "      <td>-4.0950</td>\n",
       "      <td>-7.3860</td>\n",
       "      <td>-1.4160</td>\n",
       "      <td>-3.5770</td>\n",
       "      <td>-0.4775</td>\n",
       "      <td>-2.1500</td>\n",
       "      <td>-4.2520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2  \\\n",
       "0      id_000644bb2       trt_cp       24      D1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc       trt_cp       72      D1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a       trt_cp       48      D1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391       trt_cp       48      D1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3       trt_cp       72      D2 -0.3254 -0.4009  0.9700   \n",
       "...             ...          ...      ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed       trt_cp       24      D2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c       trt_cp       24      D2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4  ctl_vehicle       48      D2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c       trt_cp       24      D1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b       trt_cp       72      D1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "          g-3     g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912   \n",
       "1      0.0604  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957   \n",
       "2     -0.0764 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240   \n",
       "3      0.5288  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632   \n",
       "4      0.6919  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ...  0.1969  0.0262 -0.8121  0.3434  0.5372   \n",
       "23810  0.9905 -0.7178  0.6621  ...  0.4286  0.4426  0.0423 -0.3195 -0.8086   \n",
       "23811 -0.7389  0.5505 -0.0159  ...  0.5409  0.3755  0.7343  0.2807  0.4116   \n",
       "23812  0.2044  0.8531 -0.0343  ... -0.1105  0.4258 -0.2012  0.1506  1.5230   \n",
       "23813  0.7952 -0.3611 -3.6750  ... -3.3890 -1.7450 -6.6300 -4.0950 -7.3860   \n",
       "\n",
       "         c-95    c-96    c-97    c-98    c-99  \n",
       "0      0.6584 -0.3981  0.2139  0.3801  0.4176  \n",
       "1      0.4899  0.1522  0.1241  0.6077  0.7371  \n",
       "2     -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3     -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4     -0.3031  0.1094  0.2885 -0.3786  0.7125  \n",
       "...       ...     ...     ...     ...     ...  \n",
       "23809 -0.3246  0.0631  0.9171  0.5258  0.4680  \n",
       "23810 -0.9798 -0.2084 -0.1224 -0.2715  0.3689  \n",
       "23811  0.6422  0.2256  0.7592  0.6656  0.3808  \n",
       "23812  0.7101  0.1732  0.7015 -0.6290  0.0740  \n",
       "23813 -1.4160 -3.5770 -0.4775 -2.1500 -4.2520  \n",
       "\n",
       "[23814 rows x 876 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>-0.1430</td>\n",
       "      <td>-0.2067</td>\n",
       "      <td>-0.2303</td>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>-0.1852</td>\n",
       "      <td>-1.0310</td>\n",
       "      <td>-1.3670</td>\n",
       "      <td>-0.3690</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.4764</td>\n",
       "      <td>-1.3810</td>\n",
       "      <td>-0.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>-1.3840</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>-1.9530</td>\n",
       "      <td>-1.0140</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-0.1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>-0.1784</td>\n",
       "      <td>-1.1200</td>\n",
       "      <td>-0.4325</td>\n",
       "      <td>-0.9005</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-0.1305</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>-0.5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-0.1580</td>\n",
       "      <td>1.0510</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>-0.2962</td>\n",
       "      <td>-0.5313</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>1.8380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>-0.5743</td>\n",
       "      <td>3.3930</td>\n",
       "      <td>-0.6202</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>1.6240</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1790</td>\n",
       "      <td>-0.6422</td>\n",
       "      <td>-0.4367</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>-0.6539</td>\n",
       "      <td>-0.4791</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>-1.1280</td>\n",
       "      <td>-0.4167</td>\n",
       "      <td>-0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5885</td>\n",
       "      <td>-0.2548</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>-0.5888</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>1.2730</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>-0.2790</td>\n",
       "      <td>-0.0131</td>\n",
       "      <td>-0.0934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3985</td>\n",
       "      <td>-0.1554</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>-0.6813</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4418</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>-0.1862</td>\n",
       "      <td>0.4049</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.4666</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>-0.4205</td>\n",
       "      <td>-0.1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.0960</td>\n",
       "      <td>-1.7750</td>\n",
       "      <td>-0.3977</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>-1.3350</td>\n",
       "      <td>-0.2207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>-0.4473</td>\n",
       "      <td>-0.8192</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>-0.2618</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>-0.0484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5174</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>-0.0428</td>\n",
       "      <td>-0.0800</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>-0.0507</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>-0.4041</td>\n",
       "      <td>-0.4948</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>-0.1356</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2  \\\n",
       "0     id_0004d9e33       trt_cp       24      D1 -0.5458  0.1306 -0.5135   \n",
       "1     id_001897cda       trt_cp       72      D1 -0.1829  0.2320  1.2080   \n",
       "2     id_002429b5b  ctl_vehicle       24      D1  0.1852 -0.1404 -0.3911   \n",
       "3     id_00276f245       trt_cp       24      D2  0.4828  0.1955  0.3825   \n",
       "4     id_0027f1083       trt_cp       48      D1 -0.3979 -1.2680  1.9130   \n",
       "...            ...          ...      ...     ...     ...     ...     ...   \n",
       "3977  id_ff7004b87       trt_cp       24      D1  0.4571 -0.5743  3.3930   \n",
       "3978  id_ff925dd0d       trt_cp       24      D1 -0.5885 -0.2548  2.5850   \n",
       "3979  id_ffb710450       trt_cp       72      D1 -0.3985 -0.1554  0.2677   \n",
       "3980  id_ffbb869f2       trt_cp       48      D2 -1.0960 -1.7750 -0.3977   \n",
       "3981  id_ffd5800b6       trt_cp       72      D1 -0.5174  0.2953  0.3286   \n",
       "\n",
       "         g-3     g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94  \\\n",
       "0     0.4408  1.5500 -0.1644  ...  0.0981  0.7978 -0.1430 -0.2067 -0.2303   \n",
       "1    -0.4522 -0.3652 -0.3319  ... -0.1190 -0.1852 -1.0310 -1.3670 -0.3690   \n",
       "2     0.1310 -1.4380  0.2455  ... -0.2261  0.3370 -1.3840  0.8604 -1.9530   \n",
       "3     0.4244 -0.5855 -1.2020  ...  0.1260  0.1570 -0.1784 -1.1200 -0.4325   \n",
       "4     0.2057 -0.5864 -0.0166  ...  0.4965  0.7578 -0.1580  1.0510  0.5742   \n",
       "...      ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "3977 -0.6202  0.8557  1.6240  ... -1.1790 -0.6422 -0.4367  0.0159 -0.6539   \n",
       "3978  0.3456  0.4401  0.3107  ...  0.0210  0.5780 -0.5888  0.8057  0.9312   \n",
       "3979 -0.6813  0.0152  0.4791  ...  0.4418  0.9153 -0.1862  0.4049  0.9568   \n",
       "3980  1.0160 -1.3350 -0.2207  ...  0.3079 -0.4473 -0.8192  0.7785  0.3133   \n",
       "3981 -0.0428 -0.0800  0.8702  ...  0.0363  0.1708  0.5939 -0.0507  0.2811   \n",
       "\n",
       "        c-95    c-96    c-97    c-98    c-99  \n",
       "0    -0.1193  0.0210 -0.0502  0.1510 -0.7750  \n",
       "1    -0.5382  0.0359 -0.4764 -1.3810 -0.7300  \n",
       "2    -1.0140  0.8662  1.0160  0.4924 -0.1942  \n",
       "3    -0.9005  0.8131 -0.1305  0.5645 -0.5809  \n",
       "4     1.0900 -0.2962 -0.5313  0.9931  1.8380  \n",
       "...      ...     ...     ...     ...     ...  \n",
       "3977 -0.4791 -1.2680 -1.1280 -0.4167 -0.6600  \n",
       "3978  1.2730  0.2614 -0.2790 -0.0131 -0.0934  \n",
       "3979  0.4666  0.0461  0.5888 -0.4205 -0.1504  \n",
       "3980  0.1286 -0.2618  0.5074  0.7430 -0.0484  \n",
       "3981 -0.4041 -0.4948  0.0757 -0.1356  0.5280  \n",
       "\n",
       "[3982 rows x 876 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config about Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configは辞書化しておく。\n",
    "def Config_about_Fitting(train, test, target, folds):\n",
    "    confFitting = {}\n",
    "    \n",
    "    #Fitするときに\"y\"として使う列の列名配列\n",
    "    confFitting[\"target_cols\"] = target.drop('sig_id', axis=1).columns.values.tolist()\n",
    "    #Fitするときに\"X\"として使う列の列名配列\n",
    "    #kfold, id等はここで削除。\n",
    "    feature_cols = [c for c in folds.columns if c not in confFitting[\"target_cols\"]]\n",
    "    confFitting[\"feature_cols\"] = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "    #特徴量、ターゲットのサイズ\n",
    "    confFitting[\"num_features\"]=len(confFitting[\"feature_cols\"])\n",
    "    confFitting[\"num_targets\"]=len(confFitting[\"target_cols\"])\n",
    "    \n",
    "    return confFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fitTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitPreprocessingModel(param, train, test, valid, fold, seed):\n",
    "    \n",
    "    #LOG SCALER\n",
    "    train_all_features = train[all_features].copy().values\n",
    "    valid_all_features = valid[all_features].copy().values\n",
    "    test_all_features = test[all_features].copy().values\n",
    "    \n",
    "    all_scaler = LogScaler()\n",
    "    train_all_features = all_scaler.fit_transform(train_all_features)\n",
    "    test_all_features = all_scaler.transform(test_all_features)\n",
    "    valid_all_features = all_scaler.transform(valid_all_features)\n",
    "    \n",
    "    train[all_features] = train_all_features\n",
    "    test[all_features] = test_all_features\n",
    "    valid[all_features] = valid_all_features\n",
    "    \n",
    "    dump(all_scaler, open(f\"{SAVELOGSCALE}/seed{seed}_fold{fold}_LogScaleTransformer.pkl\", 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    #DeepInsight\n",
    "    all_it = DeepInsightTransformer(feature_extractor='tsne_exact',\n",
    "                                    pixels=resolution,\n",
    "                                    perplexity=5,\n",
    "                                    random_state=1120,\n",
    "                                    n_jobs=-1)\n",
    "    all_it.fit(train_all_features, plot=False)\n",
    "    \n",
    "    dump(all_it, open(f\"{SAVEDEEPINSIGHT}/seed{seed}_fold{fold}_DeepInsightTransformer.pkl\", 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return all_scaler, all_it, train, test, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessingLoadTransform(param, test, fold, seed):\n",
    "    test_all_features = test[all_features].copy().values\n",
    "    \n",
    "    #LOG SCALER\n",
    "    all_scaler = load(open(f\"{SAVELOGSCALE}/seed{seed}_fold{fold}_LogScaleTransformer.pkl\", 'rb'))\n",
    "    test_all_features = all_scaler.transform(test_all_features)\n",
    "    \n",
    "    #DeepInsight\n",
    "    all_it = load(open(f\"{SAVEDEEPINSIGHT}/seed{seed}_fold{fold}_DeepInsightTransformer.pkl\", 'rb'))\n",
    "    \n",
    "    return all_scaler, all_it, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoAImageSwapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 features,\n",
    "                 labels,\n",
    "                 transformer,\n",
    "                 swap_prob=0.15,\n",
    "                 swap_portion=0.1):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transformer = transformer\n",
    "        self.swap_prob = swap_prob\n",
    "        self.swap_portion = swap_portion\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        normalized = self.features[index, :]\n",
    "\n",
    "        # Swap row features randomly\n",
    "        normalized = self.add_swap_noise(index, normalized)\n",
    "\n",
    "        normalized = np.expand_dims(normalized, axis=0)\n",
    "\n",
    "        # Note: we are setting empty_value=1 to follow the setup in the paper\n",
    "        image = self.transformer.transform(normalized, empty_value=1)[0]\n",
    "\n",
    "        # Resize to target size\n",
    "        gene_cht = cv2.resize(image, (image_size, image_size),\n",
    "                              interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert to 3 channels\n",
    "        image = np.repeat(gene_cht[np.newaxis, :, :], 3, axis=0)\n",
    "\n",
    "        return {\"x\": image, \"y\": self.labels[index, :]}\n",
    "\n",
    "    def add_swap_noise(self, index, X):\n",
    "        if np.random.rand() < self.swap_prob:\n",
    "            swap_index = np.random.randint(self.features.shape[0], size=1)[0]\n",
    "            # Select only gene expression and cell viability features\n",
    "            swap_features = np.random.choice(\n",
    "                np.array(range(3, self.features.shape[1])),\n",
    "                size=int(self.features.shape[1] * self.swap_portion),\n",
    "                replace=False)\n",
    "            X[swap_features] = self.features[swap_index, swap_features]\n",
    "\n",
    "        return X\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "class MoAImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels, transformer):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        normalized = self.features[index, :]\n",
    "        normalized = np.expand_dims(normalized, axis=0)\n",
    "\n",
    "        # Note: we are setting empty_value=1 to follow the setup in the paper\n",
    "        image = self.transformer.transform(normalized, empty_value=1)[0]\n",
    "\n",
    "        # Resize to target size\n",
    "        gene_cht = cv2.resize(image, (image_size, image_size),\n",
    "                              interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert to 3 channels\n",
    "        image = np.repeat(gene_cht[np.newaxis, :, :], 3, axis=0)\n",
    "\n",
    "        return {\"x\": image, \"y\": self.labels[index, :]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels, transformer):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        normalized = self.features[index, :]\n",
    "        normalized = np.expand_dims(normalized, axis=0)\n",
    "\n",
    "        # Note: we are setting empty_value=1 to follow the setup in the paper\n",
    "        image = self.transformer.transform(normalized, empty_value=1)[0]\n",
    "\n",
    "        # Resize to target size\n",
    "        gene_cht = cv2.resize(image, (image_size, image_size),\n",
    "                              interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert to 3 channels\n",
    "        image = np.repeat(gene_cht[np.newaxis, :, :], 3, axis=0)\n",
    "\n",
    "        return {\"x\": image, \"y\": -1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/rwightman/gen-efficientnet-pytorch/blob/master/geffnet/efficientnet_builder.py#L672\n",
    "def initialize_weight_goog(m, n='', fix_group_fanout=True):\n",
    "    # weight init as per Tensorflow Official impl\n",
    "    # https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_model.py\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        if fix_group_fanout:\n",
    "            fan_out //= m.groups\n",
    "        m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1.0)\n",
    "        m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        fan_out = m.weight.size(0)  # fan-out\n",
    "        fan_in = 0\n",
    "        if 'routing_fn' in n:\n",
    "            fan_in = m.weight.size(1)\n",
    "        init_range = 1.0 / math.sqrt(fan_in + fan_out)\n",
    "        m.weight.data.uniform_(-init_range, init_range)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def initialize_weight_default(m, n=''):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1.0)\n",
    "        m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight,\n",
    "                                 mode='fan_in',\n",
    "                                 nonlinearity='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "    def forward(self, x, target, smoothing=0.001):\n",
    "        confidence = 1. - smoothing\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        bcs_loss = nn.BCEWithLogitsLoss()(x, target)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = confidence * bcs_loss + smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "#nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoAEfficientNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_model_name,\n",
    "            training_set=(None, None),  # tuple\n",
    "            valid_set=(None, None),  # tuple\n",
    "            test_set=None,\n",
    "            transformer=None,\n",
    "            num_classes=206,\n",
    "            in_chans=3,\n",
    "            drop_rate=0.,\n",
    "            drop_connect_rate=0.,\n",
    "            fc_size=512,\n",
    "            learning_rate=1e-3,\n",
    "            weight_init='goog'):\n",
    "        super(MoAEfficientNet, self).__init__()\n",
    "\n",
    "        self.train_data, self.train_labels = training_set\n",
    "        self.valid_data, self.valid_labels = valid_set\n",
    "        self.test_data = test_set\n",
    "        self.transformer = transformer\n",
    "\n",
    "        self.backbone = getattr(geffnet, pretrained_model)(\n",
    "            pretrained=True,\n",
    "            in_chans=in_chans,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_connect_rate=drop_connect_rate,\n",
    "            weight_init=weight_init)\n",
    "\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(self.backbone.classifier.in_features, fc_size,\n",
    "                      bias=True), nn.ELU(),\n",
    "            nn.Linear(fc_size, num_classes, bias=True))\n",
    "\n",
    "        if self.training:\n",
    "            for m in self.backbone.classifier.modules():\n",
    "                initialize_weight_goog(m)\n",
    "\n",
    "        # Save passed hyperparameters\n",
    "        self.save_hyperparameters(\"pretrained_model_name\", \"num_classes\",\n",
    "                                  \"in_chans\", \"drop_rate\", \"drop_connect_rate\",\n",
    "                                  \"weight_init\", \"fc_size\", \"learning_rate\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[\"x\"]\n",
    "        y = batch[\"y\"]\n",
    "        x = x.float()\n",
    "        y = y.type_as(x)\n",
    "        logits = self(x)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y, reduction=\"mean\")\n",
    "        #loss = LabelSmoothingCrossEntropy()\n",
    "\n",
    "        self.log('train_loss',\n",
    "                 loss,\n",
    "                 on_step=True,\n",
    "                 on_epoch=True,\n",
    "                 prog_bar=True,\n",
    "                 logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch[\"x\"]\n",
    "        y = batch[\"y\"]\n",
    "        x = x.float()\n",
    "        y = y.type_as(x)\n",
    "        logits = self(x)\n",
    "\n",
    "        val_loss = F.binary_cross_entropy_with_logits(logits,\n",
    "                                                      y,\n",
    "                                                      reduction=\"mean\")\n",
    "\n",
    "        self.log('val_loss',\n",
    "                 val_loss,\n",
    "                 on_step=True,\n",
    "                 on_epoch=True,\n",
    "                 prog_bar=True,\n",
    "                 logger=True)\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = batch[\"x\"]\n",
    "        y = batch[\"y\"]\n",
    "        x = x.float()\n",
    "        y = y.type_as(x)\n",
    "        logits = self(x)\n",
    "        return {\"pred_logits\": logits}\n",
    "\n",
    "    def test_epoch_end(self, output_results):\n",
    "        all_outputs = torch.cat([out[\"pred_logits\"] for out in output_results],\n",
    "                                dim=0)\n",
    "        print(\"Logits:\", all_outputs)\n",
    "        pred_probs = F.sigmoid(all_outputs).detach().cpu().numpy()\n",
    "        print(\"Predictions: \", pred_probs)\n",
    "        return {\"pred_probs\": pred_probs}\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        #         self.train_dataset = MoAImageDataset(self.train_data,\n",
    "        #                                              self.train_labels,\n",
    "        #                                              self.transformer)\n",
    "        self.train_dataset = MoAImageSwapDataset(self.train_data,\n",
    "                                                 self.train_labels,\n",
    "                                                 self.transformer,\n",
    "                                                 swap_prob=swap_prob,\n",
    "                                                 swap_portion=swap_portion)\n",
    "\n",
    "        self.val_dataset = MoAImageDataset(self.valid_data, self.valid_labels,\n",
    "                                           self.transformer)\n",
    "\n",
    "        self.test_dataset = TestDataset(self.test_data, None, self.transformer)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataloader = DataLoader(self.train_dataset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      pin_memory=True,\n",
    "                                      drop_last=False)\n",
    "        print(f\"Train iterations: {len(train_dataloader)}\")\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataloader = DataLoader(self.val_dataset,\n",
    "                                    batch_size=infer_batch_size,\n",
    "                                    shuffle=False,\n",
    "                                    num_workers=num_workers,\n",
    "                                    pin_memory=True,\n",
    "                                    drop_last=False)\n",
    "        print(f\"Validate iterations: {len(val_dataloader)}\")\n",
    "        return val_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_dataloader = DataLoader(self.test_dataset,\n",
    "                                     batch_size=infer_batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=num_workers,\n",
    "                                     pin_memory=True,\n",
    "                                     drop_last=False)\n",
    "        print(f\"Test iterations: {len(test_dataloader)}\")\n",
    "        return test_dataloader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        print(f\"Initial Learning Rate: {self.hparams.learning_rate:.6f}\")\n",
    "        optimizer = optim.Adam(self.parameters(),\n",
    "                               lr=self.hparams.learning_rate,\n",
    "                               weight_decay=1e-5)\n",
    "\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                         T_max=20,\n",
    "                                                         eta_min=0,\n",
    "                                                         last_epoch=-1)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds(train, target):\n",
    "    folds = train.copy()\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "    \n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "        folds.loc[v_idx, 'kfold'] = int(f)\n",
    "    \n",
    "    folds['kfold'] = folds['kfold'].astype(int)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds_drug_id(train, target):\n",
    "    ###drug_idを考慮####\n",
    "    \n",
    "    targets = target.columns[1:]\n",
    "    \n",
    "    # foldsにdrug_id付与\n",
    "    folds = train.copy()\n",
    "    folds = folds.merge(drug, on='sig_id', how='left') \n",
    "    \n",
    "    # LOCATE DRUGS\n",
    "    vc = folds.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc<=18].index.sort_values()\n",
    "    vc2 = vc.loc[vc>18].index.sort_values()\n",
    "    \n",
    "    # STRATIFY DRUGS 18X OR LESS\n",
    "    dct1 = {}; dct2 = {}\n",
    "    skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, \n",
    "              random_state=42)\n",
    "    tmp = folds.groupby('drug_id')[targets].mean().loc[vc1]\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.index[idxV].values}\n",
    "        dct1.update(dd)\n",
    "    \n",
    "    # STRATIFY DRUGS MORE THAN 18X\n",
    "    skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, \n",
    "              random_state=42)\n",
    "    tmp = folds.loc[folds.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "        dct2.update(dd)\n",
    "    \n",
    "    # ASSIGN NFOLDS\n",
    "    folds['kfold'] = folds.drug_id.map(dct1)\n",
    "    folds.loc[folds.kfold.isna(),'kfold'] =\\\n",
    "        folds.loc[folds.kfold.isna(),'sig_id'].map(dct2)\n",
    "    folds.kfold = folds.kfold.astype('int8')\n",
    "    \n",
    "    folds = folds.drop('drug_id', axis=1)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 474 ms, sys: 137 ms, total: 611 ms\n",
      "Wall time: 609 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1083 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  cp_type  cp_time  cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2        1      0.0        0  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc        1      1.0        0  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a        1      0.5        0  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391        1      0.5        0 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3        1      1.0        1 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0 -0.1944 -1.0120  ...             0                0                  0   \n",
       "1  1.0190  0.5207  ...             0                0                  0   \n",
       "2 -0.0323  1.2390  ...             0                0                  0   \n",
       "3  4.0620 -0.8095  ...             0                0                  0   \n",
       "4  1.4180 -0.8244  ...             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0                0          0                           0              0   \n",
       "1                0          0                           0              0   \n",
       "2                0          0                           0              0   \n",
       "3                0          0                           0              0   \n",
       "4                0          0                           0              0   \n",
       "\n",
       "   kfold  \n",
       "0      4  \n",
       "1      2  \n",
       "2      4  \n",
       "3      0  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 1083 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Preprocessing Data\n",
    "trainVsl, testVsl = preprocessing(param_space, trainFeature, testFeature, trainTargetScored)\n",
    "#CV folds\n",
    "foldsVsl = CV_folds_drug_id(trainVsl, trainTargetScored)\n",
    "\n",
    "foldsVsl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(confFitting, Tester, fold, seed, param,\n",
    "                 folds, train, test, target):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = folds\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[confFitting[\"feature_cols\"]], train_df[confFitting[\"target_cols\"]].values\n",
    "    x_valid, y_valid =  valid_df[confFitting[\"feature_cols\"]], valid_df[confFitting[\"target_cols\"]].values\n",
    "    x_test = test[confFitting[\"feature_cols\"]]\n",
    "    \n",
    "    #データセットをイメージ化するトランスフォーマー。\n",
    "    #ここでLogScaleも実施。\n",
    "    all_scaler, all_it, x_train, x_test, x_valid = fitPreprocessingModel(param_space, x_train, x_test, x_valid, fold, seed)\n",
    "    x_train = x_train.values\n",
    "    x_valid = x_valid.values\n",
    "    x_test = x_test.values\n",
    "    \n",
    "    #model class 定義\n",
    "    model = MoAEfficientNet(\n",
    "        pretrained_model_name=pretrained_model,\n",
    "        training_set=(x_train, y_train),  # tuple\n",
    "        valid_set=(x_valid, y_valid),  # tuple\n",
    "        test_set=np.concatenate([x_valid, x_test], 0), #予測用のデータセット\n",
    "        transformer=all_it,\n",
    "        drop_rate=drop_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        fc_size=fc_size,\n",
    "        weight_init='goog')\n",
    "    \n",
    "    #データセット定義(データセットをイメージ化)\n",
    "    model.setup()\n",
    "    \n",
    "    #学習クラス\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=SAVEMODEL,\n",
    "        max_epochs=EPOCHS,\n",
    "        logger=False,\n",
    "        gpus=gpus,\n",
    "        distributed_backend=\"dp\",  # multiple-gpus, 1 machine\n",
    "        precision=16)\n",
    "    \n",
    "    #学習\n",
    "    trainer.fit(model)\n",
    "    \n",
    "    #save model\n",
    "    trainer.save_checkpoint(f\"{SAVEMODEL}/model{model_type}_SEED{seed}_FOLD{fold}.ckpt\")\n",
    "    \n",
    "    #予測\n",
    "    output = trainer.test(model, verbose=False)[0]\n",
    "    allPred = output[\"pred_probs\"]\n",
    "    \n",
    "    #out of fold\n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    oof[val_idx] = allPred[0:x_valid.shape[0]]\n",
    "    \n",
    "    #Predictions\n",
    "    predictions = allPred[x_valid.shape[0]:]\n",
    "    \n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(Tester, NFOLDS, seed, param,\n",
    "               folds, train, test, target, confFitting):\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        oof_, pred_ = run_training(confFitting, Tester, fold, seed, param,\n",
    "                                   folds, train, test, target)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " def CV_Evaluation(confFitting, oof, train, target):\n",
    "    #CV score : OOFの評価結果。\n",
    "    #OOF(学習モデルによるtrain dataの予測)\n",
    "    train[confFitting[\"target_cols\"]] = oof\n",
    "    #target(予測結果)：ここで処理「cp_type = ctl_vehicleのレコードを削除」で抜けたところに0を入れている。\n",
    "    valid_results = trainTargetScored.drop(columns=confFitting[\"target_cols\"]).merge(train[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    \n",
    "    y_true = trainTargetScored[confFitting[\"target_cols\"]].values\n",
    "    y_pred = valid_results[confFitting[\"target_cols\"]].values\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(confFitting[\"num_targets\"]):\n",
    "        score_ = log_loss(y_true[:, i], y_pred[:, i]) #問題の評価指標によって変わる。\n",
    "        score += score_ / target.shape[1]\n",
    "        \n",
    "    print(\"CV log_loss: \", score)\n",
    "    \n",
    "    #OOF save\n",
    "    np.save(SAVEOOF + 'oof', y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特になし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Submit(confFitting, predictions, test):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Exec(param):\n",
    "    \n",
    "    #Tester(True/False)\n",
    "    Tester = True\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds_drug_id(train, trainTargetScored)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, trainTargetScored, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [42]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, trainTargetScored, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, trainTargetScored)\n",
    "    \n",
    "    # 課題提出\n",
    "    Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 42 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 11 M  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 76\n",
      "Train iterations: 594                                                 \n",
      "Epoch 0:  89%|████████▊ | 594/670 [03:37<00:27,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 595/670 [03:37<00:27,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  89%|████████▉ | 596/670 [03:37<00:27,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  89%|████████▉ | 597/670 [03:37<00:26,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  89%|████████▉ | 598/670 [03:38<00:26,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  89%|████████▉ | 599/670 [03:38<00:25,  2.75it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  90%|████████▉ | 600/670 [03:38<00:25,  2.75it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  90%|████████▉ | 601/670 [03:38<00:25,  2.75it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  90%|████████▉ | 602/670 [03:38<00:24,  2.75it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  90%|█████████ | 603/670 [03:38<00:24,  2.76it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  90%|█████████ | 604/670 [03:39<00:23,  2.76it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  90%|█████████ | 605/670 [03:39<00:23,  2.76it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  90%|█████████ | 606/670 [03:39<00:23,  2.76it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  91%|█████████ | 607/670 [03:39<00:22,  2.76it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  91%|█████████ | 608/670 [03:39<00:22,  2.77it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  91%|█████████ | 609/670 [03:39<00:22,  2.77it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  91%|█████████ | 610/670 [03:40<00:21,  2.77it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  91%|█████████ | 611/670 [03:40<00:21,  2.77it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  91%|█████████▏| 612/670 [03:40<00:20,  2.78it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  91%|█████████▏| 613/670 [03:40<00:20,  2.78it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  92%|█████████▏| 614/670 [03:40<00:20,  2.78it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  92%|█████████▏| 615/670 [03:40<00:19,  2.78it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  92%|█████████▏| 616/670 [03:41<00:19,  2.79it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  92%|█████████▏| 617/670 [03:41<00:19,  2.79it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  92%|█████████▏| 618/670 [03:41<00:18,  2.79it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  92%|█████████▏| 619/670 [03:41<00:18,  2.79it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  93%|█████████▎| 620/670 [03:41<00:17,  2.80it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  93%|█████████▎| 621/670 [03:41<00:17,  2.80it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  93%|█████████▎| 622/670 [03:42<00:17,  2.80it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  93%|█████████▎| 623/670 [03:42<00:16,  2.80it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  93%|█████████▎| 624/670 [03:42<00:16,  2.81it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  93%|█████████▎| 625/670 [03:42<00:16,  2.81it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  93%|█████████▎| 626/670 [03:42<00:15,  2.81it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  94%|█████████▎| 627/670 [03:42<00:15,  2.81it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  94%|█████████▎| 628/670 [03:43<00:14,  2.81it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  94%|█████████▍| 629/670 [03:43<00:14,  2.82it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  94%|█████████▍| 630/670 [03:43<00:14,  2.82it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  94%|█████████▍| 631/670 [03:43<00:13,  2.82it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  94%|█████████▍| 632/670 [03:43<00:13,  2.82it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  94%|█████████▍| 633/670 [03:43<00:13,  2.83it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  95%|█████████▍| 634/670 [03:44<00:12,  2.83it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  95%|█████████▍| 635/670 [03:44<00:12,  2.83it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  95%|█████████▍| 636/670 [03:44<00:12,  2.83it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  95%|█████████▌| 637/670 [03:44<00:11,  2.84it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  95%|█████████▌| 638/670 [03:44<00:11,  2.84it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  95%|█████████▌| 639/670 [03:45<00:10,  2.84it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  96%|█████████▌| 640/670 [03:45<00:10,  2.84it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  96%|█████████▌| 641/670 [03:45<00:10,  2.84it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  96%|█████████▌| 642/670 [03:45<00:09,  2.85it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  96%|█████████▌| 643/670 [03:45<00:09,  2.85it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  96%|█████████▌| 644/670 [03:45<00:09,  2.85it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  96%|█████████▋| 645/670 [03:46<00:08,  2.85it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  96%|█████████▋| 646/670 [03:46<00:08,  2.86it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  97%|█████████▋| 647/670 [03:46<00:08,  2.86it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  97%|█████████▋| 648/670 [03:46<00:07,  2.86it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  97%|█████████▋| 649/670 [03:46<00:07,  2.86it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  97%|█████████▋| 650/670 [03:46<00:06,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  97%|█████████▋| 651/670 [03:47<00:06,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  97%|█████████▋| 652/670 [03:47<00:06,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  97%|█████████▋| 653/670 [03:47<00:05,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  98%|█████████▊| 654/670 [03:47<00:05,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  98%|█████████▊| 655/670 [03:47<00:05,  2.88it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  98%|█████████▊| 656/670 [03:47<00:04,  2.88it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  98%|█████████▊| 657/670 [03:48<00:04,  2.88it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  98%|█████████▊| 658/670 [03:48<00:04,  2.88it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  98%|█████████▊| 659/670 [03:48<00:03,  2.89it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  99%|█████████▊| 660/670 [03:48<00:03,  2.89it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  99%|█████████▊| 661/670 [03:48<00:03,  2.89it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  99%|█████████▉| 662/670 [03:48<00:02,  2.89it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|█████████▉| 663/670 [03:49<00:02,  2.89it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  99%|█████████▉| 664/670 [03:49<00:02,  2.90it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  99%|█████████▉| 665/670 [03:49<00:01,  2.90it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0:  99%|█████████▉| 666/670 [03:49<00:01,  2.90it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0: 100%|█████████▉| 667/670 [03:49<00:01,  2.90it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0: 100%|█████████▉| 668/670 [03:49<00:00,  2.91it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0: 100%|█████████▉| 669/670 [03:50<00:00,  2.91it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0192]\n",
      "Epoch 0: 100%|██████████| 670/670 [03:50<00:00,  2.91it/s, loss=0.020, val_loss_step=0.0209, train_loss_step=0.0192, val_loss_epoch=0.0206]\n",
      "Epoch 1:  89%|████████▊ | 594/670 [03:37<00:27,  2.73it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 595/670 [03:37<00:27,  2.73it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  89%|████████▉ | 596/670 [03:37<00:27,  2.74it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  89%|████████▉ | 597/670 [03:37<00:26,  2.74it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  89%|████████▉ | 598/670 [03:38<00:26,  2.74it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  89%|████████▉ | 599/670 [03:38<00:25,  2.74it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  90%|████████▉ | 600/670 [03:38<00:25,  2.75it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  90%|████████▉ | 601/670 [03:38<00:25,  2.75it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  90%|████████▉ | 602/670 [03:38<00:24,  2.75it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  90%|█████████ | 603/670 [03:38<00:24,  2.75it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  90%|█████████ | 604/670 [03:39<00:23,  2.76it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  90%|█████████ | 605/670 [03:39<00:23,  2.76it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  90%|█████████ | 606/670 [03:39<00:23,  2.76it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  91%|█████████ | 607/670 [03:39<00:22,  2.76it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  91%|█████████ | 608/670 [03:39<00:22,  2.77it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  91%|█████████ | 609/670 [03:39<00:22,  2.77it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  91%|█████████ | 610/670 [03:40<00:21,  2.77it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  91%|█████████ | 611/670 [03:40<00:21,  2.77it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  91%|█████████▏| 612/670 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  91%|█████████▏| 613/670 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  92%|█████████▏| 614/670 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  92%|█████████▏| 615/670 [03:40<00:19,  2.78it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  92%|█████████▏| 616/670 [03:41<00:19,  2.79it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  92%|█████████▏| 617/670 [03:41<00:19,  2.79it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  92%|█████████▏| 618/670 [03:41<00:18,  2.79it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  92%|█████████▏| 619/670 [03:41<00:18,  2.79it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  93%|█████████▎| 620/670 [03:41<00:17,  2.79it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  93%|█████████▎| 621/670 [03:41<00:17,  2.80it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  93%|█████████▎| 622/670 [03:42<00:17,  2.80it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  93%|█████████▎| 623/670 [03:42<00:16,  2.80it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  93%|█████████▎| 624/670 [03:42<00:16,  2.80it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  93%|█████████▎| 625/670 [03:42<00:16,  2.81it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  93%|█████████▎| 626/670 [03:42<00:15,  2.81it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  94%|█████████▎| 627/670 [03:43<00:15,  2.81it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  94%|█████████▎| 628/670 [03:43<00:14,  2.81it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  94%|█████████▍| 629/670 [03:43<00:14,  2.82it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  94%|█████████▍| 630/670 [03:43<00:14,  2.82it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  94%|█████████▍| 631/670 [03:43<00:13,  2.82it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  94%|█████████▍| 632/670 [03:43<00:13,  2.82it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  94%|█████████▍| 633/670 [03:44<00:13,  2.83it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  95%|█████████▍| 634/670 [03:44<00:12,  2.83it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  95%|█████████▍| 635/670 [03:44<00:12,  2.83it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  95%|█████████▍| 636/670 [03:44<00:12,  2.83it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  95%|█████████▌| 637/670 [03:44<00:11,  2.84it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  95%|█████████▌| 638/670 [03:44<00:11,  2.84it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  95%|█████████▌| 639/670 [03:45<00:10,  2.84it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  96%|█████████▌| 640/670 [03:45<00:10,  2.84it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  96%|█████████▌| 641/670 [03:45<00:10,  2.84it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  96%|█████████▌| 642/670 [03:45<00:09,  2.85it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  96%|█████████▌| 643/670 [03:45<00:09,  2.85it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  96%|█████████▌| 644/670 [03:45<00:09,  2.85it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  96%|█████████▋| 645/670 [03:46<00:08,  2.85it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  96%|█████████▋| 646/670 [03:46<00:08,  2.86it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  97%|█████████▋| 647/670 [03:46<00:08,  2.86it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  97%|█████████▋| 648/670 [03:46<00:07,  2.86it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  97%|█████████▋| 649/670 [03:46<00:07,  2.86it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  97%|█████████▋| 650/670 [03:46<00:06,  2.86it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  97%|█████████▋| 651/670 [03:47<00:06,  2.87it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  97%|█████████▋| 652/670 [03:47<00:06,  2.87it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  97%|█████████▋| 653/670 [03:47<00:05,  2.87it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  98%|█████████▊| 654/670 [03:47<00:05,  2.87it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  98%|█████████▊| 655/670 [03:47<00:05,  2.88it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  98%|█████████▊| 656/670 [03:47<00:04,  2.88it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  98%|█████████▊| 657/670 [03:48<00:04,  2.88it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  98%|█████████▊| 658/670 [03:48<00:04,  2.88it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  98%|█████████▊| 659/670 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  99%|█████████▊| 660/670 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  99%|█████████▊| 661/670 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  99%|█████████▉| 662/670 [03:48<00:02,  2.89it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  99%|█████████▉| 663/670 [03:49<00:02,  2.89it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  99%|█████████▉| 664/670 [03:49<00:02,  2.90it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  99%|█████████▉| 665/670 [03:49<00:01,  2.90it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1:  99%|█████████▉| 666/670 [03:49<00:01,  2.90it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1: 100%|█████████▉| 667/670 [03:49<00:01,  2.90it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1: 100%|█████████▉| 668/670 [03:49<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1: 100%|█████████▉| 669/670 [03:50<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0206, train_loss_epoch=0.0263]\n",
      "Epoch 1: 100%|██████████| 670/670 [03:50<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0172, val_loss_epoch=0.0205, train_loss_epoch=0.0263]\n",
      "Epoch 2:  89%|████████▊ | 594/670 [03:37<00:27,  2.73it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 595/670 [03:37<00:27,  2.73it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  89%|████████▉ | 596/670 [03:37<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  89%|████████▉ | 597/670 [03:37<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  89%|████████▉ | 598/670 [03:38<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  89%|████████▉ | 599/670 [03:38<00:25,  2.74it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  90%|████████▉ | 600/670 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  90%|████████▉ | 601/670 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  90%|████████▉ | 602/670 [03:38<00:24,  2.75it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  90%|█████████ | 603/670 [03:38<00:24,  2.75it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  90%|█████████ | 604/670 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  90%|█████████ | 605/670 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  90%|█████████ | 606/670 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  91%|█████████ | 607/670 [03:39<00:22,  2.76it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  91%|█████████ | 608/670 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  91%|█████████ | 609/670 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  91%|█████████ | 610/670 [03:40<00:21,  2.77it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  91%|█████████ | 611/670 [03:40<00:21,  2.77it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  91%|█████████▏| 612/670 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  91%|█████████▏| 613/670 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  92%|█████████▏| 614/670 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  92%|█████████▏| 615/670 [03:40<00:19,  2.78it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  92%|█████████▏| 616/670 [03:41<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  92%|█████████▏| 617/670 [03:41<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  92%|█████████▏| 618/670 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  92%|█████████▏| 619/670 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  93%|█████████▎| 620/670 [03:41<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  93%|█████████▎| 621/670 [03:41<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  93%|█████████▎| 622/670 [03:42<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  93%|█████████▎| 623/670 [03:42<00:16,  2.80it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  93%|█████████▎| 624/670 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  93%|█████████▎| 625/670 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  93%|█████████▎| 626/670 [03:42<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  94%|█████████▎| 627/670 [03:42<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  94%|█████████▎| 628/670 [03:43<00:14,  2.81it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  94%|█████████▍| 629/670 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  94%|█████████▍| 630/670 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  94%|█████████▍| 631/670 [03:43<00:13,  2.82it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  94%|█████████▍| 632/670 [03:43<00:13,  2.82it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  94%|█████████▍| 633/670 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  95%|█████████▍| 634/670 [03:44<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  95%|█████████▍| 635/670 [03:44<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  95%|█████████▍| 636/670 [03:44<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  95%|█████████▌| 637/670 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  95%|█████████▌| 638/670 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  95%|█████████▌| 639/670 [03:44<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  96%|█████████▌| 640/670 [03:45<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  96%|█████████▌| 641/670 [03:45<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  96%|█████████▌| 642/670 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  96%|█████████▌| 643/670 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  96%|█████████▌| 644/670 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  96%|█████████▋| 645/670 [03:46<00:08,  2.85it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  96%|█████████▋| 646/670 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  97%|█████████▋| 647/670 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  97%|█████████▋| 648/670 [03:46<00:07,  2.86it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  97%|█████████▋| 649/670 [03:46<00:07,  2.86it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  97%|█████████▋| 650/670 [03:46<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  97%|█████████▋| 651/670 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  97%|█████████▋| 652/670 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  97%|█████████▋| 653/670 [03:47<00:05,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  98%|█████████▊| 654/670 [03:47<00:05,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  98%|█████████▊| 655/670 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  98%|█████████▊| 656/670 [03:47<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  98%|█████████▊| 657/670 [03:48<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  98%|█████████▊| 658/670 [03:48<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  98%|█████████▊| 659/670 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  99%|█████████▊| 660/670 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  99%|█████████▊| 661/670 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  99%|█████████▉| 662/670 [03:48<00:02,  2.89it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  99%|█████████▉| 663/670 [03:49<00:02,  2.89it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  99%|█████████▉| 664/670 [03:49<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  99%|█████████▉| 665/670 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2:  99%|█████████▉| 666/670 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2: 100%|█████████▉| 667/670 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2: 100%|█████████▉| 668/670 [03:49<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2: 100%|█████████▉| 669/670 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0184, val_loss_epoch=0.0205, train_loss_epoch=0.0194]\n",
      "Epoch 2: 100%|██████████| 670/670 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.025, train_loss_step=0.0184, val_loss_epoch=0.0228, train_loss_epoch=0.0194] \n",
      "Epoch 3:  89%|████████▊ | 594/670 [03:37<00:27,  2.73it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 595/670 [03:37<00:27,  2.73it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  89%|████████▉ | 596/670 [03:37<00:27,  2.74it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  89%|████████▉ | 597/670 [03:38<00:26,  2.74it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  89%|████████▉ | 598/670 [03:38<00:26,  2.74it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  89%|████████▉ | 599/670 [03:38<00:25,  2.74it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|████████▉ | 600/670 [03:38<00:25,  2.74it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|████████▉ | 601/670 [03:38<00:25,  2.75it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|████████▉ | 602/670 [03:38<00:24,  2.75it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|█████████ | 603/670 [03:39<00:24,  2.75it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|█████████ | 604/670 [03:39<00:23,  2.75it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|█████████ | 605/670 [03:39<00:23,  2.76it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|█████████ | 606/670 [03:39<00:23,  2.76it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 607/670 [03:39<00:22,  2.76it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 608/670 [03:39<00:22,  2.76it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 609/670 [03:40<00:22,  2.77it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 610/670 [03:40<00:21,  2.77it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 611/670 [03:40<00:21,  2.77it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████▏| 612/670 [03:40<00:20,  2.77it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████▏| 613/670 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 614/670 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 615/670 [03:41<00:19,  2.78it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 616/670 [03:41<00:19,  2.78it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 617/670 [03:41<00:19,  2.79it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 618/670 [03:41<00:18,  2.79it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 619/670 [03:41<00:18,  2.79it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 620/670 [03:41<00:17,  2.79it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 621/670 [03:42<00:17,  2.80it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 622/670 [03:42<00:17,  2.80it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 623/670 [03:42<00:16,  2.80it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 624/670 [03:42<00:16,  2.80it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 625/670 [03:42<00:16,  2.81it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 626/670 [03:42<00:15,  2.81it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▎| 627/670 [03:43<00:15,  2.81it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▎| 628/670 [03:43<00:14,  2.81it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▍| 629/670 [03:43<00:14,  2.81it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  94%|█████████▍| 630/670 [03:43<00:14,  2.82it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▍| 631/670 [03:43<00:13,  2.82it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▍| 632/670 [03:43<00:13,  2.82it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▍| 633/670 [03:44<00:13,  2.82it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▍| 634/670 [03:44<00:12,  2.83it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▍| 635/670 [03:44<00:12,  2.83it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▍| 636/670 [03:44<00:12,  2.83it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▌| 637/670 [03:44<00:11,  2.83it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▌| 638/670 [03:45<00:11,  2.84it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▌| 639/670 [03:45<00:10,  2.84it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 640/670 [03:45<00:10,  2.84it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 641/670 [03:45<00:10,  2.84it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 642/670 [03:45<00:09,  2.84it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 643/670 [03:45<00:09,  2.85it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 644/670 [03:46<00:09,  2.85it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▋| 645/670 [03:46<00:08,  2.85it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▋| 646/670 [03:46<00:08,  2.85it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 647/670 [03:46<00:08,  2.86it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 648/670 [03:46<00:07,  2.86it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 649/670 [03:46<00:07,  2.86it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 650/670 [03:47<00:06,  2.86it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 651/670 [03:47<00:06,  2.87it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 652/670 [03:47<00:06,  2.87it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 653/670 [03:47<00:05,  2.87it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 654/670 [03:47<00:05,  2.87it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 655/670 [03:47<00:05,  2.87it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 656/670 [03:48<00:04,  2.88it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 657/670 [03:48<00:04,  2.88it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 658/670 [03:48<00:04,  2.88it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 659/670 [03:48<00:03,  2.88it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▊| 660/670 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▊| 661/670 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 662/670 [03:49<00:02,  2.89it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 663/670 [03:49<00:02,  2.89it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 664/670 [03:49<00:02,  2.89it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 665/670 [03:49<00:01,  2.90it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 666/670 [03:49<00:01,  2.90it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3: 100%|█████████▉| 667/670 [03:49<00:01,  2.90it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3: 100%|█████████▉| 668/670 [03:50<00:00,  2.90it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3: 100%|█████████▉| 669/670 [03:50<00:00,  2.91it/s, loss=0.019, val_loss_step=0.025, train_loss_step=0.0193, val_loss_epoch=0.0228, train_loss_epoch=0.0189]\n",
      "Epoch 3: 100%|██████████| 670/670 [03:50<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0218, train_loss_step=0.0193, val_loss_epoch=0.0202, train_loss_epoch=0.0189]\n",
      "Epoch 4:  89%|████████▊ | 594/670 [03:36<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 595/670 [03:37<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  89%|████████▉ | 596/670 [03:37<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  89%|████████▉ | 597/670 [03:37<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  89%|████████▉ | 598/670 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  89%|████████▉ | 599/670 [03:37<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|████████▉ | 600/670 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|████████▉ | 601/670 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  90%|████████▉ | 602/670 [03:38<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|█████████ | 603/670 [03:38<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|█████████ | 604/670 [03:38<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|█████████ | 605/670 [03:38<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|█████████ | 606/670 [03:39<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 607/670 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 608/670 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 609/670 [03:39<00:21,  2.77it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 610/670 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 611/670 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████▏| 612/670 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████▏| 613/670 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 614/670 [03:40<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 615/670 [03:40<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 616/670 [03:40<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 617/670 [03:40<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 618/670 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 619/670 [03:41<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 620/670 [03:41<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 621/670 [03:41<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 622/670 [03:41<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 623/670 [03:41<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 624/670 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 625/670 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 626/670 [03:42<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▎| 627/670 [03:42<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▎| 628/670 [03:42<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 629/670 [03:42<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 630/670 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 631/670 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 632/670 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 633/670 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▍| 634/670 [03:43<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▍| 635/670 [03:43<00:12,  2.84it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▍| 636/670 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▌| 637/670 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▌| 638/670 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▌| 639/670 [03:44<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 640/670 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 641/670 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 642/670 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 643/670 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 644/670 [03:45<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▋| 645/670 [03:45<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▋| 646/670 [03:45<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 647/670 [03:45<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 648/670 [03:46<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 649/670 [03:46<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 650/670 [03:46<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  97%|█████████▋| 651/670 [03:46<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 652/670 [03:46<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 653/670 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 654/670 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 655/670 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 656/670 [03:47<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 657/670 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 658/670 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 659/670 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▊| 660/670 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▊| 661/670 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 662/670 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 663/670 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 664/670 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 665/670 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 666/670 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4: 100%|█████████▉| 667/670 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4: 100%|█████████▉| 668/670 [03:49<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4: 100%|█████████▉| 669/670 [03:49<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0218, train_loss_step=0.0235, val_loss_epoch=0.0202, train_loss_epoch=0.0186]\n",
      "Epoch 4: 100%|██████████| 670/670 [03:49<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0222, train_loss_step=0.0235, val_loss_epoch=0.0214, train_loss_epoch=0.0186]\n",
      "Epoch 5:  89%|████████▊ | 594/670 [03:36<00:27,  2.74it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 595/670 [03:37<00:27,  2.74it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 596/670 [03:37<00:26,  2.74it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 597/670 [03:37<00:26,  2.74it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 598/670 [03:37<00:26,  2.75it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 599/670 [03:37<00:25,  2.75it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|████████▉ | 600/670 [03:38<00:25,  2.75it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|████████▉ | 601/670 [03:38<00:25,  2.75it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|████████▉ | 602/670 [03:38<00:24,  2.76it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 603/670 [03:38<00:24,  2.76it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 604/670 [03:38<00:23,  2.76it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 605/670 [03:38<00:23,  2.76it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 606/670 [03:39<00:23,  2.77it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 607/670 [03:39<00:22,  2.77it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 608/670 [03:39<00:22,  2.77it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 609/670 [03:39<00:21,  2.77it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 610/670 [03:39<00:21,  2.78it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 611/670 [03:39<00:21,  2.78it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████▏| 612/670 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████▏| 613/670 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 614/670 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 615/670 [03:40<00:19,  2.79it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 616/670 [03:40<00:19,  2.79it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 617/670 [03:40<00:18,  2.79it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 618/670 [03:41<00:18,  2.79it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 619/670 [03:41<00:18,  2.80it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 620/670 [03:41<00:17,  2.80it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 621/670 [03:41<00:17,  2.80it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 622/670 [03:41<00:17,  2.80it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  93%|█████████▎| 623/670 [03:41<00:16,  2.81it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 624/670 [03:42<00:16,  2.81it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 625/670 [03:42<00:16,  2.81it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 626/670 [03:42<00:15,  2.81it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▎| 627/670 [03:42<00:15,  2.82it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▎| 628/670 [03:42<00:14,  2.82it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 629/670 [03:43<00:14,  2.82it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 630/670 [03:43<00:14,  2.82it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 631/670 [03:43<00:13,  2.83it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 632/670 [03:43<00:13,  2.83it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 633/670 [03:43<00:13,  2.83it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▍| 634/670 [03:43<00:12,  2.83it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▍| 635/670 [03:44<00:12,  2.83it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▍| 636/670 [03:44<00:11,  2.84it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▌| 637/670 [03:44<00:11,  2.84it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▌| 638/670 [03:44<00:11,  2.84it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▌| 639/670 [03:44<00:10,  2.84it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 640/670 [03:44<00:10,  2.85it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 641/670 [03:45<00:10,  2.85it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 642/670 [03:45<00:09,  2.85it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 643/670 [03:45<00:09,  2.85it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 644/670 [03:45<00:09,  2.86it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▋| 645/670 [03:45<00:08,  2.86it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▋| 646/670 [03:45<00:08,  2.86it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 647/670 [03:46<00:08,  2.86it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 648/670 [03:46<00:07,  2.86it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 649/670 [03:46<00:07,  2.87it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 650/670 [03:46<00:06,  2.87it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 651/670 [03:46<00:06,  2.87it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 652/670 [03:46<00:06,  2.87it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 653/670 [03:47<00:05,  2.88it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 654/670 [03:47<00:05,  2.88it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 655/670 [03:47<00:05,  2.88it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 656/670 [03:47<00:04,  2.88it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 657/670 [03:47<00:04,  2.88it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 658/670 [03:47<00:04,  2.89it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 659/670 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▊| 660/670 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▊| 661/670 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 662/670 [03:48<00:02,  2.90it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 663/670 [03:48<00:02,  2.90it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 664/670 [03:48<00:02,  2.90it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 665/670 [03:49<00:01,  2.90it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 666/670 [03:49<00:01,  2.91it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|█████████▉| 667/670 [03:49<00:01,  2.91it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|█████████▉| 668/670 [03:49<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|█████████▉| 669/670 [03:49<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0222, train_loss_step=0.0203, val_loss_epoch=0.0214, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|██████████| 670/670 [03:49<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0878, train_loss_step=0.0203, val_loss_epoch=0.0784, train_loss_epoch=0.0183]\n",
      "Epoch 6:  89%|████████▊ | 594/670 [03:36<00:27,  2.74it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  89%|████████▉ | 595/670 [03:37<00:27,  2.74it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  89%|████████▉ | 596/670 [03:37<00:26,  2.74it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  89%|████████▉ | 597/670 [03:37<00:26,  2.74it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  89%|████████▉ | 598/670 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  89%|████████▉ | 599/670 [03:37<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|████████▉ | 600/670 [03:38<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|████████▉ | 601/670 [03:38<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|████████▉ | 602/670 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|█████████ | 603/670 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|█████████ | 604/670 [03:38<00:23,  2.76it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|█████████ | 605/670 [03:38<00:23,  2.76it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|█████████ | 606/670 [03:39<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████ | 607/670 [03:39<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████ | 608/670 [03:39<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████ | 609/670 [03:39<00:21,  2.77it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████ | 610/670 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████ | 611/670 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████▏| 612/670 [03:40<00:20,  2.78it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████▏| 613/670 [03:40<00:20,  2.78it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 614/670 [03:40<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 615/670 [03:40<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 616/670 [03:40<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 617/670 [03:40<00:18,  2.79it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 618/670 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 619/670 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 620/670 [03:41<00:17,  2.80it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 621/670 [03:41<00:17,  2.80it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 622/670 [03:41<00:17,  2.80it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 623/670 [03:41<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 624/670 [03:42<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 625/670 [03:42<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 626/670 [03:42<00:15,  2.81it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▎| 627/670 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▎| 628/670 [03:42<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 629/670 [03:42<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 630/670 [03:43<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 631/670 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 632/670 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 633/670 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▍| 634/670 [03:43<00:12,  2.83it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▍| 635/670 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▍| 636/670 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▌| 637/670 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▌| 638/670 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▌| 639/670 [03:44<00:10,  2.84it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▌| 640/670 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▌| 641/670 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▌| 642/670 [03:45<00:09,  2.85it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▌| 643/670 [03:45<00:09,  2.85it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  96%|█████████▌| 644/670 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▋| 645/670 [03:45<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▋| 646/670 [03:45<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 647/670 [03:45<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 648/670 [03:46<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 649/670 [03:46<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 650/670 [03:46<00:06,  2.87it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 651/670 [03:46<00:06,  2.87it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 652/670 [03:46<00:06,  2.87it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 653/670 [03:46<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 654/670 [03:47<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 655/670 [03:47<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 656/670 [03:47<00:04,  2.88it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 657/670 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 658/670 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 659/670 [03:47<00:03,  2.89it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▊| 660/670 [03:48<00:03,  2.89it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▊| 661/670 [03:48<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 662/670 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 663/670 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 664/670 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 665/670 [03:48<00:01,  2.90it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 666/670 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6: 100%|█████████▉| 667/670 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6: 100%|█████████▉| 668/670 [03:49<00:00,  2.91it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6: 100%|█████████▉| 669/670 [03:49<00:00,  2.91it/s, loss=0.017, val_loss_step=0.0878, train_loss_step=0.0175, val_loss_epoch=0.0784, train_loss_epoch=0.0181]\n",
      "Epoch 6: 100%|██████████| 670/670 [03:50<00:00,  2.91it/s, loss=0.017, val_loss_step=0.0195, train_loss_step=0.0175, val_loss_epoch=0.0195, train_loss_epoch=0.0181]\n",
      "Epoch 7:  89%|████████▊ | 594/670 [03:36<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 595/670 [03:36<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  89%|████████▉ | 596/670 [03:36<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  89%|████████▉ | 597/670 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  89%|████████▉ | 598/670 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  89%|████████▉ | 599/670 [03:37<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  90%|████████▉ | 600/670 [03:37<00:25,  2.76it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  90%|████████▉ | 601/670 [03:37<00:25,  2.76it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  90%|████████▉ | 602/670 [03:37<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  90%|█████████ | 603/670 [03:38<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  90%|█████████ | 604/670 [03:38<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  90%|█████████ | 605/670 [03:38<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  90%|█████████ | 606/670 [03:38<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  91%|█████████ | 607/670 [03:38<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  91%|█████████ | 609/670 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  91%|█████████ | 610/670 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  91%|█████████ | 611/670 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  91%|█████████▏| 613/670 [03:39<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  92%|█████████▏| 614/670 [03:39<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  92%|█████████▏| 615/670 [03:40<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  92%|█████████▏| 616/670 [03:40<00:19,  2.80it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  92%|█████████▏| 617/670 [03:40<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  92%|█████████▏| 618/670 [03:40<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  92%|█████████▏| 619/670 [03:40<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  93%|█████████▎| 620/670 [03:41<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  93%|█████████▎| 621/670 [03:41<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  93%|█████████▎| 622/670 [03:41<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  93%|█████████▎| 623/670 [03:41<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  93%|█████████▎| 624/670 [03:41<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  93%|█████████▎| 625/670 [03:41<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  93%|█████████▎| 626/670 [03:42<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  94%|█████████▎| 627/670 [03:42<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  94%|█████████▎| 628/670 [03:42<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  94%|█████████▍| 629/670 [03:42<00:14,  2.83it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  94%|█████████▍| 630/670 [03:42<00:14,  2.83it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  94%|█████████▍| 631/670 [03:42<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  94%|█████████▍| 632/670 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  94%|█████████▍| 633/670 [03:43<00:13,  2.84it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  95%|█████████▍| 634/670 [03:43<00:12,  2.84it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  95%|█████████▍| 635/670 [03:43<00:12,  2.84it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  95%|█████████▍| 636/670 [03:43<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  95%|█████████▌| 638/670 [03:44<00:11,  2.85it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  95%|█████████▌| 639/670 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  96%|█████████▌| 640/670 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  96%|█████████▌| 641/670 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  96%|█████████▌| 642/670 [03:44<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  96%|█████████▌| 643/670 [03:44<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  96%|█████████▌| 644/670 [03:45<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  96%|█████████▋| 645/670 [03:45<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  96%|█████████▋| 646/670 [03:45<00:08,  2.87it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  97%|█████████▋| 647/670 [03:45<00:08,  2.87it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  97%|█████████▋| 648/670 [03:45<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  97%|█████████▋| 649/670 [03:45<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  97%|█████████▋| 650/670 [03:46<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  97%|█████████▋| 651/670 [03:46<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  97%|█████████▋| 652/670 [03:46<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  97%|█████████▋| 653/670 [03:46<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  98%|█████████▊| 654/670 [03:46<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  98%|█████████▊| 655/670 [03:46<00:05,  2.89it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  98%|█████████▊| 656/670 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  98%|█████████▊| 657/670 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  98%|█████████▊| 658/670 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  98%|█████████▊| 659/670 [03:47<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  99%|█████████▊| 660/670 [03:47<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  99%|█████████▊| 661/670 [03:47<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  99%|█████████▉| 662/670 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  99%|█████████▉| 663/670 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  99%|█████████▉| 664/670 [03:48<00:02,  2.91it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  99%|█████████▉| 665/670 [03:48<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7:  99%|█████████▉| 666/670 [03:48<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7: 100%|█████████▉| 667/670 [03:48<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7: 100%|█████████▉| 668/670 [03:49<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7: 100%|█████████▉| 669/670 [03:49<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0195, train_loss_step=0.0161, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 7: 100%|██████████| 670/670 [03:49<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0161, val_loss_epoch=0.0205, train_loss_epoch=0.0177]\n",
      "Epoch 8:  89%|████████▊ | 594/670 [03:36<00:27,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  89%|████████▉ | 596/670 [03:36<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  89%|████████▉ | 597/670 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  89%|████████▉ | 598/670 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  89%|████████▉ | 599/670 [03:37<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|████████▉ | 600/670 [03:37<00:25,  2.76it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|████████▉ | 601/670 [03:37<00:25,  2.76it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|████████▉ | 602/670 [03:37<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|█████████ | 603/670 [03:38<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|█████████ | 604/670 [03:38<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|█████████ | 605/670 [03:38<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|█████████ | 606/670 [03:38<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 607/670 [03:38<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 609/670 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 610/670 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 611/670 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████▏| 613/670 [03:39<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 614/670 [03:39<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 615/670 [03:40<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 616/670 [03:40<00:19,  2.80it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 617/670 [03:40<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 618/670 [03:40<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 619/670 [03:40<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 621/670 [03:41<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 622/670 [03:41<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 623/670 [03:41<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 625/670 [03:41<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 626/670 [03:41<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▎| 627/670 [03:42<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▎| 628/670 [03:42<00:14,  2.83it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 629/670 [03:42<00:14,  2.83it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 630/670 [03:42<00:14,  2.83it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 631/670 [03:42<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 632/670 [03:42<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 633/670 [03:43<00:13,  2.84it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▍| 634/670 [03:43<00:12,  2.84it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▍| 635/670 [03:43<00:12,  2.84it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▍| 636/670 [03:43<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▌| 638/670 [03:43<00:11,  2.85it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▌| 639/670 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 640/670 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 641/670 [03:44<00:10,  2.86it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 642/670 [03:44<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 643/670 [03:44<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 644/670 [03:44<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▋| 645/670 [03:45<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▋| 646/670 [03:45<00:08,  2.87it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 647/670 [03:45<00:08,  2.87it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 648/670 [03:45<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 649/670 [03:45<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 651/670 [03:46<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 652/670 [03:46<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 653/670 [03:46<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 655/670 [03:46<00:05,  2.89it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 656/670 [03:46<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 657/670 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 658/670 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 659/670 [03:47<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▊| 660/670 [03:47<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▊| 661/670 [03:47<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 662/670 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 663/670 [03:48<00:02,  2.91it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 664/670 [03:48<00:02,  2.91it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 665/670 [03:48<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 666/670 [03:48<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8: 100%|█████████▉| 667/670 [03:48<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8: 100%|█████████▉| 668/670 [03:49<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8: 100%|█████████▉| 669/670 [03:49<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0205, val_loss_epoch=0.0205, train_loss_epoch=0.0174]\n",
      "Epoch 8: 100%|██████████| 670/670 [03:49<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0254, train_loss_step=0.0205, val_loss_epoch=0.0245, train_loss_epoch=0.0174]\n",
      "Epoch 9:  89%|████████▊ | 594/670 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  89%|████████▉ | 596/670 [03:36<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  89%|████████▉ | 597/670 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  89%|████████▉ | 598/670 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  89%|████████▉ | 599/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  90%|████████▉ | 600/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  90%|████████▉ | 601/670 [03:37<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  90%|████████▉ | 602/670 [03:37<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  90%|█████████ | 603/670 [03:38<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  90%|█████████ | 604/670 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  90%|█████████ | 605/670 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  90%|█████████ | 606/670 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  91%|█████████ | 609/670 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  91%|█████████ | 610/670 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  91%|█████████ | 611/670 [03:39<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  91%|█████████▏| 613/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  92%|█████████▏| 614/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  92%|█████████▏| 615/670 [03:40<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  92%|█████████▏| 616/670 [03:40<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  92%|█████████▏| 617/670 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  92%|█████████▏| 618/670 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  92%|█████████▏| 619/670 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  93%|█████████▎| 621/670 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  93%|█████████▎| 622/670 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  93%|█████████▎| 623/670 [03:41<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  93%|█████████▎| 625/670 [03:41<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  93%|█████████▎| 626/670 [03:41<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  94%|█████████▎| 627/670 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  94%|█████████▎| 628/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  94%|█████████▍| 629/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  94%|█████████▍| 630/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  94%|█████████▍| 631/670 [03:42<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  94%|█████████▍| 633/670 [03:43<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  95%|█████████▍| 634/670 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  95%|█████████▍| 635/670 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  95%|█████████▍| 636/670 [03:43<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  95%|█████████▌| 638/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  95%|█████████▌| 639/670 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  96%|█████████▌| 640/670 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  96%|█████████▌| 641/670 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  96%|█████████▌| 642/670 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  96%|█████████▌| 643/670 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  96%|█████████▌| 644/670 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  96%|█████████▋| 645/670 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  96%|█████████▋| 646/670 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  97%|█████████▋| 647/670 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  97%|█████████▋| 648/670 [03:45<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  97%|█████████▋| 649/670 [03:45<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  97%|█████████▋| 651/670 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  97%|█████████▋| 652/670 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  97%|█████████▋| 653/670 [03:46<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  98%|█████████▊| 655/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  98%|█████████▊| 656/670 [03:46<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  98%|█████████▊| 657/670 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  98%|█████████▊| 658/670 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  98%|█████████▊| 659/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  99%|█████████▊| 660/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  99%|█████████▊| 661/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  99%|█████████▉| 662/670 [03:47<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  99%|█████████▉| 663/670 [03:48<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  99%|█████████▉| 664/670 [03:48<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  99%|█████████▉| 665/670 [03:48<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9:  99%|█████████▉| 666/670 [03:48<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9: 100%|█████████▉| 667/670 [03:48<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9: 100%|█████████▉| 668/670 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9: 100%|█████████▉| 669/670 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0254, train_loss_step=0.0164, val_loss_epoch=0.0245, train_loss_epoch=0.0172]\n",
      "Epoch 9: 100%|██████████| 670/670 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0164, val_loss_epoch=0.146, train_loss_epoch=0.0172]  \n",
      "Epoch 10:  89%|████████▊ | 594/670 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  89%|████████▉ | 596/670 [03:36<00:26,  2.75it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  89%|████████▉ | 597/670 [03:36<00:26,  2.75it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  89%|████████▉ | 599/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  90%|████████▉ | 600/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  90%|████████▉ | 601/670 [03:37<00:24,  2.76it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  90%|█████████ | 604/670 [03:37<00:23,  2.77it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  90%|█████████ | 605/670 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  90%|█████████ | 606/670 [03:38<00:23,  2.78it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  91%|█████████ | 609/670 [03:38<00:21,  2.78it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  91%|█████████ | 611/670 [03:39<00:21,  2.79it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  91%|█████████▏| 613/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  92%|█████████▏| 617/670 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  92%|█████████▏| 618/670 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  93%|█████████▎| 621/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  93%|█████████▎| 623/670 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  93%|█████████▎| 625/670 [03:41<00:15,  2.82it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  93%|█████████▎| 626/670 [03:41<00:15,  2.82it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  94%|█████████▍| 629/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  94%|█████████▍| 630/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  94%|█████████▍| 633/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  95%|█████████▍| 634/670 [03:42<00:12,  2.84it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  95%|█████████▍| 635/670 [03:43<00:12,  2.85it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  95%|█████████▍| 636/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  95%|█████████▌| 638/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  96%|█████████▌| 641/670 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  96%|█████████▌| 642/670 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  96%|█████████▌| 643/670 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  96%|█████████▋| 646/670 [03:44<00:08,  2.87it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  97%|█████████▋| 647/670 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  97%|█████████▋| 648/670 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  97%|█████████▋| 651/670 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  97%|█████████▋| 653/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  98%|█████████▊| 655/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  98%|█████████▊| 656/670 [03:46<00:04,  2.89it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  98%|█████████▊| 659/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  99%|█████████▊| 660/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  99%|█████████▉| 664/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  99%|█████████▉| 665/670 [03:48<00:01,  2.91it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10:  99%|█████████▉| 666/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10: 100%|█████████▉| 668/670 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10: 100%|█████████▉| 669/670 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.149, train_loss_step=0.0135, val_loss_epoch=0.146, train_loss_epoch=0.017]\n",
      "Epoch 10: 100%|██████████| 670/670 [03:49<00:00,  2.93it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0135, val_loss_epoch=0.0279, train_loss_epoch=0.017]\n",
      "Epoch 11:  89%|████████▊ | 594/670 [03:35<00:27,  2.75it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  89%|████████▉ | 596/670 [03:36<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  89%|████████▉ | 599/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  90%|████████▉ | 600/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  90%|████████▉ | 601/670 [03:37<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  90%|█████████ | 604/670 [03:37<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  90%|█████████ | 605/670 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  90%|█████████ | 606/670 [03:38<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  91%|█████████ | 609/670 [03:38<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  91%|█████████ | 611/670 [03:39<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  91%|█████████▏| 613/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  92%|█████████▏| 617/670 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  92%|█████████▏| 618/670 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  93%|█████████▎| 621/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  93%|█████████▎| 623/670 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  93%|█████████▎| 625/670 [03:41<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  94%|█████████▍| 629/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  94%|█████████▍| 630/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  94%|█████████▍| 633/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  95%|█████████▍| 634/670 [03:42<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  95%|█████████▍| 635/670 [03:43<00:12,  2.85it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  95%|█████████▍| 636/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  95%|█████████▌| 638/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  96%|█████████▌| 641/670 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  96%|█████████▌| 642/670 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  96%|█████████▋| 646/670 [03:44<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  97%|█████████▋| 647/670 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  97%|█████████▋| 648/670 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  97%|█████████▋| 651/670 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  97%|█████████▋| 653/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  98%|█████████▊| 655/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  98%|█████████▊| 656/670 [03:46<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  98%|█████████▊| 659/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  99%|█████████▊| 660/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  99%|█████████▉| 664/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  99%|█████████▉| 665/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11:  99%|█████████▉| 666/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11: 100%|█████████▉| 668/670 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11: 100%|█████████▉| 669/670 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0256, train_loss_step=0.0183, val_loss_epoch=0.0279, train_loss_epoch=0.0169]\n",
      "Epoch 11: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0183, val_loss_epoch=0.149, train_loss_epoch=0.0169]  \n",
      "Epoch 12:  89%|████████▊ | 594/670 [03:35<00:27,  2.75it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  89%|████████▉ | 596/670 [03:36<00:26,  2.75it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  89%|████████▉ | 599/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|████████▉ | 600/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|████████▉ | 601/670 [03:37<00:24,  2.76it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|█████████ | 604/670 [03:37<00:23,  2.77it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|█████████ | 605/670 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|█████████ | 606/670 [03:38<00:23,  2.78it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 609/670 [03:38<00:21,  2.78it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 611/670 [03:39<00:21,  2.79it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████▏| 613/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 617/670 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 618/670 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 621/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  93%|█████████▎| 623/670 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 625/670 [03:41<00:15,  2.82it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 629/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 630/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 633/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▍| 634/670 [03:42<00:12,  2.84it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▍| 635/670 [03:43<00:12,  2.85it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▍| 636/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▌| 638/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 641/670 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 642/670 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▋| 646/670 [03:44<00:08,  2.87it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 647/670 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 648/670 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 651/670 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 653/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 655/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 659/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▊| 660/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 664/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 665/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 666/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12: 100%|█████████▉| 668/670 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12: 100%|█████████▉| 669/670 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.161, train_loss_step=0.0159, val_loss_epoch=0.149, train_loss_epoch=0.0166]\n",
      "Epoch 12: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.017, val_loss_step=0.095, train_loss_step=0.0159, val_loss_epoch=0.105, train_loss_epoch=0.0166]\n",
      "Epoch 13:  89%|████████▊ | 594/670 [03:35<00:27,  2.75it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  89%|████████▉ | 599/670 [03:36<00:25,  2.76it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|████████▉ | 601/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|█████████ | 604/670 [03:37<00:23,  2.77it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|█████████ | 606/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████▏| 613/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 618/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 625/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 630/670 [03:42<00:14,  2.84it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 633/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▍| 636/670 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 641/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 642/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▋| 646/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 648/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 659/670 [03:46<00:03,  2.90it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▊| 660/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 666/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13: 100%|█████████▉| 668/670 [03:48<00:00,  2.92it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.095, train_loss_step=0.014, val_loss_epoch=0.105, train_loss_epoch=0.0165]\n",
      "Epoch 13: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0165]\n",
      "Epoch 14:  89%|████████▊ | 594/670 [03:35<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  89%|████████▉ | 599/670 [03:36<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|████████▉ | 600/670 [03:36<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|████████▉ | 601/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 604/670 [03:37<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 606/670 [03:38<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████▏| 613/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 618/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 625/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 630/670 [03:42<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 633/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▍| 636/670 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 641/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 642/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▋| 646/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 648/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 659/670 [03:46<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▊| 660/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  99%|█████████▉| 666/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|█████████▉| 668/670 [03:48<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0237, train_loss_step=0.014, val_loss_epoch=0.025, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0552, train_loss_step=0.014, val_loss_epoch=0.0565, train_loss_epoch=0.0164]\n",
      "Epoch 15:  89%|████████▊ | 594/670 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  89%|████████▉ | 596/670 [03:36<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  89%|████████▉ | 597/670 [03:36<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  89%|████████▉ | 599/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|████████▉ | 600/670 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|████████▉ | 601/670 [03:37<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|█████████ | 604/670 [03:37<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|█████████ | 605/670 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|█████████ | 606/670 [03:38<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 609/670 [03:38<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 611/670 [03:39<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████▏| 613/670 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 617/670 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 618/670 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 621/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 622/670 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 623/670 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 625/670 [03:41<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 626/670 [03:41<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 629/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 630/670 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 633/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▍| 634/670 [03:42<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▍| 635/670 [03:43<00:12,  2.85it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▍| 636/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  95%|█████████▌| 638/670 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▌| 639/670 [03:43<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 641/670 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 642/670 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 643/670 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▋| 646/670 [03:44<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 647/670 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 648/670 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 651/670 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 652/670 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 653/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 655/670 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 656/670 [03:46<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 658/670 [03:47<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 659/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▊| 660/670 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 664/670 [03:48<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 665/670 [03:48<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 666/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15: 100%|█████████▉| 668/670 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15: 100%|█████████▉| 669/670 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0552, train_loss_step=0.0173, val_loss_epoch=0.0565, train_loss_epoch=0.0163]\n",
      "Epoch 15: 100%|██████████| 670/670 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0216, train_loss_step=0.0173, val_loss_epoch=0.0221, train_loss_epoch=0.0163]\n",
      "Epoch 16:  89%|████████▊ | 594/670 [03:35<00:27,  2.75it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  89%|████████▉ | 599/670 [03:36<00:25,  2.76it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|████████▉ | 601/670 [03:37<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|█████████ | 606/670 [03:37<00:23,  2.78it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████ | 608/670 [03:38<00:22,  2.79it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████▏| 613/670 [03:39<00:20,  2.80it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 618/670 [03:39<00:18,  2.81it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 624/670 [03:40<00:16,  2.82it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 625/670 [03:41<00:15,  2.83it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 633/670 [03:42<00:13,  2.85it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▍| 636/670 [03:42<00:11,  2.85it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▌| 641/670 [03:43<00:10,  2.86it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 648/670 [03:44<00:07,  2.88it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 654/670 [03:45<00:05,  2.89it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 666/670 [03:47<00:01,  2.92it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16: 100%|█████████▉| 668/670 [03:48<00:00,  2.93it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.015, val_loss_step=0.0216, train_loss_step=0.0214, val_loss_epoch=0.0221, train_loss_epoch=0.0161]\n",
      "Epoch 16: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.015, val_loss_step=0.0183, train_loss_step=0.0214, val_loss_epoch=0.0185, train_loss_epoch=0.0161]\n",
      "Epoch 17:  89%|████████▊ | 594/670 [03:35<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  89%|████████▉ | 599/670 [03:36<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|████████▉ | 601/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|█████████ | 606/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 608/670 [03:38<00:22,  2.79it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████▏| 613/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 618/670 [03:39<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 624/670 [03:40<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 625/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▍| 633/670 [03:42<00:13,  2.85it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▍| 636/670 [03:42<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 641/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 648/670 [03:44<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 654/670 [03:45<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▉| 666/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17: 100%|█████████▉| 668/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0183, train_loss_step=0.0181, val_loss_epoch=0.0185, train_loss_epoch=0.016]\n",
      "Epoch 17: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0181, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  89%|████████▊ | 594/670 [03:35<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  89%|████████▉ | 599/670 [03:36<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|████████▉ | 600/670 [03:37<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|████████▉ | 601/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|█████████ | 604/670 [03:37<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|█████████ | 606/670 [03:38<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████▏| 612/670 [03:39<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████▏| 613/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 618/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 625/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 630/670 [03:42<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 633/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▍| 636/670 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▌| 641/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▌| 642/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▋| 646/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 648/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 659/670 [03:46<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▊| 660/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 666/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18: 100%|█████████▉| 668/670 [03:48<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0193, train_loss_step=0.0171, val_loss_epoch=0.0188, train_loss_epoch=0.016]\n",
      "Epoch 18: 100%|██████████| 670/670 [03:49<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0174, train_loss_step=0.0171, val_loss_epoch=0.0176, train_loss_epoch=0.016]\n",
      "Epoch 19:  89%|████████▊ | 594/670 [03:35<00:27,  2.76it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  89%|████████▉ | 595/670 [03:35<00:27,  2.76it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  89%|████████▉ | 599/670 [03:36<00:25,  2.76it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|████████▉ | 601/670 [03:36<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 606/670 [03:37<00:23,  2.78it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 607/670 [03:37<00:22,  2.78it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 608/670 [03:38<00:22,  2.79it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████▏| 613/670 [03:38<00:20,  2.80it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 614/670 [03:39<00:19,  2.80it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 616/670 [03:39<00:19,  2.81it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 618/670 [03:39<00:18,  2.81it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 619/670 [03:39<00:18,  2.81it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 620/670 [03:40<00:17,  2.82it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 625/670 [03:40<00:15,  2.83it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▎| 628/670 [03:41<00:14,  2.84it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 633/670 [03:42<00:12,  2.85it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▍| 636/670 [03:42<00:11,  2.85it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▌| 637/670 [03:43<00:11,  2.86it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 641/670 [03:43<00:10,  2.87it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▋| 645/670 [03:44<00:08,  2.88it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 648/670 [03:44<00:07,  2.88it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 650/670 [03:45<00:06,  2.89it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 654/670 [03:45<00:05,  2.90it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 663/670 [03:47<00:02,  2.92it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 666/670 [03:47<00:01,  2.92it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|█████████▉| 667/670 [03:48<00:01,  2.93it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|█████████▉| 668/670 [03:48<00:00,  2.93it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.014, val_loss_epoch=0.0176, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 20:  89%|████████▊ | 594/670 [03:35<00:27,  2.75it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  89%|████████▉ | 599/670 [03:36<00:25,  2.76it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  90%|████████▉ | 601/670 [03:37<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  90%|█████████ | 606/670 [03:37<00:23,  2.78it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  91%|█████████ | 608/670 [03:38<00:22,  2.79it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  91%|█████████▏| 613/670 [03:39<00:20,  2.80it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  92%|█████████▏| 614/670 [03:39<00:19,  2.80it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  92%|█████████▏| 616/670 [03:39<00:19,  2.81it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  92%|█████████▏| 618/670 [03:39<00:18,  2.81it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  93%|█████████▎| 620/670 [03:40<00:17,  2.82it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  93%|█████████▎| 624/670 [03:40<00:16,  2.82it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  93%|█████████▎| 625/670 [03:41<00:15,  2.83it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  94%|█████████▍| 633/670 [03:42<00:13,  2.85it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  95%|█████████▍| 636/670 [03:42<00:11,  2.85it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  95%|█████████▌| 637/670 [03:43<00:11,  2.86it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  96%|█████████▌| 641/670 [03:43<00:10,  2.86it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  97%|█████████▋| 648/670 [03:44<00:07,  2.88it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  97%|█████████▋| 650/670 [03:45<00:06,  2.89it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  98%|█████████▊| 654/670 [03:45<00:05,  2.89it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  99%|█████████▉| 663/670 [03:47<00:02,  2.92it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20:  99%|█████████▉| 666/670 [03:47<00:01,  2.92it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20: 100%|█████████▉| 668/670 [03:48<00:00,  2.93it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 20: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0102, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  89%|████████▊ | 594/670 [03:35<00:27,  2.76it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  89%|████████▉ | 595/670 [03:35<00:27,  2.76it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  89%|████████▉ | 599/670 [03:36<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|████████▉ | 601/670 [03:36<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|█████████ | 606/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████ | 607/670 [03:37<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████ | 608/670 [03:38<00:22,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████▏| 613/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 614/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 616/670 [03:39<00:19,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 618/670 [03:39<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 620/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 625/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 633/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▍| 636/670 [03:42<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▌| 637/670 [03:43<00:11,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 641/670 [03:43<00:10,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 648/670 [03:44<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 650/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 654/670 [03:45<00:05,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▉| 663/670 [03:47<00:02,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  99%|█████████▉| 666/670 [03:47<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21: 100%|█████████▉| 668/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 21: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0164, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  89%|████████▊ | 594/670 [03:35<00:27,  2.76it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 595/670 [03:35<00:27,  2.76it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  89%|████████▉ | 599/670 [03:36<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|████████▉ | 601/670 [03:36<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|█████████ | 603/670 [03:37<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|█████████ | 606/670 [03:37<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 607/670 [03:37<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 608/670 [03:38<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████▏| 613/670 [03:38<00:20,  2.80it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 614/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 616/670 [03:39<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 618/670 [03:39<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 619/670 [03:39<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 620/670 [03:40<00:17,  2.82it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 625/670 [03:40<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▎| 628/670 [03:41<00:14,  2.84it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 631/670 [03:41<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 633/670 [03:42<00:12,  2.85it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▍| 636/670 [03:42<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▌| 637/670 [03:42<00:11,  2.86it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 641/670 [03:43<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 643/670 [03:43<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▋| 645/670 [03:44<00:08,  2.88it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 648/670 [03:44<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 650/670 [03:45<00:06,  2.89it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 654/670 [03:45<00:05,  2.90it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 663/670 [03:47<00:02,  2.92it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 666/670 [03:47<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22: 100%|█████████▉| 667/670 [03:48<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22: 100%|█████████▉| 668/670 [03:48<00:00,  2.93it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0204, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 22: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.017, val_loss_step=0.0172, train_loss_step=0.0204, val_loss_epoch=0.0173, train_loss_epoch=0.0158]\n",
      "Epoch 23:  89%|████████▊ | 594/670 [03:35<00:27,  2.76it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 595/670 [03:35<00:27,  2.76it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  89%|████████▉ | 596/670 [03:35<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  89%|████████▉ | 597/670 [03:35<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  89%|████████▉ | 598/670 [03:36<00:26,  2.77it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  89%|████████▉ | 599/670 [03:36<00:25,  2.77it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|████████▉ | 601/670 [03:36<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|████████▉ | 602/670 [03:36<00:24,  2.78it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 603/670 [03:36<00:24,  2.78it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 606/670 [03:37<00:22,  2.79it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 607/670 [03:37<00:22,  2.79it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 608/670 [03:37<00:22,  2.79it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  91%|█████████ | 610/670 [03:38<00:21,  2.80it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 611/670 [03:38<00:21,  2.80it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████▏| 613/670 [03:38<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 614/670 [03:38<00:19,  2.81it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 615/670 [03:39<00:19,  2.81it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 616/670 [03:39<00:19,  2.81it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 618/670 [03:39<00:18,  2.82it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 619/670 [03:39<00:18,  2.82it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 620/670 [03:39<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 622/670 [03:40<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 623/670 [03:40<00:16,  2.83it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 625/670 [03:40<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 626/670 [03:40<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▎| 627/670 [03:41<00:15,  2.84it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▎| 628/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 631/670 [03:41<00:13,  2.85it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 632/670 [03:41<00:13,  2.85it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 633/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▍| 635/670 [03:42<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▍| 636/670 [03:42<00:11,  2.86it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▌| 637/670 [03:42<00:11,  2.86it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▌| 638/670 [03:42<00:11,  2.86it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▌| 639/670 [03:43<00:10,  2.87it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 640/670 [03:43<00:10,  2.87it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 641/670 [03:43<00:10,  2.87it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 643/670 [03:43<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 644/670 [03:43<00:09,  2.88it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▋| 645/670 [03:44<00:08,  2.88it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 648/670 [03:44<00:07,  2.89it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 649/670 [03:44<00:07,  2.89it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 650/670 [03:44<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 653/670 [03:45<00:05,  2.90it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 654/670 [03:45<00:05,  2.90it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 655/670 [03:45<00:05,  2.90it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 656/670 [03:45<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 657/670 [03:46<00:04,  2.91it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 658/670 [03:46<00:04,  2.91it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▊| 661/670 [03:46<00:03,  2.92it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 662/670 [03:46<00:02,  2.92it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 663/670 [03:47<00:02,  2.92it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 666/670 [03:47<00:01,  2.93it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|█████████▉| 667/670 [03:47<00:01,  2.93it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|█████████▉| 668/670 [03:47<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0172, train_loss_step=0.0148, val_loss_epoch=0.0173, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|██████████| 670/670 [03:48<00:00,  2.94it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0148, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▊ | 594/670 [03:35<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 595/670 [03:36<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 599/670 [03:36<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|████████▉ | 601/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 603/670 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 606/670 [03:37<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 607/670 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 608/670 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████▏| 612/670 [03:38<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████▏| 613/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 614/670 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 616/670 [03:39<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 618/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 619/670 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 620/670 [03:40<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 624/670 [03:41<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 625/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▎| 628/670 [03:41<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 630/670 [03:42<00:14,  2.84it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  94%|█████████▍| 631/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 632/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 633/670 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▍| 636/670 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▌| 637/670 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 641/670 [03:43<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 642/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 643/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▋| 645/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▋| 646/670 [03:44<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 648/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 649/670 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 650/670 [03:45<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 654/670 [03:46<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 655/670 [03:46<00:05,  2.90it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 658/670 [03:46<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 659/670 [03:46<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▊| 660/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▊| 661/670 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 662/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 663/670 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 666/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|█████████▉| 667/670 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|█████████▉| 668/670 [03:48<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0162, val_loss_epoch=0.0177, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0218, train_loss_step=0.0162, val_loss_epoch=0.021, train_loss_epoch=0.0159] \n",
      "Epoch 24: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.016, val_loss_step=0.0218, train_loss_step=0.0162, val_loss_epoch=0.021, train_loss_epoch=0.0159]\n",
      "Test iterations: 138\n",
      "Testing: 100%|██████████| 138/138 [00:21<00:00,  6.64it/s]Logits: tensor([[ -9.8516,  -8.6406,  -9.8594,  ...,  -9.5938,  -8.9766,  -9.4844],\n",
      "        [ -9.0156,  -8.4531, -10.5703,  ...,  -9.3984,  -9.4844,  -9.3984],\n",
      "        [-10.1484,  -9.4453,  -9.6406,  ...,  -8.7891,  -9.2266,  -8.7109],\n",
      "        ...,\n",
      "        [ -8.5781,  -8.1641, -10.1406,  ...,  -8.9766,  -9.0469,  -8.9297],\n",
      "        [ -9.2969,  -8.7031, -10.5156,  ...,  -9.1719,  -9.6953,  -9.2734],\n",
      "        [ -8.3203,  -8.0469,  -9.8359,  ...,  -8.7422,  -8.8672,  -8.6719]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[5.269e-05 1.768e-04 5.227e-05 ... 6.813e-05 1.264e-04 7.600e-05]\n",
      " [1.215e-04 2.131e-04 2.569e-05 ... 8.285e-05 7.600e-05 8.285e-05]\n",
      " [3.916e-05 7.904e-05 6.503e-05 ... 1.523e-04 9.841e-05 1.647e-04]\n",
      " ...\n",
      " [1.881e-04 2.847e-04 3.946e-05 ... 1.264e-04 1.177e-04 1.323e-04]\n",
      " [9.173e-05 1.661e-04 2.712e-05 ... 1.039e-04 6.157e-05 9.388e-05]\n",
      " [2.434e-04 3.200e-04 5.347e-05 ... 1.596e-04 1.409e-04 1.713e-04]]\n",
      "Testing: 100%|██████████| 138/138 [00:21<00:00,  6.50it/s]\n",
      "==================== Fold 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 11 M  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 75\n",
      "Train iterations: 596                                                 \n",
      "Epoch 0:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 597/671 [03:38<00:27,  2.73it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  89%|████████▉ | 598/671 [03:38<00:26,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  89%|████████▉ | 600/671 [03:38<00:25,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  90%|████████▉ | 601/671 [03:39<00:25,  2.74it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  90%|████████▉ | 602/671 [03:39<00:25,  2.75it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  90%|████████▉ | 603/671 [03:39<00:24,  2.75it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  90%|█████████ | 604/671 [03:39<00:24,  2.75it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  90%|█████████ | 605/671 [03:39<00:23,  2.75it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  90%|█████████ | 606/671 [03:39<00:23,  2.76it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  90%|█████████ | 607/671 [03:40<00:23,  2.76it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  91%|█████████ | 608/671 [03:40<00:22,  2.76it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  91%|█████████ | 609/671 [03:40<00:22,  2.76it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  91%|█████████ | 610/671 [03:40<00:22,  2.77it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  91%|█████████ | 612/671 [03:40<00:21,  2.77it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  91%|█████████▏| 613/671 [03:41<00:20,  2.77it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  92%|█████████▏| 614/671 [03:41<00:20,  2.78it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  92%|█████████▏| 615/671 [03:41<00:20,  2.78it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  92%|█████████▏| 616/671 [03:41<00:19,  2.78it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  92%|█████████▏| 617/671 [03:41<00:19,  2.78it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  92%|█████████▏| 618/671 [03:41<00:19,  2.79it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  92%|█████████▏| 619/671 [03:42<00:18,  2.79it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  92%|█████████▏| 620/671 [03:42<00:18,  2.79it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  93%|█████████▎| 621/671 [03:42<00:17,  2.79it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  93%|█████████▎| 622/671 [03:42<00:17,  2.79it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  93%|█████████▎| 623/671 [03:42<00:17,  2.80it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  93%|█████████▎| 624/671 [03:42<00:16,  2.80it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  93%|█████████▎| 625/671 [03:43<00:16,  2.80it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  93%|█████████▎| 626/671 [03:43<00:16,  2.80it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  93%|█████████▎| 627/671 [03:43<00:15,  2.81it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  94%|█████████▎| 629/671 [03:43<00:14,  2.81it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  94%|█████████▍| 630/671 [03:43<00:14,  2.81it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  94%|█████████▍| 631/671 [03:44<00:14,  2.82it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  94%|█████████▍| 632/671 [03:44<00:13,  2.82it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  94%|█████████▍| 634/671 [03:44<00:13,  2.82it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  95%|█████████▍| 635/671 [03:44<00:12,  2.83it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  95%|█████████▍| 636/671 [03:44<00:12,  2.83it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  95%|█████████▍| 637/671 [03:45<00:12,  2.83it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  95%|█████████▌| 638/671 [03:45<00:11,  2.83it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  95%|█████████▌| 639/671 [03:45<00:11,  2.83it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  95%|█████████▌| 640/671 [03:45<00:10,  2.84it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  96%|█████████▌| 641/671 [03:45<00:10,  2.84it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  96%|█████████▌| 642/671 [03:45<00:10,  2.84it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  96%|█████████▌| 643/671 [03:46<00:09,  2.84it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  96%|█████████▌| 644/671 [03:46<00:09,  2.85it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  96%|█████████▌| 645/671 [03:46<00:09,  2.85it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  96%|█████████▋| 646/671 [03:46<00:08,  2.85it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  96%|█████████▋| 647/671 [03:46<00:08,  2.85it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  97%|█████████▋| 648/671 [03:46<00:08,  2.85it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  97%|█████████▋| 649/671 [03:47<00:07,  2.86it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  97%|█████████▋| 650/671 [03:47<00:07,  2.86it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  97%|█████████▋| 651/671 [03:47<00:06,  2.86it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  97%|█████████▋| 652/671 [03:47<00:06,  2.86it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  97%|█████████▋| 653/671 [03:47<00:06,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  97%|█████████▋| 654/671 [03:48<00:05,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  98%|█████████▊| 655/671 [03:48<00:05,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  98%|█████████▊| 656/671 [03:48<00:05,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  98%|█████████▊| 657/671 [03:48<00:04,  2.87it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  98%|█████████▊| 658/671 [03:48<00:04,  2.88it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  98%|█████████▊| 659/671 [03:48<00:04,  2.88it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  98%|█████████▊| 660/671 [03:49<00:03,  2.88it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  99%|█████████▊| 661/671 [03:49<00:03,  2.88it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  99%|█████████▊| 662/671 [03:49<00:03,  2.89it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  99%|█████████▉| 664/671 [03:49<00:02,  2.89it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|█████████▉| 665/671 [03:49<00:02,  2.89it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  99%|█████████▉| 666/671 [03:50<00:01,  2.90it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0:  99%|█████████▉| 667/671 [03:50<00:01,  2.90it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0: 100%|█████████▉| 668/671 [03:50<00:01,  2.90it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0: 100%|█████████▉| 669/671 [03:50<00:00,  2.90it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0: 100%|█████████▉| 670/671 [03:50<00:00,  2.90it/s, loss=0.020, val_loss_step=0.698, train_loss_step=0.0165]\n",
      "Epoch 0: 100%|██████████| 671/671 [03:51<00:00,  2.90it/s, loss=0.020, val_loss_step=0.0182, train_loss_step=0.0165, val_loss_epoch=0.0197]\n",
      "Epoch 1:  89%|████████▉ | 596/671 [03:38<00:27,  2.73it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 597/671 [03:38<00:27,  2.73it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  89%|████████▉ | 598/671 [03:39<00:26,  2.73it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  89%|████████▉ | 599/671 [03:39<00:26,  2.73it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  89%|████████▉ | 600/671 [03:39<00:25,  2.74it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|████████▉ | 601/671 [03:39<00:25,  2.74it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|████████▉ | 602/671 [03:39<00:25,  2.74it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|████████▉ | 603/671 [03:39<00:24,  2.74it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|█████████ | 604/671 [03:40<00:24,  2.74it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|█████████ | 605/671 [03:40<00:24,  2.75it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|█████████ | 606/671 [03:40<00:23,  2.75it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|█████████ | 607/671 [03:40<00:23,  2.75it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 608/671 [03:40<00:22,  2.75it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 609/671 [03:40<00:22,  2.76it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 610/671 [03:41<00:22,  2.76it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 611/671 [03:41<00:21,  2.76it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 612/671 [03:41<00:21,  2.76it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████▏| 613/671 [03:41<00:20,  2.77it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 614/671 [03:41<00:20,  2.77it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 615/671 [03:41<00:20,  2.77it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 616/671 [03:42<00:19,  2.77it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 617/671 [03:42<00:19,  2.78it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 618/671 [03:42<00:19,  2.78it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 619/671 [03:42<00:18,  2.78it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 620/671 [03:42<00:18,  2.78it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 621/671 [03:42<00:17,  2.79it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 622/671 [03:43<00:17,  2.79it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 623/671 [03:43<00:17,  2.79it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 624/671 [03:43<00:16,  2.79it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 625/671 [03:43<00:16,  2.80it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 626/671 [03:43<00:16,  2.80it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 627/671 [03:43<00:15,  2.80it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▎| 628/671 [03:44<00:15,  2.80it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▎| 629/671 [03:44<00:14,  2.80it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 630/671 [03:44<00:14,  2.81it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 631/671 [03:44<00:14,  2.81it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 632/671 [03:44<00:13,  2.81it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 633/671 [03:44<00:13,  2.81it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 634/671 [03:45<00:13,  2.82it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▍| 635/671 [03:45<00:12,  2.82it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▍| 636/671 [03:45<00:12,  2.82it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▍| 637/671 [03:45<00:12,  2.82it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▌| 638/671 [03:45<00:11,  2.83it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▌| 639/671 [03:45<00:11,  2.83it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  95%|█████████▌| 640/671 [03:46<00:10,  2.83it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▌| 641/671 [03:46<00:10,  2.83it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▌| 642/671 [03:46<00:10,  2.83it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▌| 643/671 [03:46<00:09,  2.84it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▌| 644/671 [03:46<00:09,  2.84it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▌| 645/671 [03:46<00:09,  2.84it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▋| 646/671 [03:47<00:08,  2.84it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▋| 647/671 [03:47<00:08,  2.85it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 648/671 [03:47<00:08,  2.85it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 649/671 [03:47<00:07,  2.85it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 650/671 [03:47<00:07,  2.85it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 651/671 [03:48<00:07,  2.86it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 652/671 [03:48<00:06,  2.86it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 653/671 [03:48<00:06,  2.86it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 654/671 [03:48<00:05,  2.86it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 655/671 [03:48<00:05,  2.86it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 656/671 [03:48<00:05,  2.87it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 657/671 [03:49<00:04,  2.87it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 658/671 [03:49<00:04,  2.87it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 659/671 [03:49<00:04,  2.87it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 660/671 [03:49<00:03,  2.88it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▊| 661/671 [03:49<00:03,  2.88it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▊| 662/671 [03:49<00:03,  2.88it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 663/671 [03:50<00:02,  2.88it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 664/671 [03:50<00:02,  2.88it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 665/671 [03:50<00:02,  2.89it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 666/671 [03:50<00:01,  2.89it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 667/671 [03:50<00:01,  2.89it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1: 100%|█████████▉| 668/671 [03:50<00:01,  2.89it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1: 100%|█████████▉| 669/671 [03:51<00:00,  2.90it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1: 100%|█████████▉| 670/671 [03:51<00:00,  2.90it/s, loss=0.019, val_loss_step=0.0182, train_loss_step=0.0101, val_loss_epoch=0.0197, train_loss_epoch=0.0257]\n",
      "Epoch 1: 100%|██████████| 671/671 [03:51<00:00,  2.90it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0101, val_loss_epoch=0.022, train_loss_epoch=0.0257] \n",
      "Epoch 2:  89%|████████▉ | 596/671 [03:38<00:27,  2.73it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 597/671 [03:38<00:27,  2.73it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  89%|████████▉ | 598/671 [03:38<00:26,  2.73it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  89%|████████▉ | 599/671 [03:39<00:26,  2.73it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  89%|████████▉ | 600/671 [03:39<00:25,  2.74it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|████████▉ | 601/671 [03:39<00:25,  2.74it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|████████▉ | 602/671 [03:39<00:25,  2.74it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|████████▉ | 603/671 [03:39<00:24,  2.74it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 604/671 [03:39<00:24,  2.75it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 605/671 [03:40<00:24,  2.75it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 606/671 [03:40<00:23,  2.75it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 607/671 [03:40<00:23,  2.75it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 608/671 [03:40<00:22,  2.76it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 609/671 [03:40<00:22,  2.76it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 610/671 [03:40<00:22,  2.76it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 611/671 [03:41<00:21,  2.76it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 612/671 [03:41<00:21,  2.77it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  91%|█████████▏| 613/671 [03:41<00:20,  2.77it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 614/671 [03:41<00:20,  2.77it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 615/671 [03:41<00:20,  2.77it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 616/671 [03:41<00:19,  2.77it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 617/671 [03:42<00:19,  2.78it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 618/671 [03:42<00:19,  2.78it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 619/671 [03:42<00:18,  2.78it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 620/671 [03:42<00:18,  2.78it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 621/671 [03:42<00:17,  2.79it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 622/671 [03:43<00:17,  2.79it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 623/671 [03:43<00:17,  2.79it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 624/671 [03:43<00:16,  2.79it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 625/671 [03:43<00:16,  2.80it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 626/671 [03:43<00:16,  2.80it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 627/671 [03:43<00:15,  2.80it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▎| 628/671 [03:44<00:15,  2.80it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▎| 629/671 [03:44<00:14,  2.81it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 630/671 [03:44<00:14,  2.81it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 631/671 [03:44<00:14,  2.81it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 632/671 [03:44<00:13,  2.81it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 634/671 [03:45<00:13,  2.82it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▍| 635/671 [03:45<00:12,  2.82it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▍| 636/671 [03:45<00:12,  2.82it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▍| 637/671 [03:45<00:12,  2.82it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▌| 638/671 [03:45<00:11,  2.83it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▌| 639/671 [03:45<00:11,  2.83it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▌| 640/671 [03:46<00:10,  2.83it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 641/671 [03:46<00:10,  2.83it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 642/671 [03:46<00:10,  2.84it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 643/671 [03:46<00:09,  2.84it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 644/671 [03:46<00:09,  2.84it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 645/671 [03:46<00:09,  2.84it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▋| 646/671 [03:47<00:08,  2.84it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▋| 647/671 [03:47<00:08,  2.85it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 648/671 [03:47<00:08,  2.85it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 649/671 [03:47<00:07,  2.85it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 650/671 [03:47<00:07,  2.85it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 651/671 [03:47<00:07,  2.86it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 652/671 [03:48<00:06,  2.86it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 653/671 [03:48<00:06,  2.86it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 654/671 [03:48<00:05,  2.86it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 655/671 [03:48<00:05,  2.87it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 656/671 [03:48<00:05,  2.87it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 657/671 [03:48<00:04,  2.87it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 658/671 [03:49<00:04,  2.87it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 659/671 [03:49<00:04,  2.87it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 660/671 [03:49<00:03,  2.88it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▊| 661/671 [03:49<00:03,  2.88it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  99%|█████████▊| 662/671 [03:49<00:03,  2.88it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 663/671 [03:49<00:02,  2.88it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 664/671 [03:50<00:02,  2.88it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 665/671 [03:50<00:02,  2.89it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 666/671 [03:50<00:01,  2.89it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 667/671 [03:50<00:01,  2.89it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|█████████▉| 668/671 [03:50<00:01,  2.89it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|█████████▉| 669/671 [03:50<00:00,  2.90it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|█████████▉| 670/671 [03:51<00:00,  2.90it/s, loss=0.019, val_loss_step=0.0208, train_loss_step=0.0274, val_loss_epoch=0.022, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|██████████| 671/671 [03:51<00:00,  2.90it/s, loss=0.019, val_loss_step=0.0448, train_loss_step=0.0274, val_loss_epoch=0.0459, train_loss_epoch=0.0195]\n",
      "Epoch 3:  89%|████████▉ | 596/671 [03:38<00:27,  2.73it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 597/671 [03:38<00:27,  2.73it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  89%|████████▉ | 598/671 [03:38<00:26,  2.73it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  89%|████████▉ | 600/671 [03:39<00:25,  2.74it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  90%|████████▉ | 601/671 [03:39<00:25,  2.74it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  90%|████████▉ | 602/671 [03:39<00:25,  2.74it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  90%|████████▉ | 603/671 [03:39<00:24,  2.75it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  90%|█████████ | 604/671 [03:39<00:24,  2.75it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  90%|█████████ | 605/671 [03:39<00:23,  2.75it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  90%|█████████ | 606/671 [03:40<00:23,  2.75it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  90%|█████████ | 607/671 [03:40<00:23,  2.76it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  91%|█████████ | 608/671 [03:40<00:22,  2.76it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  91%|█████████ | 609/671 [03:40<00:22,  2.76it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  91%|█████████ | 610/671 [03:40<00:22,  2.76it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  91%|█████████ | 612/671 [03:41<00:21,  2.77it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  91%|█████████▏| 613/671 [03:41<00:20,  2.77it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  92%|█████████▏| 614/671 [03:41<00:20,  2.77it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  92%|█████████▏| 615/671 [03:41<00:20,  2.78it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  92%|█████████▏| 616/671 [03:41<00:19,  2.78it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  92%|█████████▏| 617/671 [03:41<00:19,  2.78it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  92%|█████████▏| 618/671 [03:42<00:19,  2.78it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  92%|█████████▏| 619/671 [03:42<00:18,  2.78it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  92%|█████████▏| 620/671 [03:42<00:18,  2.79it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  93%|█████████▎| 621/671 [03:42<00:17,  2.79it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  93%|█████████▎| 622/671 [03:42<00:17,  2.79it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  93%|█████████▎| 623/671 [03:42<00:17,  2.79it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  93%|█████████▎| 624/671 [03:43<00:16,  2.80it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  93%|█████████▎| 625/671 [03:43<00:16,  2.80it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  93%|█████████▎| 626/671 [03:43<00:16,  2.80it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  93%|█████████▎| 627/671 [03:43<00:15,  2.80it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  94%|█████████▎| 629/671 [03:43<00:14,  2.81it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  94%|█████████▍| 630/671 [03:44<00:14,  2.81it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  94%|█████████▍| 631/671 [03:44<00:14,  2.81it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  94%|█████████▍| 632/671 [03:44<00:13,  2.82it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  94%|█████████▍| 634/671 [03:44<00:13,  2.82it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  95%|█████████▍| 635/671 [03:44<00:12,  2.82it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  95%|█████████▍| 636/671 [03:45<00:12,  2.82it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  95%|█████████▍| 637/671 [03:45<00:12,  2.83it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  95%|█████████▌| 638/671 [03:45<00:11,  2.83it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  95%|█████████▌| 639/671 [03:45<00:11,  2.83it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  95%|█████████▌| 640/671 [03:45<00:10,  2.83it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  96%|█████████▌| 641/671 [03:46<00:10,  2.84it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  96%|█████████▌| 642/671 [03:46<00:10,  2.84it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  96%|█████████▌| 643/671 [03:46<00:09,  2.84it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  96%|█████████▌| 644/671 [03:46<00:09,  2.84it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  96%|█████████▌| 645/671 [03:46<00:09,  2.85it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  96%|█████████▋| 646/671 [03:46<00:08,  2.85it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  96%|█████████▋| 647/671 [03:47<00:08,  2.85it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  97%|█████████▋| 648/671 [03:47<00:08,  2.85it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  97%|█████████▋| 649/671 [03:47<00:07,  2.85it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  97%|█████████▋| 650/671 [03:47<00:07,  2.86it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  97%|█████████▋| 651/671 [03:47<00:06,  2.86it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  97%|█████████▋| 652/671 [03:47<00:06,  2.86it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  97%|█████████▋| 653/671 [03:48<00:06,  2.86it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  97%|█████████▋| 654/671 [03:48<00:05,  2.87it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  98%|█████████▊| 655/671 [03:48<00:05,  2.87it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  98%|█████████▊| 656/671 [03:48<00:05,  2.87it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  98%|█████████▊| 657/671 [03:48<00:04,  2.87it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  98%|█████████▊| 658/671 [03:48<00:04,  2.87it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  98%|█████████▊| 659/671 [03:49<00:04,  2.88it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  98%|█████████▊| 660/671 [03:49<00:03,  2.88it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  99%|█████████▊| 661/671 [03:49<00:03,  2.88it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  99%|█████████▊| 662/671 [03:49<00:03,  2.88it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  99%|█████████▉| 664/671 [03:49<00:02,  2.89it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  99%|█████████▉| 665/671 [03:50<00:02,  2.89it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  99%|█████████▉| 666/671 [03:50<00:01,  2.89it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3:  99%|█████████▉| 667/671 [03:50<00:01,  2.89it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3: 100%|█████████▉| 668/671 [03:50<00:01,  2.90it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3: 100%|█████████▉| 669/671 [03:50<00:00,  2.90it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3: 100%|█████████▉| 670/671 [03:50<00:00,  2.90it/s, loss=0.017, val_loss_step=0.0448, train_loss_step=0.00259, val_loss_epoch=0.0459, train_loss_epoch=0.0186]\n",
      "Epoch 3: 100%|██████████| 671/671 [03:51<00:00,  2.90it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.00259, val_loss_epoch=0.0233, train_loss_epoch=0.0186]\n",
      "Epoch 4:  89%|████████▉ | 596/671 [03:38<00:27,  2.73it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 597/671 [03:38<00:27,  2.73it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  89%|████████▉ | 598/671 [03:38<00:26,  2.73it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  89%|████████▉ | 600/671 [03:39<00:25,  2.74it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  90%|████████▉ | 601/671 [03:39<00:25,  2.74it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  90%|████████▉ | 602/671 [03:39<00:25,  2.74it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  90%|████████▉ | 603/671 [03:39<00:24,  2.75it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  90%|█████████ | 604/671 [03:39<00:24,  2.75it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  90%|█████████ | 605/671 [03:39<00:23,  2.75it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  90%|█████████ | 606/671 [03:40<00:23,  2.75it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  90%|█████████ | 607/671 [03:40<00:23,  2.76it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  91%|█████████ | 608/671 [03:40<00:22,  2.76it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  91%|█████████ | 609/671 [03:40<00:22,  2.76it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  91%|█████████ | 610/671 [03:40<00:22,  2.76it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  91%|█████████ | 612/671 [03:41<00:21,  2.77it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  91%|█████████▏| 613/671 [03:41<00:20,  2.77it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  92%|█████████▏| 614/671 [03:41<00:20,  2.77it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  92%|█████████▏| 615/671 [03:41<00:20,  2.77it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  92%|█████████▏| 616/671 [03:41<00:19,  2.78it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  92%|█████████▏| 617/671 [03:41<00:19,  2.78it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  92%|█████████▏| 618/671 [03:42<00:19,  2.78it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  92%|█████████▏| 619/671 [03:42<00:18,  2.78it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  92%|█████████▏| 620/671 [03:42<00:18,  2.79it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  93%|█████████▎| 621/671 [03:42<00:17,  2.79it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  93%|█████████▎| 622/671 [03:42<00:17,  2.79it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  93%|█████████▎| 623/671 [03:42<00:17,  2.79it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  93%|█████████▎| 624/671 [03:43<00:16,  2.80it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  93%|█████████▎| 625/671 [03:43<00:16,  2.80it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  93%|█████████▎| 626/671 [03:43<00:16,  2.80it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  93%|█████████▎| 627/671 [03:43<00:15,  2.80it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  94%|█████████▎| 629/671 [03:44<00:14,  2.81it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  94%|█████████▍| 630/671 [03:44<00:14,  2.81it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  94%|█████████▍| 631/671 [03:44<00:14,  2.81it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  94%|█████████▍| 632/671 [03:44<00:13,  2.81it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  94%|█████████▍| 634/671 [03:44<00:13,  2.82it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  95%|█████████▍| 635/671 [03:45<00:12,  2.82it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  95%|█████████▍| 636/671 [03:45<00:12,  2.82it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  95%|█████████▍| 637/671 [03:45<00:12,  2.83it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  95%|█████████▌| 638/671 [03:45<00:11,  2.83it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  95%|█████████▌| 639/671 [03:45<00:11,  2.83it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  95%|█████████▌| 640/671 [03:45<00:10,  2.83it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  96%|█████████▌| 641/671 [03:46<00:10,  2.84it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  96%|█████████▌| 642/671 [03:46<00:10,  2.84it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  96%|█████████▌| 643/671 [03:46<00:09,  2.84it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  96%|█████████▌| 644/671 [03:46<00:09,  2.84it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  96%|█████████▌| 645/671 [03:46<00:09,  2.84it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  96%|█████████▋| 646/671 [03:46<00:08,  2.85it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  96%|█████████▋| 647/671 [03:47<00:08,  2.85it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  97%|█████████▋| 648/671 [03:47<00:08,  2.85it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  97%|█████████▋| 649/671 [03:47<00:07,  2.85it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  97%|█████████▋| 650/671 [03:47<00:07,  2.86it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  97%|█████████▋| 651/671 [03:47<00:06,  2.86it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  97%|█████████▋| 652/671 [03:47<00:06,  2.86it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  97%|█████████▋| 653/671 [03:48<00:06,  2.86it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  97%|█████████▋| 654/671 [03:48<00:05,  2.87it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  98%|█████████▊| 655/671 [03:48<00:05,  2.87it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  98%|█████████▊| 656/671 [03:48<00:05,  2.87it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  98%|█████████▊| 657/671 [03:48<00:04,  2.87it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  98%|█████████▊| 658/671 [03:48<00:04,  2.87it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  98%|█████████▊| 659/671 [03:49<00:04,  2.88it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  98%|█████████▊| 660/671 [03:49<00:03,  2.88it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  99%|█████████▊| 661/671 [03:49<00:03,  2.88it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  99%|█████████▊| 662/671 [03:49<00:03,  2.88it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  99%|█████████▉| 664/671 [03:49<00:02,  2.89it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  99%|█████████▉| 665/671 [03:50<00:02,  2.89it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  99%|█████████▉| 666/671 [03:50<00:01,  2.89it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4:  99%|█████████▉| 667/671 [03:50<00:01,  2.89it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4: 100%|█████████▉| 668/671 [03:50<00:01,  2.90it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4: 100%|█████████▉| 669/671 [03:50<00:00,  2.90it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4: 100%|█████████▉| 670/671 [03:50<00:00,  2.90it/s, loss=0.017, val_loss_step=0.0237, train_loss_step=0.0067, val_loss_epoch=0.0233, train_loss_epoch=0.0182]\n",
      "Epoch 4: 100%|██████████| 671/671 [03:51<00:00,  2.90it/s, loss=0.017, val_loss_step=0.0326, train_loss_step=0.0067, val_loss_epoch=0.0325, train_loss_epoch=0.0182]\n",
      "Epoch 5:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 597/671 [03:37<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  89%|████████▉ | 598/671 [03:38<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  89%|████████▉ | 600/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  90%|████████▉ | 602/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  90%|████████▉ | 603/671 [03:38<00:24,  2.75it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  90%|█████████ | 604/671 [03:39<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  90%|█████████ | 605/671 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  90%|█████████ | 606/671 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  90%|█████████ | 607/671 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  91%|█████████ | 609/671 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  91%|█████████ | 610/671 [03:40<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  91%|█████████ | 612/671 [03:40<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  92%|█████████▏| 614/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  92%|█████████▏| 615/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  92%|█████████▏| 616/671 [03:41<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  92%|█████████▏| 617/671 [03:41<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  92%|█████████▏| 618/671 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  92%|█████████▏| 619/671 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  92%|█████████▏| 620/671 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  93%|█████████▎| 621/671 [03:41<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  93%|█████████▎| 622/671 [03:42<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  93%|█████████▎| 623/671 [03:42<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  93%|█████████▎| 624/671 [03:42<00:16,  2.80it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  93%|█████████▎| 626/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  93%|█████████▎| 627/671 [03:43<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  94%|█████████▎| 629/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  94%|█████████▍| 631/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  94%|█████████▍| 632/671 [03:43<00:13,  2.82it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  94%|█████████▍| 633/671 [03:44<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  94%|█████████▍| 634/671 [03:44<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  95%|█████████▍| 635/671 [03:44<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  95%|█████████▍| 636/671 [03:44<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  95%|█████████▍| 637/671 [03:44<00:11,  2.83it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  95%|█████████▌| 639/671 [03:45<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  95%|█████████▌| 640/671 [03:45<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  96%|█████████▌| 641/671 [03:45<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  96%|█████████▌| 644/671 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  96%|█████████▌| 645/671 [03:46<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  96%|█████████▋| 646/671 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  96%|█████████▋| 647/671 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  97%|█████████▋| 648/671 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  97%|█████████▋| 649/671 [03:46<00:07,  2.86it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  97%|█████████▋| 650/671 [03:46<00:07,  2.86it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  97%|█████████▋| 651/671 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  97%|█████████▋| 652/671 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  97%|█████████▋| 653/671 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  97%|█████████▋| 654/671 [03:47<00:05,  2.87it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  98%|█████████▊| 657/671 [03:48<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  98%|█████████▊| 658/671 [03:48<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  98%|█████████▊| 659/671 [03:48<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  99%|█████████▊| 661/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  99%|█████████▊| 662/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  99%|█████████▉| 664/671 [03:49<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  99%|█████████▉| 665/671 [03:49<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  99%|█████████▉| 666/671 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5:  99%|█████████▉| 667/671 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5: 100%|█████████▉| 669/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5: 100%|█████████▉| 670/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0326, train_loss_step=0.0121, val_loss_epoch=0.0325, train_loss_epoch=0.0178]\n",
      "Epoch 5: 100%|██████████| 671/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0121, val_loss_epoch=0.0195, train_loss_epoch=0.0178]\n",
      "Epoch 6:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 597/671 [03:37<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  89%|████████▉ | 598/671 [03:38<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  89%|████████▉ | 600/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|████████▉ | 602/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  90%|████████▉ | 603/671 [03:38<00:24,  2.75it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|█████████ | 604/671 [03:39<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|█████████ | 605/671 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|█████████ | 606/671 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|█████████ | 607/671 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████ | 609/671 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████ | 610/671 [03:40<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████ | 612/671 [03:40<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 614/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 615/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 616/671 [03:41<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 617/671 [03:41<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 618/671 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 619/671 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 621/671 [03:41<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 622/671 [03:42<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 623/671 [03:42<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 624/671 [03:42<00:16,  2.80it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 626/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 627/671 [03:42<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▎| 629/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 631/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 632/671 [03:43<00:13,  2.82it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 633/671 [03:44<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 634/671 [03:44<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▍| 635/671 [03:44<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▍| 636/671 [03:44<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▍| 637/671 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▌| 639/671 [03:45<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▌| 640/671 [03:45<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 641/671 [03:45<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 644/671 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 645/671 [03:46<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▋| 646/671 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▋| 647/671 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 648/671 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 649/671 [03:46<00:07,  2.86it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 651/671 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  97%|█████████▋| 652/671 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 653/671 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 654/671 [03:47<00:05,  2.87it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 657/671 [03:48<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 658/671 [03:48<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 659/671 [03:48<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▊| 661/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▊| 662/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 664/671 [03:49<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 665/671 [03:49<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 666/671 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 667/671 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6: 100%|█████████▉| 669/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6: 100%|█████████▉| 670/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0174, train_loss_step=0.0194, val_loss_epoch=0.0195, train_loss_epoch=0.0177]\n",
      "Epoch 6: 100%|██████████| 671/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0169, train_loss_step=0.0194, val_loss_epoch=0.018, train_loss_epoch=0.0177] \n",
      "Epoch 7:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 597/671 [03:37<00:27,  2.74it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  89%|████████▉ | 598/671 [03:38<00:26,  2.74it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  89%|████████▉ | 600/671 [03:38<00:25,  2.75it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|████████▉ | 602/671 [03:38<00:25,  2.75it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|████████▉ | 603/671 [03:38<00:24,  2.75it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|█████████ | 604/671 [03:39<00:24,  2.76it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|█████████ | 605/671 [03:39<00:23,  2.76it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|█████████ | 606/671 [03:39<00:23,  2.76it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|█████████ | 607/671 [03:39<00:23,  2.76it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 609/671 [03:39<00:22,  2.77it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 610/671 [03:40<00:22,  2.77it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 612/671 [03:40<00:21,  2.78it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 614/671 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 615/671 [03:40<00:20,  2.78it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 616/671 [03:41<00:19,  2.79it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 617/671 [03:41<00:19,  2.79it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 618/671 [03:41<00:18,  2.79it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 619/671 [03:41<00:18,  2.79it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 621/671 [03:41<00:17,  2.80it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 622/671 [03:42<00:17,  2.80it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 623/671 [03:42<00:17,  2.80it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 624/671 [03:42<00:16,  2.80it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 626/671 [03:42<00:16,  2.81it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 627/671 [03:42<00:15,  2.81it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▎| 629/671 [03:43<00:14,  2.82it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 631/671 [03:43<00:14,  2.82it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 632/671 [03:43<00:13,  2.82it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 633/671 [03:44<00:13,  2.83it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 634/671 [03:44<00:13,  2.83it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▍| 635/671 [03:44<00:12,  2.83it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▍| 636/671 [03:44<00:12,  2.83it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▍| 637/671 [03:44<00:11,  2.84it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▌| 639/671 [03:45<00:11,  2.84it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▌| 640/671 [03:45<00:10,  2.84it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 641/671 [03:45<00:10,  2.84it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 644/671 [03:45<00:09,  2.85it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 645/671 [03:46<00:09,  2.85it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▋| 646/671 [03:46<00:08,  2.86it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▋| 647/671 [03:46<00:08,  2.86it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 648/671 [03:46<00:08,  2.86it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 649/671 [03:46<00:07,  2.86it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 651/671 [03:47<00:06,  2.87it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 652/671 [03:47<00:06,  2.87it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 653/671 [03:47<00:06,  2.87it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 654/671 [03:47<00:05,  2.87it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 657/671 [03:48<00:04,  2.88it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 658/671 [03:48<00:04,  2.88it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 659/671 [03:48<00:04,  2.89it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▊| 661/671 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▊| 662/671 [03:48<00:03,  2.89it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 664/671 [03:49<00:02,  2.90it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 665/671 [03:49<00:02,  2.90it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 666/671 [03:49<00:01,  2.90it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 667/671 [03:49<00:01,  2.90it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7: 100%|█████████▉| 669/671 [03:50<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7: 100%|█████████▉| 670/671 [03:50<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0169, train_loss_step=0.0256, val_loss_epoch=0.018, train_loss_epoch=0.0176]\n",
      "Epoch 7: 100%|██████████| 671/671 [03:50<00:00,  2.91it/s, loss=0.019, val_loss_step=0.0192, train_loss_step=0.0256, val_loss_epoch=0.0206, train_loss_epoch=0.0176]\n",
      "Epoch 8:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 597/671 [03:38<00:27,  2.74it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  89%|████████▉ | 598/671 [03:38<00:26,  2.74it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  89%|████████▉ | 600/671 [03:38<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|████████▉ | 602/671 [03:38<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|████████▉ | 603/671 [03:39<00:24,  2.75it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|█████████ | 604/671 [03:39<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|█████████ | 605/671 [03:39<00:23,  2.76it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|█████████ | 606/671 [03:39<00:23,  2.76it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  90%|█████████ | 607/671 [03:39<00:23,  2.76it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 608/671 [03:39<00:22,  2.76it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 609/671 [03:40<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 610/671 [03:40<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████ | 612/671 [03:40<00:21,  2.77it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 614/671 [03:40<00:20,  2.78it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 615/671 [03:41<00:20,  2.78it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 616/671 [03:41<00:19,  2.78it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 617/671 [03:41<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 618/671 [03:41<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 619/671 [03:41<00:18,  2.79it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  92%|█████████▏| 620/671 [03:41<00:18,  2.79it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 621/671 [03:42<00:17,  2.80it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 622/671 [03:42<00:17,  2.80it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 623/671 [03:42<00:17,  2.80it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 624/671 [03:42<00:16,  2.80it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 626/671 [03:42<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  93%|█████████▎| 627/671 [03:43<00:15,  2.81it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▎| 629/671 [03:43<00:14,  2.81it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 631/671 [03:43<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 632/671 [03:43<00:13,  2.82it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  94%|█████████▍| 634/671 [03:44<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▍| 635/671 [03:44<00:12,  2.83it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▍| 636/671 [03:44<00:12,  2.83it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▍| 637/671 [03:44<00:11,  2.83it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▌| 639/671 [03:45<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  95%|█████████▌| 640/671 [03:45<00:10,  2.84it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 641/671 [03:45<00:10,  2.84it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 644/671 [03:45<00:09,  2.85it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▌| 645/671 [03:46<00:09,  2.85it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  96%|█████████▋| 646/671 [03:46<00:08,  2.85it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  96%|█████████▋| 647/671 [03:46<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 648/671 [03:46<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 649/671 [03:46<00:07,  2.86it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 650/671 [03:46<00:07,  2.86it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 651/671 [03:47<00:06,  2.87it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 652/671 [03:47<00:06,  2.87it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 653/671 [03:47<00:06,  2.87it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  97%|█████████▋| 654/671 [03:47<00:05,  2.87it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 655/671 [03:47<00:05,  2.87it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 656/671 [03:48<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 657/671 [03:48<00:04,  2.88it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 658/671 [03:48<00:04,  2.88it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 659/671 [03:48<00:04,  2.88it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▊| 661/671 [03:48<00:03,  2.89it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▊| 662/671 [03:49<00:03,  2.89it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 664/671 [03:49<00:02,  2.89it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 665/671 [03:49<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 666/671 [03:49<00:01,  2.90it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8:  99%|█████████▉| 667/671 [03:49<00:01,  2.90it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8: 100%|█████████▉| 668/671 [03:50<00:01,  2.90it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8: 100%|█████████▉| 669/671 [03:50<00:00,  2.91it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8: 100%|█████████▉| 670/671 [03:50<00:00,  2.91it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0187, val_loss_epoch=0.0206, train_loss_epoch=0.0174]\n",
      "Epoch 8: 100%|██████████| 671/671 [03:50<00:00,  2.91it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0187, val_loss_epoch=0.0281, train_loss_epoch=0.0174]\n",
      "Epoch 9:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 597/671 [03:37<00:26,  2.74it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  89%|████████▉ | 600/671 [03:37<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  90%|████████▉ | 602/671 [03:38<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  90%|█████████ | 604/671 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  90%|█████████ | 605/671 [03:38<00:23,  2.76it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  90%|█████████ | 606/671 [03:39<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  90%|█████████ | 607/671 [03:39<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  91%|█████████ | 609/671 [03:39<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  91%|█████████ | 612/671 [03:40<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  92%|█████████▏| 614/671 [03:40<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  92%|█████████▏| 616/671 [03:40<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  92%|█████████▏| 617/671 [03:40<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  92%|█████████▏| 618/671 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  92%|█████████▏| 619/671 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  93%|█████████▎| 621/671 [03:41<00:17,  2.80it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  93%|█████████▎| 624/671 [03:42<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  93%|█████████▎| 626/671 [03:42<00:15,  2.81it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  94%|█████████▎| 629/671 [03:42<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  94%|█████████▍| 631/671 [03:43<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  94%|█████████▍| 633/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  94%|█████████▍| 634/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  95%|█████████▍| 636/671 [03:44<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  95%|█████████▍| 637/671 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  96%|█████████▋| 646/671 [03:45<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  96%|█████████▋| 647/671 [03:45<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  97%|█████████▋| 648/671 [03:46<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  97%|█████████▋| 649/671 [03:46<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  97%|█████████▋| 651/671 [03:46<00:06,  2.87it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  97%|█████████▋| 654/671 [03:47<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  98%|█████████▊| 659/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  99%|█████████▊| 661/671 [03:48<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  99%|█████████▉| 664/671 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  99%|█████████▉| 665/671 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  99%|█████████▉| 666/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9:  99%|█████████▉| 667/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████▉| 669/671 [03:49<00:00,  2.91it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0281, train_loss_step=0.0091, val_loss_epoch=0.0281, train_loss_epoch=0.0173]\n",
      "Epoch 9: 100%|██████████| 671/671 [03:50<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0091, val_loss_epoch=0.0274, train_loss_epoch=0.0173]\n",
      "Epoch 10:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 597/671 [03:37<00:26,  2.74it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  89%|████████▉ | 600/671 [03:38<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  90%|████████▉ | 602/671 [03:38<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  90%|█████████ | 604/671 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  90%|█████████ | 605/671 [03:38<00:23,  2.76it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  90%|█████████ | 606/671 [03:39<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  90%|█████████ | 607/671 [03:39<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  91%|█████████ | 609/671 [03:39<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  91%|█████████ | 612/671 [03:40<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  92%|█████████▏| 614/671 [03:40<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  92%|█████████▏| 616/671 [03:40<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  92%|█████████▏| 617/671 [03:40<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  92%|█████████▏| 618/671 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  92%|█████████▏| 619/671 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  93%|█████████▎| 621/671 [03:41<00:17,  2.80it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  93%|█████████▎| 622/671 [03:41<00:17,  2.80it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  93%|█████████▎| 624/671 [03:42<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  93%|█████████▎| 626/671 [03:42<00:15,  2.81it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  94%|█████████▎| 629/671 [03:42<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  94%|█████████▍| 631/671 [03:43<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  94%|█████████▍| 633/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  94%|█████████▍| 634/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  95%|█████████▍| 636/671 [03:44<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  95%|█████████▍| 637/671 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  95%|█████████▌| 639/671 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  96%|█████████▋| 646/671 [03:45<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  96%|█████████▋| 647/671 [03:45<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  97%|█████████▋| 648/671 [03:46<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  97%|█████████▋| 649/671 [03:46<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  97%|█████████▋| 651/671 [03:46<00:06,  2.87it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  97%|█████████▋| 652/671 [03:46<00:06,  2.87it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  97%|█████████▋| 654/671 [03:47<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  98%|█████████▊| 659/671 [03:48<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  99%|█████████▊| 661/671 [03:48<00:03,  2.89it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  99%|█████████▉| 664/671 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  99%|█████████▉| 665/671 [03:49<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  99%|█████████▉| 666/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10:  99%|█████████▉| 667/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10: 100%|█████████▉| 669/671 [03:49<00:00,  2.91it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0286, train_loss_step=0.0108, val_loss_epoch=0.0274, train_loss_epoch=0.0171]\n",
      "Epoch 10: 100%|██████████| 671/671 [03:50<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0224, train_loss_step=0.0108, val_loss_epoch=0.0238, train_loss_epoch=0.0171]\n",
      "Epoch 11:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  89%|████████▉ | 597/671 [03:37<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  89%|████████▉ | 600/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|████████▉ | 602/671 [03:38<00:25,  2.76it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|█████████ | 604/671 [03:38<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|█████████ | 605/671 [03:38<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|█████████ | 606/671 [03:39<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|█████████ | 607/671 [03:39<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 609/671 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 612/671 [03:40<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 614/671 [03:40<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 616/671 [03:40<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 617/671 [03:40<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 618/671 [03:41<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 619/671 [03:41<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 621/671 [03:41<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 624/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 626/671 [03:42<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▎| 629/671 [03:42<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 631/671 [03:43<00:14,  2.83it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 633/671 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 634/671 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▍| 636/671 [03:44<00:12,  2.84it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▍| 637/671 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▋| 646/671 [03:45<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▋| 647/671 [03:45<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 648/671 [03:46<00:08,  2.87it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 649/671 [03:46<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 651/671 [03:46<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 652/671 [03:46<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 654/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 659/671 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▊| 661/671 [03:48<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  99%|█████████▉| 664/671 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▉| 665/671 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▉| 666/671 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▉| 667/671 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11: 100%|█████████▉| 669/671 [03:49<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0224, train_loss_step=0.0255, val_loss_epoch=0.0238, train_loss_epoch=0.017]\n",
      "Epoch 11: 100%|██████████| 671/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.0255, val_loss_epoch=0.0176, train_loss_epoch=0.017]\n",
      "Epoch 12:  89%|████████▉ | 596/671 [03:37<00:27,  2.75it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 597/671 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  89%|████████▉ | 600/671 [03:37<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  90%|████████▉ | 601/671 [03:38<00:25,  2.76it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  90%|████████▉ | 602/671 [03:38<00:25,  2.76it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  90%|█████████ | 604/671 [03:38<00:24,  2.76it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  90%|█████████ | 605/671 [03:38<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  90%|█████████ | 606/671 [03:38<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  90%|█████████ | 607/671 [03:39<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  91%|█████████ | 609/671 [03:39<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  91%|█████████ | 612/671 [03:39<00:21,  2.78it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  92%|█████████▏| 614/671 [03:40<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  92%|█████████▏| 616/671 [03:40<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  92%|█████████▏| 617/671 [03:40<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  92%|█████████▏| 618/671 [03:40<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  92%|█████████▏| 619/671 [03:41<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  93%|█████████▎| 621/671 [03:41<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  93%|█████████▎| 624/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  93%|█████████▎| 626/671 [03:42<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  94%|█████████▎| 629/671 [03:42<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  94%|█████████▍| 631/671 [03:43<00:14,  2.83it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  94%|█████████▍| 633/671 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  94%|█████████▍| 634/671 [03:43<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  95%|█████████▍| 636/671 [03:44<00:12,  2.84it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  95%|█████████▍| 637/671 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  96%|█████████▌| 643/671 [03:45<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  96%|█████████▋| 646/671 [03:45<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  96%|█████████▋| 647/671 [03:45<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  97%|█████████▋| 648/671 [03:46<00:08,  2.87it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  97%|█████████▋| 649/671 [03:46<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  97%|█████████▋| 651/671 [03:46<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  97%|█████████▋| 654/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  98%|█████████▊| 659/671 [03:47<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  99%|█████████▊| 661/671 [03:48<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  99%|█████████▉| 664/671 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  99%|█████████▉| 665/671 [03:48<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  99%|█████████▉| 666/671 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12:  99%|█████████▉| 667/671 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12: 100%|█████████▉| 669/671 [03:49<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0153, train_loss_step=0.029, val_loss_epoch=0.0176, train_loss_epoch=0.0168]\n",
      "Epoch 12: 100%|██████████| 671/671 [03:50<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0193, train_loss_step=0.029, val_loss_epoch=0.0237, train_loss_epoch=0.0168]\n",
      "Epoch 13:  89%|████████▉ | 596/671 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  89%|████████▉ | 597/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  90%|████████▉ | 601/671 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  90%|████████▉ | 602/671 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  90%|█████████ | 604/671 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  90%|█████████ | 605/671 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  90%|█████████ | 606/671 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  90%|█████████ | 607/671 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  91%|█████████ | 609/671 [03:39<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  91%|█████████ | 612/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  91%|█████████▏| 613/671 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  92%|█████████▏| 614/671 [03:40<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  92%|█████████▏| 616/671 [03:40<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  92%|█████████▏| 617/671 [03:40<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  92%|█████████▏| 618/671 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  92%|█████████▏| 619/671 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  93%|█████████▎| 621/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  93%|█████████▎| 624/671 [03:41<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  93%|█████████▎| 625/671 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  93%|█████████▎| 626/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  94%|█████████▎| 629/671 [03:42<00:14,  2.82it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  94%|█████████▍| 630/671 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  94%|█████████▍| 631/671 [03:43<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  94%|█████████▍| 633/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  94%|█████████▍| 634/671 [03:43<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  95%|█████████▍| 636/671 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  95%|█████████▍| 637/671 [03:44<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  95%|█████████▌| 638/671 [03:44<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  96%|█████████▌| 642/671 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  96%|█████████▌| 643/671 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  96%|█████████▋| 646/671 [03:45<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  96%|█████████▋| 647/671 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  97%|█████████▋| 648/671 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  97%|█████████▋| 649/671 [03:46<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  97%|█████████▋| 651/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  97%|█████████▋| 654/671 [03:46<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  98%|█████████▊| 656/671 [03:47<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  98%|█████████▊| 659/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  98%|█████████▊| 660/671 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  99%|█████████▊| 661/671 [03:48<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  99%|█████████▉| 664/671 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  99%|█████████▉| 665/671 [03:48<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  99%|█████████▉| 666/671 [03:48<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13:  99%|█████████▉| 667/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13: 100%|█████████▉| 669/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0193, train_loss_step=0.0211, val_loss_epoch=0.0237, train_loss_epoch=0.0167]\n",
      "Epoch 13: 100%|██████████| 671/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0165, train_loss_step=0.0211, val_loss_epoch=0.0184, train_loss_epoch=0.0167]\n",
      "Epoch 14:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  89%|████████▉ | 597/671 [03:37<00:26,  2.74it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  89%|████████▉ | 600/671 [03:38<00:25,  2.75it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  90%|████████▉ | 602/671 [03:38<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  90%|█████████ | 604/671 [03:38<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  90%|█████████ | 605/671 [03:38<00:23,  2.76it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  90%|█████████ | 606/671 [03:39<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  90%|█████████ | 607/671 [03:39<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  91%|█████████ | 609/671 [03:39<00:22,  2.77it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  91%|█████████ | 612/671 [03:40<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  92%|█████████▏| 614/671 [03:40<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  92%|█████████▏| 616/671 [03:40<00:19,  2.79it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  92%|█████████▏| 617/671 [03:40<00:19,  2.79it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  92%|█████████▏| 618/671 [03:41<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  92%|█████████▏| 619/671 [03:41<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  93%|█████████▎| 621/671 [03:41<00:17,  2.80it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  93%|█████████▎| 622/671 [03:41<00:17,  2.80it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  93%|█████████▎| 624/671 [03:42<00:16,  2.81it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  93%|█████████▎| 626/671 [03:42<00:15,  2.81it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  94%|█████████▎| 629/671 [03:42<00:14,  2.82it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  94%|█████████▍| 631/671 [03:43<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  94%|█████████▍| 633/671 [03:43<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  94%|█████████▍| 634/671 [03:43<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  95%|█████████▍| 636/671 [03:44<00:12,  2.84it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  95%|█████████▍| 637/671 [03:44<00:11,  2.84it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  95%|█████████▌| 639/671 [03:44<00:11,  2.84it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  96%|█████████▋| 646/671 [03:45<00:08,  2.86it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  96%|█████████▋| 647/671 [03:45<00:08,  2.86it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  97%|█████████▋| 648/671 [03:46<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  97%|█████████▋| 649/671 [03:46<00:07,  2.87it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  97%|█████████▋| 651/671 [03:46<00:06,  2.87it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  97%|█████████▋| 652/671 [03:46<00:06,  2.87it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  97%|█████████▋| 654/671 [03:47<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  98%|█████████▊| 659/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  99%|█████████▊| 661/671 [03:48<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  99%|█████████▉| 664/671 [03:48<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  99%|█████████▉| 665/671 [03:48<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  99%|█████████▉| 666/671 [03:49<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14:  99%|█████████▉| 667/671 [03:49<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14: 100%|█████████▉| 669/671 [03:49<00:00,  2.91it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.018, val_loss_epoch=0.0184, train_loss_epoch=0.0166]\n",
      "Epoch 14: 100%|██████████| 671/671 [03:50<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0153, train_loss_step=0.018, val_loss_epoch=0.0181, train_loss_epoch=0.0166]\n",
      "Epoch 15:  89%|████████▉ | 596/671 [03:36<00:27,  2.75it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  89%|████████▉ | 597/671 [03:37<00:26,  2.75it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  90%|████████▉ | 601/671 [03:37<00:25,  2.76it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  90%|████████▉ | 602/671 [03:38<00:24,  2.76it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  90%|█████████ | 604/671 [03:38<00:24,  2.77it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  90%|█████████ | 605/671 [03:38<00:23,  2.77it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  90%|█████████ | 606/671 [03:38<00:23,  2.77it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  90%|█████████ | 607/671 [03:38<00:23,  2.77it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  91%|█████████ | 608/671 [03:39<00:22,  2.78it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  91%|█████████ | 609/671 [03:39<00:22,  2.78it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  91%|█████████ | 612/671 [03:39<00:21,  2.79it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  91%|█████████▏| 613/671 [03:39<00:20,  2.79it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  92%|█████████▏| 614/671 [03:40<00:20,  2.79it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  92%|█████████▏| 616/671 [03:40<00:19,  2.79it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  92%|█████████▏| 617/671 [03:40<00:19,  2.80it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  92%|█████████▏| 618/671 [03:40<00:18,  2.80it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  92%|█████████▏| 619/671 [03:40<00:18,  2.80it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  93%|█████████▎| 621/671 [03:41<00:17,  2.81it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  93%|█████████▎| 624/671 [03:41<00:16,  2.81it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  93%|█████████▎| 625/671 [03:41<00:16,  2.82it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  93%|█████████▎| 626/671 [03:42<00:15,  2.82it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  94%|█████████▎| 629/671 [03:42<00:14,  2.83it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  94%|█████████▍| 630/671 [03:42<00:14,  2.83it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  94%|█████████▍| 631/671 [03:42<00:14,  2.83it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  94%|█████████▍| 633/671 [03:43<00:13,  2.84it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  94%|█████████▍| 634/671 [03:43<00:13,  2.84it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  95%|█████████▍| 636/671 [03:43<00:12,  2.84it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  95%|█████████▍| 637/671 [03:43<00:11,  2.84it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  95%|█████████▌| 638/671 [03:44<00:11,  2.85it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  96%|█████████▌| 642/671 [03:44<00:10,  2.86it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  96%|█████████▌| 643/671 [03:44<00:09,  2.86it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  96%|█████████▋| 646/671 [03:45<00:08,  2.87it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  96%|█████████▋| 647/671 [03:45<00:08,  2.87it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  97%|█████████▋| 648/671 [03:45<00:08,  2.87it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  97%|█████████▋| 649/671 [03:45<00:07,  2.87it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  97%|█████████▋| 651/671 [03:46<00:06,  2.88it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  97%|█████████▋| 654/671 [03:46<00:05,  2.88it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  98%|█████████▊| 655/671 [03:46<00:05,  2.89it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  98%|█████████▊| 656/671 [03:47<00:05,  2.89it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  98%|█████████▊| 659/671 [03:47<00:04,  2.89it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  98%|█████████▊| 660/671 [03:47<00:03,  2.90it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  99%|█████████▊| 661/671 [03:47<00:03,  2.90it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  99%|█████████▉| 664/671 [03:48<00:02,  2.91it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  99%|█████████▉| 665/671 [03:48<00:02,  2.91it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  99%|█████████▉| 666/671 [03:48<00:01,  2.91it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15:  99%|█████████▉| 667/671 [03:48<00:01,  2.91it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15: 100%|█████████▉| 668/671 [03:49<00:01,  2.92it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15: 100%|█████████▉| 669/671 [03:49<00:00,  2.92it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.00995, val_loss_epoch=0.0181, train_loss_epoch=0.0164]\n",
      "Epoch 15: 100%|██████████| 671/671 [03:49<00:00,  2.92it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.00995, val_loss_epoch=0.0166, train_loss_epoch=0.0164]\n",
      "Epoch 16:  89%|████████▉ | 596/671 [03:37<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  89%|████████▉ | 597/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  89%|████████▉ | 600/671 [03:37<00:25,  2.75it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  90%|████████▉ | 601/671 [03:38<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  90%|████████▉ | 602/671 [03:38<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  90%|█████████ | 604/671 [03:38<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  90%|█████████ | 605/671 [03:38<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  90%|█████████ | 606/671 [03:38<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  90%|█████████ | 607/671 [03:39<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  91%|█████████ | 609/671 [03:39<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  91%|█████████ | 612/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  92%|█████████▏| 614/671 [03:40<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  92%|█████████▏| 616/671 [03:40<00:19,  2.79it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  92%|█████████▏| 617/671 [03:40<00:19,  2.79it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  92%|█████████▏| 618/671 [03:40<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  92%|█████████▏| 619/671 [03:41<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  93%|█████████▎| 621/671 [03:41<00:17,  2.80it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  93%|█████████▎| 624/671 [03:41<00:16,  2.81it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  93%|█████████▎| 626/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  94%|█████████▎| 629/671 [03:42<00:14,  2.82it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  94%|█████████▍| 630/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  94%|█████████▍| 631/671 [03:43<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  94%|█████████▍| 633/671 [03:43<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  94%|█████████▍| 634/671 [03:43<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  95%|█████████▍| 636/671 [03:43<00:12,  2.84it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  95%|█████████▍| 637/671 [03:44<00:11,  2.84it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  96%|█████████▌| 643/671 [03:45<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  96%|█████████▋| 646/671 [03:45<00:08,  2.86it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  96%|█████████▋| 647/671 [03:45<00:08,  2.86it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  97%|█████████▋| 648/671 [03:46<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  97%|█████████▋| 649/671 [03:46<00:07,  2.87it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  97%|█████████▋| 651/671 [03:46<00:06,  2.87it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  97%|█████████▋| 654/671 [03:47<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  98%|█████████▊| 656/671 [03:47<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  98%|█████████▊| 659/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  99%|█████████▊| 661/671 [03:48<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  99%|█████████▉| 664/671 [03:48<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  99%|█████████▉| 665/671 [03:48<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  99%|█████████▉| 666/671 [03:49<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16:  99%|█████████▉| 667/671 [03:49<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16: 100%|█████████▉| 669/671 [03:49<00:00,  2.91it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.015, val_loss_epoch=0.0166, train_loss_epoch=0.0163]\n",
      "Epoch 16: 100%|██████████| 671/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0143, train_loss_step=0.015, val_loss_epoch=0.017, train_loss_epoch=0.0163] \n",
      "Epoch 17:  89%|████████▉ | 596/671 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  89%|████████▉ | 597/671 [03:36<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  89%|████████▉ | 599/671 [03:37<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  90%|████████▉ | 601/671 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  90%|████████▉ | 602/671 [03:37<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  90%|████████▉ | 603/671 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  90%|█████████ | 604/671 [03:38<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  90%|█████████ | 605/671 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  90%|█████████ | 606/671 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  90%|█████████ | 607/671 [03:38<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  91%|█████████ | 608/671 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  91%|█████████ | 609/671 [03:39<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  91%|█████████ | 611/671 [03:39<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  91%|█████████ | 612/671 [03:39<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  91%|█████████▏| 613/671 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  92%|█████████▏| 614/671 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  92%|█████████▏| 615/671 [03:40<00:20,  2.80it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  92%|█████████▏| 616/671 [03:40<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  92%|█████████▏| 617/671 [03:40<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  92%|█████████▏| 618/671 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  92%|█████████▏| 619/671 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  92%|█████████▏| 620/671 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  93%|█████████▎| 621/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  93%|█████████▎| 624/671 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  93%|█████████▎| 625/671 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  93%|█████████▎| 626/671 [03:41<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  94%|█████████▎| 628/671 [03:42<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  94%|█████████▎| 629/671 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  94%|█████████▍| 630/671 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  94%|█████████▍| 631/671 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  94%|█████████▍| 632/671 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  94%|█████████▍| 633/671 [03:43<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  94%|█████████▍| 634/671 [03:43<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  95%|█████████▍| 636/671 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  95%|█████████▍| 637/671 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  95%|█████████▌| 638/671 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  96%|█████████▌| 641/671 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  96%|█████████▌| 642/671 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  96%|█████████▌| 643/671 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  96%|█████████▌| 644/671 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  96%|█████████▌| 645/671 [03:45<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  96%|█████████▋| 646/671 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  96%|█████████▋| 647/671 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  97%|█████████▋| 648/671 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  97%|█████████▋| 649/671 [03:45<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  97%|█████████▋| 650/671 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  97%|█████████▋| 651/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  97%|█████████▋| 654/671 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  98%|█████████▊| 655/671 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  98%|█████████▊| 656/671 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  98%|█████████▊| 659/671 [03:47<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  98%|█████████▊| 660/671 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  99%|█████████▊| 661/671 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  99%|█████████▊| 662/671 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  99%|█████████▉| 663/671 [03:48<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  99%|█████████▉| 664/671 [03:48<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  99%|█████████▉| 665/671 [03:48<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  99%|█████████▉| 666/671 [03:48<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17:  99%|█████████▉| 667/671 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17: 100%|█████████▉| 668/671 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17: 100%|█████████▉| 669/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0143, train_loss_step=0.0157, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 17: 100%|██████████| 671/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0157, val_loss_epoch=0.0165, train_loss_epoch=0.0162]\n",
      "Epoch 18:  89%|████████▉ | 596/671 [03:36<00:27,  2.75it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  89%|████████▉ | 597/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  90%|████████▉ | 601/671 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  90%|████████▉ | 602/671 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  90%|█████████ | 604/671 [03:38<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  90%|█████████ | 605/671 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  90%|█████████ | 606/671 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  90%|█████████ | 607/671 [03:38<00:23,  2.77it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  91%|█████████ | 609/671 [03:39<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  91%|█████████ | 612/671 [03:39<00:21,  2.78it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  91%|█████████▏| 613/671 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  92%|█████████▏| 614/671 [03:40<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  92%|█████████▏| 616/671 [03:40<00:19,  2.79it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  92%|█████████▏| 617/671 [03:40<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  92%|█████████▏| 618/671 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  92%|█████████▏| 619/671 [03:40<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  92%|█████████▏| 620/671 [03:41<00:18,  2.80it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  93%|█████████▎| 621/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  93%|█████████▎| 624/671 [03:41<00:16,  2.81it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  93%|█████████▎| 625/671 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  93%|█████████▎| 626/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  94%|█████████▎| 629/671 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  94%|█████████▍| 630/671 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  94%|█████████▍| 631/671 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  94%|█████████▍| 633/671 [03:43<00:13,  2.83it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  94%|█████████▍| 634/671 [03:43<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  95%|█████████▍| 636/671 [03:43<00:12,  2.84it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  95%|█████████▍| 637/671 [03:43<00:11,  2.84it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  95%|█████████▌| 638/671 [03:44<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  96%|█████████▌| 642/671 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  96%|█████████▌| 643/671 [03:44<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  96%|█████████▋| 646/671 [03:45<00:08,  2.86it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  96%|█████████▋| 647/671 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  97%|█████████▋| 648/671 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  97%|█████████▋| 649/671 [03:45<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  97%|█████████▋| 650/671 [03:46<00:07,  2.87it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  97%|█████████▋| 651/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  97%|█████████▋| 654/671 [03:46<00:05,  2.88it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  98%|█████████▊| 655/671 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  98%|█████████▊| 656/671 [03:47<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  98%|█████████▊| 659/671 [03:47<00:04,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  98%|█████████▊| 660/671 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  99%|█████████▊| 661/671 [03:48<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  99%|█████████▉| 664/671 [03:48<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  99%|█████████▉| 665/671 [03:48<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  99%|█████████▉| 666/671 [03:48<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18:  99%|█████████▉| 667/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18: 100%|█████████▉| 669/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n",
      "Epoch 18: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.0272, val_loss_epoch=0.0165, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 671/671 [03:50<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0136, train_loss_step=0.0272, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  89%|████████▉ | 597/671 [03:37<00:27,  2.74it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  89%|████████▉ | 598/671 [03:38<00:26,  2.74it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  89%|████████▉ | 600/671 [03:38<00:25,  2.75it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  90%|████████▉ | 602/671 [03:38<00:25,  2.75it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  90%|████████▉ | 603/671 [03:39<00:24,  2.75it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  90%|█████████ | 604/671 [03:39<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  90%|█████████ | 605/671 [03:39<00:23,  2.76it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  90%|█████████ | 606/671 [03:39<00:23,  2.76it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  90%|█████████ | 607/671 [03:39<00:23,  2.76it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  91%|█████████ | 609/671 [03:40<00:22,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  91%|█████████ | 610/671 [03:40<00:22,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  91%|█████████ | 612/671 [03:40<00:21,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  92%|█████████▏| 614/671 [03:40<00:20,  2.78it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  92%|█████████▏| 615/671 [03:41<00:20,  2.78it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  92%|█████████▏| 616/671 [03:41<00:19,  2.78it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  92%|█████████▏| 617/671 [03:41<00:19,  2.79it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  92%|█████████▏| 618/671 [03:41<00:19,  2.79it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  92%|█████████▏| 619/671 [03:41<00:18,  2.79it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  92%|█████████▏| 620/671 [03:41<00:18,  2.79it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  93%|█████████▎| 621/671 [03:42<00:17,  2.80it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  93%|█████████▎| 622/671 [03:42<00:17,  2.80it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  93%|█████████▎| 623/671 [03:42<00:17,  2.80it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  93%|█████████▎| 624/671 [03:42<00:16,  2.80it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  93%|█████████▎| 626/671 [03:42<00:16,  2.81it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  93%|█████████▎| 627/671 [03:43<00:15,  2.81it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  94%|█████████▎| 629/671 [03:43<00:14,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  94%|█████████▍| 631/671 [03:43<00:14,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  94%|█████████▍| 632/671 [03:43<00:13,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  94%|█████████▍| 634/671 [03:44<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  95%|█████████▍| 635/671 [03:44<00:12,  2.83it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  95%|█████████▍| 636/671 [03:44<00:12,  2.83it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  95%|█████████▍| 637/671 [03:44<00:12,  2.83it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  95%|█████████▌| 638/671 [03:45<00:11,  2.84it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  95%|█████████▌| 639/671 [03:45<00:11,  2.84it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  95%|█████████▌| 640/671 [03:45<00:10,  2.84it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  96%|█████████▌| 641/671 [03:45<00:10,  2.84it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  96%|█████████▌| 642/671 [03:45<00:10,  2.84it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  96%|█████████▌| 644/671 [03:46<00:09,  2.85it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  96%|█████████▌| 645/671 [03:46<00:09,  2.85it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  96%|█████████▋| 646/671 [03:46<00:08,  2.85it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  96%|█████████▋| 647/671 [03:46<00:08,  2.86it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  97%|█████████▋| 648/671 [03:46<00:08,  2.86it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  97%|█████████▋| 649/671 [03:46<00:07,  2.86it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  97%|█████████▋| 650/671 [03:47<00:07,  2.86it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  97%|█████████▋| 651/671 [03:47<00:06,  2.86it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  97%|█████████▋| 652/671 [03:47<00:06,  2.87it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  97%|█████████▋| 653/671 [03:47<00:06,  2.87it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  97%|█████████▋| 654/671 [03:47<00:05,  2.87it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  98%|█████████▊| 655/671 [03:47<00:05,  2.87it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  98%|█████████▊| 656/671 [03:48<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  98%|█████████▊| 657/671 [03:48<00:04,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  98%|█████████▊| 658/671 [03:48<00:04,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  98%|█████████▊| 659/671 [03:48<00:04,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  98%|█████████▊| 660/671 [03:48<00:03,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  99%|█████████▊| 661/671 [03:48<00:03,  2.89it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  99%|█████████▊| 662/671 [03:49<00:03,  2.89it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  99%|█████████▉| 664/671 [03:49<00:02,  2.89it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  99%|█████████▉| 665/671 [03:49<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  99%|█████████▉| 666/671 [03:49<00:01,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19:  99%|█████████▉| 667/671 [03:49<00:01,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19: 100%|█████████▉| 668/671 [03:50<00:01,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19: 100%|█████████▉| 669/671 [03:50<00:00,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19: 100%|█████████▉| 670/671 [03:50<00:00,  2.91it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0164, train_loss_epoch=0.0161]\n",
      "Epoch 19: 100%|██████████| 671/671 [03:50<00:00,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0125, val_loss_epoch=0.0163, train_loss_epoch=0.0161]\n",
      "Epoch 20:  89%|████████▉ | 596/671 [03:37<00:27,  2.74it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  89%|████████▉ | 597/671 [03:38<00:27,  2.74it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  89%|████████▉ | 598/671 [03:38<00:26,  2.74it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  89%|████████▉ | 600/671 [03:38<00:25,  2.75it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  90%|████████▉ | 602/671 [03:38<00:25,  2.75it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  90%|████████▉ | 603/671 [03:39<00:24,  2.75it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  90%|█████████ | 604/671 [03:39<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  90%|█████████ | 605/671 [03:39<00:23,  2.76it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  90%|█████████ | 606/671 [03:39<00:23,  2.76it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  90%|█████████ | 607/671 [03:39<00:23,  2.76it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  91%|█████████ | 608/671 [03:39<00:22,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  91%|█████████ | 609/671 [03:40<00:22,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  91%|█████████ | 610/671 [03:40<00:22,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  91%|█████████ | 612/671 [03:40<00:21,  2.77it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  92%|█████████▏| 614/671 [03:40<00:20,  2.78it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  92%|█████████▏| 615/671 [03:41<00:20,  2.78it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  92%|█████████▏| 616/671 [03:41<00:19,  2.78it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  92%|█████████▏| 617/671 [03:41<00:19,  2.79it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  92%|█████████▏| 618/671 [03:41<00:19,  2.79it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  92%|█████████▏| 619/671 [03:41<00:18,  2.79it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  92%|█████████▏| 620/671 [03:41<00:18,  2.79it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  93%|█████████▎| 621/671 [03:42<00:17,  2.80it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  93%|█████████▎| 622/671 [03:42<00:17,  2.80it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  93%|█████████▎| 623/671 [03:42<00:17,  2.80it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  93%|█████████▎| 624/671 [03:42<00:16,  2.80it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  93%|█████████▎| 626/671 [03:42<00:16,  2.81it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  93%|█████████▎| 627/671 [03:43<00:15,  2.81it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  94%|█████████▎| 629/671 [03:43<00:14,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  94%|█████████▍| 631/671 [03:43<00:14,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  94%|█████████▍| 632/671 [03:43<00:13,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  94%|█████████▍| 634/671 [03:44<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  95%|█████████▍| 635/671 [03:44<00:12,  2.83it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  95%|█████████▍| 636/671 [03:44<00:12,  2.83it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  95%|█████████▍| 637/671 [03:44<00:11,  2.83it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  95%|█████████▌| 639/671 [03:45<00:11,  2.84it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  95%|█████████▌| 640/671 [03:45<00:10,  2.84it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  96%|█████████▌| 641/671 [03:45<00:10,  2.84it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  96%|█████████▌| 644/671 [03:45<00:09,  2.85it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  96%|█████████▌| 645/671 [03:46<00:09,  2.85it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  96%|█████████▋| 646/671 [03:46<00:08,  2.85it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  96%|█████████▋| 647/671 [03:46<00:08,  2.86it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  97%|█████████▋| 648/671 [03:46<00:08,  2.86it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  97%|█████████▋| 649/671 [03:46<00:07,  2.86it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  97%|█████████▋| 650/671 [03:46<00:07,  2.86it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  97%|█████████▋| 651/671 [03:47<00:06,  2.87it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  97%|█████████▋| 652/671 [03:47<00:06,  2.87it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  97%|█████████▋| 653/671 [03:47<00:06,  2.87it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  97%|█████████▋| 654/671 [03:47<00:05,  2.87it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  98%|█████████▊| 657/671 [03:48<00:04,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  98%|█████████▊| 658/671 [03:48<00:04,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  98%|█████████▊| 659/671 [03:48<00:04,  2.88it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  99%|█████████▊| 661/671 [03:48<00:03,  2.89it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  99%|█████████▊| 662/671 [03:48<00:03,  2.89it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  99%|█████████▉| 664/671 [03:49<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  99%|█████████▉| 665/671 [03:49<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  99%|█████████▉| 666/671 [03:49<00:01,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20:  99%|█████████▉| 667/671 [03:49<00:01,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20: 100%|█████████▉| 668/671 [03:49<00:01,  2.90it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20: 100%|█████████▉| 669/671 [03:50<00:00,  2.91it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20: 100%|█████████▉| 670/671 [03:50<00:00,  2.91it/s, loss=0.016, val_loss_step=0.0136, train_loss_step=0.0176, val_loss_epoch=0.0163, train_loss_epoch=0.016]\n",
      "Epoch 20: 100%|██████████| 671/671 [03:50<00:00,  2.91it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0176, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  89%|████████▉ | 596/671 [03:36<00:27,  2.76it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  89%|████████▉ | 597/671 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  89%|████████▉ | 598/671 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  89%|████████▉ | 599/671 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  90%|████████▉ | 601/671 [03:37<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  90%|████████▉ | 602/671 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  90%|████████▉ | 603/671 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  90%|█████████ | 604/671 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  90%|█████████ | 605/671 [03:37<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  90%|█████████ | 606/671 [03:38<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  90%|█████████ | 607/671 [03:38<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  91%|█████████ | 608/671 [03:38<00:22,  2.78it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  91%|█████████ | 609/671 [03:38<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  91%|█████████ | 610/671 [03:38<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  91%|█████████ | 611/671 [03:39<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  91%|█████████ | 612/671 [03:39<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  91%|█████████▏| 613/671 [03:39<00:20,  2.79it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  92%|█████████▏| 614/671 [03:39<00:20,  2.80it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  92%|█████████▏| 615/671 [03:39<00:20,  2.80it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  92%|█████████▏| 616/671 [03:39<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  92%|█████████▏| 617/671 [03:40<00:19,  2.80it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  92%|█████████▏| 618/671 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  92%|█████████▏| 619/671 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  92%|█████████▏| 620/671 [03:40<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  93%|█████████▎| 621/671 [03:40<00:17,  2.81it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  93%|█████████▎| 622/671 [03:40<00:17,  2.82it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  93%|█████████▎| 623/671 [03:41<00:17,  2.82it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  93%|█████████▎| 624/671 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  93%|█████████▎| 625/671 [03:41<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  93%|█████████▎| 626/671 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  93%|█████████▎| 627/671 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  94%|█████████▎| 628/671 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  94%|█████████▎| 629/671 [03:42<00:14,  2.83it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  94%|█████████▍| 630/671 [03:42<00:14,  2.84it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  94%|█████████▍| 631/671 [03:42<00:14,  2.84it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  94%|█████████▍| 632/671 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  94%|█████████▍| 633/671 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  94%|█████████▍| 634/671 [03:42<00:13,  2.84it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  95%|█████████▍| 635/671 [03:43<00:12,  2.85it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  95%|█████████▍| 636/671 [03:43<00:12,  2.85it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  95%|█████████▍| 637/671 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  95%|█████████▌| 638/671 [03:43<00:11,  2.85it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  95%|█████████▌| 639/671 [03:43<00:11,  2.86it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  95%|█████████▌| 640/671 [03:43<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  96%|█████████▌| 641/671 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  96%|█████████▌| 642/671 [03:44<00:10,  2.86it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  96%|█████████▌| 643/671 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  96%|█████████▌| 644/671 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  96%|█████████▌| 645/671 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  96%|█████████▋| 646/671 [03:44<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  96%|█████████▋| 647/671 [03:45<00:08,  2.87it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  97%|█████████▋| 648/671 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  97%|█████████▋| 649/671 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  97%|█████████▋| 650/671 [03:45<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  97%|█████████▋| 651/671 [03:45<00:06,  2.88it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  97%|█████████▋| 652/671 [03:45<00:06,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  97%|█████████▋| 653/671 [03:46<00:06,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  97%|█████████▋| 654/671 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  98%|█████████▊| 655/671 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  98%|█████████▊| 656/671 [03:46<00:05,  2.89it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  98%|█████████▊| 657/671 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  98%|█████████▊| 658/671 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  98%|█████████▊| 659/671 [03:47<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  98%|█████████▊| 660/671 [03:47<00:03,  2.90it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  99%|█████████▊| 661/671 [03:47<00:03,  2.91it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  99%|█████████▊| 662/671 [03:47<00:03,  2.91it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  99%|█████████▉| 663/671 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  99%|█████████▉| 664/671 [03:47<00:02,  2.91it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  99%|█████████▉| 665/671 [03:48<00:02,  2.92it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  99%|█████████▉| 666/671 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21:  99%|█████████▉| 667/671 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21: 100%|█████████▉| 668/671 [03:48<00:01,  2.92it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21: 100%|█████████▉| 669/671 [03:48<00:00,  2.92it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21: 100%|█████████▉| 670/671 [03:48<00:00,  2.93it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 21: 100%|██████████| 671/671 [03:49<00:00,  2.93it/s, loss=0.017, val_loss_step=0.0137, train_loss_step=0.00845, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  89%|████████▉ | 596/671 [03:36<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 597/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  90%|████████▉ | 601/671 [03:37<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  90%|████████▉ | 602/671 [03:37<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  90%|█████████ | 604/671 [03:38<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  90%|█████████ | 605/671 [03:38<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  90%|█████████ | 606/671 [03:38<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  90%|█████████ | 607/671 [03:38<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  91%|█████████ | 608/671 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  91%|█████████ | 609/671 [03:39<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  91%|█████████ | 612/671 [03:39<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  91%|█████████▏| 613/671 [03:39<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  92%|█████████▏| 614/671 [03:39<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  92%|█████████▏| 616/671 [03:40<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  92%|█████████▏| 617/671 [03:40<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  92%|█████████▏| 618/671 [03:40<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  92%|█████████▏| 619/671 [03:40<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  92%|█████████▏| 620/671 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  93%|█████████▎| 621/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  93%|█████████▎| 624/671 [03:41<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  93%|█████████▎| 625/671 [03:41<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  93%|█████████▎| 626/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  94%|█████████▎| 629/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  94%|█████████▍| 630/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  94%|█████████▍| 631/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  94%|█████████▍| 633/671 [03:43<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  94%|█████████▍| 634/671 [03:43<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  95%|█████████▍| 636/671 [03:43<00:12,  2.84it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  95%|█████████▍| 637/671 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  95%|█████████▌| 638/671 [03:44<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  96%|█████████▌| 642/671 [03:44<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  96%|█████████▌| 643/671 [03:44<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  96%|█████████▋| 646/671 [03:45<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  96%|█████████▋| 647/671 [03:45<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  97%|█████████▋| 648/671 [03:45<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  97%|█████████▋| 649/671 [03:45<00:07,  2.87it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  97%|█████████▋| 650/671 [03:46<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  97%|█████████▋| 651/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  97%|█████████▋| 654/671 [03:46<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  98%|█████████▊| 655/671 [03:46<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  98%|█████████▊| 656/671 [03:47<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  98%|█████████▊| 659/671 [03:47<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  98%|█████████▊| 660/671 [03:47<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  99%|█████████▊| 661/671 [03:47<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  99%|█████████▉| 664/671 [03:48<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  99%|█████████▉| 665/671 [03:48<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  99%|█████████▉| 666/671 [03:48<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22:  99%|█████████▉| 667/671 [03:48<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22: 100%|█████████▉| 668/671 [03:49<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22: 100%|█████████▉| 669/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0164, train_loss_epoch=0.016]\n",
      "Epoch 22: 100%|██████████| 671/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.00996, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  89%|████████▉ | 596/671 [03:36<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 597/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  89%|████████▉ | 598/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  89%|████████▉ | 599/671 [03:37<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  90%|████████▉ | 601/671 [03:37<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  90%|████████▉ | 602/671 [03:37<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  90%|████████▉ | 603/671 [03:38<00:24,  2.76it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  90%|█████████ | 604/671 [03:38<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  90%|█████████ | 605/671 [03:38<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  90%|█████████ | 606/671 [03:38<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  90%|█████████ | 607/671 [03:38<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  91%|█████████ | 608/671 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  91%|█████████ | 609/671 [03:39<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  91%|█████████ | 611/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  91%|█████████ | 612/671 [03:39<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  91%|█████████▏| 613/671 [03:39<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  92%|█████████▏| 614/671 [03:39<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  92%|█████████▏| 615/671 [03:40<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  92%|█████████▏| 616/671 [03:40<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  92%|█████████▏| 617/671 [03:40<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  92%|█████████▏| 618/671 [03:40<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  92%|█████████▏| 619/671 [03:40<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  92%|█████████▏| 620/671 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  93%|█████████▎| 621/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  93%|█████████▎| 623/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  93%|█████████▎| 624/671 [03:41<00:16,  2.81it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  93%|█████████▎| 625/671 [03:41<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  93%|█████████▎| 626/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  93%|█████████▎| 627/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  94%|█████████▎| 628/671 [03:42<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  94%|█████████▎| 629/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  94%|█████████▍| 630/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  94%|█████████▍| 631/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  94%|█████████▍| 632/671 [03:43<00:13,  2.83it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  94%|█████████▍| 633/671 [03:43<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  94%|█████████▍| 634/671 [03:43<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  95%|█████████▍| 636/671 [03:43<00:12,  2.84it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  95%|█████████▍| 637/671 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  95%|█████████▌| 638/671 [03:44<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  95%|█████████▌| 639/671 [03:44<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  95%|█████████▌| 640/671 [03:44<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  96%|█████████▌| 641/671 [03:44<00:10,  2.85it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  96%|█████████▌| 642/671 [03:44<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  96%|█████████▌| 643/671 [03:44<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  96%|█████████▌| 644/671 [03:45<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  96%|█████████▌| 645/671 [03:45<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  96%|█████████▋| 646/671 [03:45<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  96%|█████████▋| 647/671 [03:45<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  97%|█████████▋| 648/671 [03:45<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  97%|█████████▋| 649/671 [03:45<00:07,  2.87it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  97%|█████████▋| 650/671 [03:46<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  97%|█████████▋| 651/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  97%|█████████▋| 653/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  97%|█████████▋| 654/671 [03:46<00:05,  2.88it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  98%|█████████▊| 655/671 [03:46<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  98%|█████████▊| 656/671 [03:47<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  98%|█████████▊| 657/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  98%|█████████▊| 658/671 [03:47<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  98%|█████████▊| 659/671 [03:47<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  98%|█████████▊| 660/671 [03:47<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  99%|█████████▊| 661/671 [03:47<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  99%|█████████▊| 662/671 [03:48<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  99%|█████████▉| 663/671 [03:48<00:02,  2.90it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  99%|█████████▉| 664/671 [03:48<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  99%|█████████▉| 665/671 [03:48<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  99%|█████████▉| 666/671 [03:48<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23:  99%|█████████▉| 667/671 [03:48<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23: 100%|█████████▉| 668/671 [03:49<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23: 100%|█████████▉| 669/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0137, train_loss_step=0.0194, val_loss_epoch=0.0165, train_loss_epoch=0.016]\n",
      "Epoch 23: 100%|██████████| 671/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0194, val_loss_epoch=0.017, train_loss_epoch=0.016] \n",
      "Epoch 24:  89%|████████▉ | 596/671 [03:36<00:27,  2.75it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 597/671 [03:36<00:26,  2.75it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  89%|████████▉ | 598/671 [03:36<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  89%|████████▉ | 599/671 [03:37<00:26,  2.76it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  90%|████████▉ | 601/671 [03:37<00:25,  2.76it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  90%|████████▉ | 602/671 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  90%|████████▉ | 603/671 [03:37<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  90%|█████████ | 604/671 [03:38<00:24,  2.77it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  90%|█████████ | 605/671 [03:38<00:23,  2.77it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  90%|█████████ | 606/671 [03:38<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  90%|█████████ | 607/671 [03:38<00:23,  2.78it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  91%|█████████ | 608/671 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  91%|█████████ | 609/671 [03:38<00:22,  2.78it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  91%|█████████ | 610/671 [03:39<00:21,  2.78it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  91%|█████████ | 611/671 [03:39<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  91%|█████████ | 612/671 [03:39<00:21,  2.79it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  91%|█████████▏| 613/671 [03:39<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  92%|█████████▏| 614/671 [03:39<00:20,  2.79it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  92%|█████████▏| 615/671 [03:39<00:20,  2.80it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  92%|█████████▏| 616/671 [03:40<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  92%|█████████▏| 617/671 [03:40<00:19,  2.80it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  92%|█████████▏| 618/671 [03:40<00:18,  2.80it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  92%|█████████▏| 619/671 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  92%|█████████▏| 620/671 [03:40<00:18,  2.81it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  93%|█████████▎| 621/671 [03:40<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  93%|█████████▎| 622/671 [03:41<00:17,  2.81it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  93%|█████████▎| 623/671 [03:41<00:17,  2.82it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  93%|█████████▎| 624/671 [03:41<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  93%|█████████▎| 625/671 [03:41<00:16,  2.82it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  93%|█████████▎| 626/671 [03:41<00:15,  2.82it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  93%|█████████▎| 627/671 [03:41<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  94%|█████████▎| 628/671 [03:42<00:15,  2.83it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  94%|█████████▎| 629/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  94%|█████████▍| 630/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  94%|█████████▍| 631/671 [03:42<00:14,  2.83it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  94%|█████████▍| 632/671 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  94%|█████████▍| 633/671 [03:42<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  94%|█████████▍| 634/671 [03:43<00:13,  2.84it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  95%|█████████▍| 635/671 [03:43<00:12,  2.84it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  95%|█████████▍| 636/671 [03:43<00:12,  2.85it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  95%|█████████▍| 637/671 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  95%|█████████▌| 638/671 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  95%|█████████▌| 639/671 [03:43<00:11,  2.85it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  95%|█████████▌| 640/671 [03:44<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  96%|█████████▌| 641/671 [03:44<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  96%|█████████▌| 642/671 [03:44<00:10,  2.86it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  96%|█████████▌| 643/671 [03:44<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  96%|█████████▌| 644/671 [03:44<00:09,  2.86it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  96%|█████████▌| 645/671 [03:44<00:09,  2.87it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  96%|█████████▋| 646/671 [03:45<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  96%|█████████▋| 647/671 [03:45<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  97%|█████████▋| 648/671 [03:45<00:08,  2.87it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  97%|█████████▋| 649/671 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  97%|█████████▋| 650/671 [03:45<00:07,  2.88it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  97%|█████████▋| 651/671 [03:45<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  97%|█████████▋| 652/671 [03:46<00:06,  2.88it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  97%|█████████▋| 653/671 [03:46<00:06,  2.89it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  97%|█████████▋| 654/671 [03:46<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  98%|█████████▊| 655/671 [03:46<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  98%|█████████▊| 656/671 [03:46<00:05,  2.89it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  98%|█████████▊| 657/671 [03:46<00:04,  2.89it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  98%|█████████▊| 658/671 [03:47<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  98%|█████████▊| 659/671 [03:47<00:04,  2.90it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  98%|█████████▊| 660/671 [03:47<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  99%|█████████▊| 661/671 [03:47<00:03,  2.90it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  99%|█████████▊| 662/671 [03:47<00:03,  2.91it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  99%|█████████▉| 663/671 [03:47<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  99%|█████████▉| 664/671 [03:48<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  99%|█████████▉| 665/671 [03:48<00:02,  2.91it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  99%|█████████▉| 666/671 [03:48<00:01,  2.91it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24:  99%|█████████▉| 667/671 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24: 100%|█████████▉| 668/671 [03:48<00:01,  2.92it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24: 100%|█████████▉| 669/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24: 100%|█████████▉| 670/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0144, train_loss_step=0.0112, val_loss_epoch=0.017, train_loss_epoch=0.0161]\n",
      "Epoch 24: 100%|██████████| 671/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0146, train_loss_step=0.0112, val_loss_epoch=0.0171, train_loss_epoch=0.0161]\n",
      "Epoch 24: 100%|██████████| 671/671 [03:49<00:00,  2.92it/s, loss=0.016, val_loss_step=0.0146, train_loss_step=0.0112, val_loss_epoch=0.0171, train_loss_epoch=0.0161]\n",
      "Test iterations: 137\n",
      "Testing: 100%|██████████| 137/137 [00:21<00:00,  6.59it/s]Logits: tensor([[-7.2852, -7.1523, -6.6250,  ..., -6.5430, -6.6758, -6.3125],\n",
      "        [-7.4180, -7.3242, -6.8047,  ..., -6.6836, -6.8125, -6.4766],\n",
      "        [-7.1211, -7.0977, -6.7109,  ..., -6.5898, -6.4414, -6.3516],\n",
      "        ...,\n",
      "        [-7.3867, -7.4297, -6.4570,  ..., -6.3906, -6.2188, -6.2344],\n",
      "        [-8.4453, -8.7422, -6.3477,  ..., -6.6367, -5.5742, -6.4648],\n",
      "        [-7.2852, -7.3281, -6.5312,  ..., -6.5938, -6.0273, -6.3086]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[0.000685  0.0007825 0.001325  ... 0.001438  0.00126   0.00181  ]\n",
      " [0.0006    0.000659  0.001107  ... 0.001249  0.001099  0.001536 ]\n",
      " [0.0008073 0.0008264 0.001216  ... 0.001372  0.001592  0.001741 ]\n",
      " ...\n",
      " [0.000619  0.000593  0.001567  ... 0.001675  0.001987  0.001957 ]\n",
      " [0.0002148 0.0001596 0.001748  ... 0.001309  0.00378   0.0015545]\n",
      " [0.000685  0.0006566 0.001455  ... 0.001367  0.002405  0.001818 ]]\n",
      "Testing: 100%|██████████| 137/137 [00:21<00:00,  6.46it/s]\n",
      "==================== Fold 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 11 M  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 74\n",
      "Train iterations: 597                                                 \n",
      "Epoch 0:  89%|████████▉ | 597/671 [03:38<00:27,  2.73it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 598/671 [03:38<00:26,  2.73it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  89%|████████▉ | 599/671 [03:39<00:26,  2.73it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  89%|████████▉ | 600/671 [03:39<00:25,  2.74it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  90%|████████▉ | 601/671 [03:39<00:25,  2.74it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  90%|████████▉ | 602/671 [03:39<00:25,  2.74it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  90%|████████▉ | 603/671 [03:39<00:24,  2.74it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  90%|█████████ | 604/671 [03:39<00:24,  2.75it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  90%|█████████ | 605/671 [03:40<00:24,  2.75it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  90%|█████████ | 606/671 [03:40<00:23,  2.75it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  90%|█████████ | 607/671 [03:40<00:23,  2.75it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  91%|█████████ | 608/671 [03:40<00:22,  2.76it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  91%|█████████ | 609/671 [03:40<00:22,  2.76it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  91%|█████████ | 610/671 [03:40<00:22,  2.76it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  91%|█████████ | 611/671 [03:41<00:21,  2.76it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  91%|█████████ | 612/671 [03:41<00:21,  2.77it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  91%|█████████▏| 613/671 [03:41<00:20,  2.77it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  92%|█████████▏| 614/671 [03:41<00:20,  2.77it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  92%|█████████▏| 615/671 [03:41<00:20,  2.77it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  92%|█████████▏| 616/671 [03:41<00:19,  2.77it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  92%|█████████▏| 617/671 [03:42<00:19,  2.78it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  92%|█████████▏| 618/671 [03:42<00:19,  2.78it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  92%|█████████▏| 619/671 [03:42<00:18,  2.78it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  92%|█████████▏| 620/671 [03:42<00:18,  2.78it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  93%|█████████▎| 621/671 [03:42<00:17,  2.79it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  93%|█████████▎| 622/671 [03:43<00:17,  2.79it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  93%|█████████▎| 623/671 [03:43<00:17,  2.79it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  93%|█████████▎| 624/671 [03:43<00:16,  2.79it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  93%|█████████▎| 625/671 [03:43<00:16,  2.80it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  93%|█████████▎| 626/671 [03:43<00:16,  2.80it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  93%|█████████▎| 627/671 [03:43<00:15,  2.80it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  94%|█████████▎| 628/671 [03:44<00:15,  2.80it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  94%|█████████▎| 629/671 [03:44<00:14,  2.81it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  94%|█████████▍| 630/671 [03:44<00:14,  2.81it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  94%|█████████▍| 631/671 [03:44<00:14,  2.81it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  94%|█████████▍| 632/671 [03:44<00:13,  2.81it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  94%|█████████▍| 634/671 [03:45<00:13,  2.82it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  95%|█████████▍| 635/671 [03:45<00:12,  2.82it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  95%|█████████▍| 636/671 [03:45<00:12,  2.82it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  95%|█████████▍| 637/671 [03:45<00:12,  2.82it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  95%|█████████▌| 638/671 [03:45<00:11,  2.83it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  95%|█████████▌| 639/671 [03:45<00:11,  2.83it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  95%|█████████▌| 640/671 [03:46<00:10,  2.83it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  96%|█████████▌| 641/671 [03:46<00:10,  2.83it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  96%|█████████▌| 642/671 [03:46<00:10,  2.84it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  96%|█████████▌| 643/671 [03:46<00:09,  2.84it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  96%|█████████▌| 644/671 [03:46<00:09,  2.84it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  96%|█████████▌| 645/671 [03:46<00:09,  2.84it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  96%|█████████▋| 646/671 [03:47<00:08,  2.84it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  96%|█████████▋| 647/671 [03:47<00:08,  2.85it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  97%|█████████▋| 648/671 [03:47<00:08,  2.85it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  97%|█████████▋| 649/671 [03:47<00:07,  2.85it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  97%|█████████▋| 650/671 [03:47<00:07,  2.85it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  97%|█████████▋| 651/671 [03:47<00:07,  2.86it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  97%|█████████▋| 652/671 [03:48<00:06,  2.86it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  97%|█████████▋| 653/671 [03:48<00:06,  2.86it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  97%|█████████▋| 654/671 [03:48<00:05,  2.86it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  98%|█████████▊| 655/671 [03:48<00:05,  2.87it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  98%|█████████▊| 656/671 [03:48<00:05,  2.87it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  98%|█████████▊| 657/671 [03:48<00:04,  2.87it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  98%|█████████▊| 658/671 [03:49<00:04,  2.87it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  98%|█████████▊| 659/671 [03:49<00:04,  2.87it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  98%|█████████▊| 660/671 [03:49<00:03,  2.88it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  99%|█████████▊| 661/671 [03:49<00:03,  2.88it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  99%|█████████▊| 662/671 [03:49<00:03,  2.88it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  99%|█████████▉| 663/671 [03:49<00:02,  2.88it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  99%|█████████▉| 664/671 [03:50<00:02,  2.89it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  99%|█████████▉| 665/671 [03:50<00:02,  2.89it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|█████████▉| 666/671 [03:50<00:01,  2.89it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0:  99%|█████████▉| 667/671 [03:50<00:01,  2.89it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0: 100%|█████████▉| 668/671 [03:50<00:01,  2.89it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0: 100%|█████████▉| 669/671 [03:50<00:00,  2.90it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0: 100%|█████████▉| 670/671 [03:51<00:00,  2.90it/s, loss=0.021, val_loss_step=0.699, train_loss_step=0.0197]\n",
      "Epoch 0: 100%|██████████| 671/671 [03:51<00:00,  2.90it/s, loss=0.021, val_loss_step=0.0273, train_loss_step=0.0197, val_loss_epoch=0.0304]\n",
      "Epoch 1:  89%|████████▉ | 597/671 [03:38<00:27,  2.73it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 598/671 [03:39<00:26,  2.73it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  89%|████████▉ | 599/671 [03:39<00:26,  2.73it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  89%|████████▉ | 600/671 [03:39<00:25,  2.73it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  90%|████████▉ | 601/671 [03:39<00:25,  2.73it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  90%|████████▉ | 602/671 [03:39<00:25,  2.74it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  90%|████████▉ | 603/671 [03:40<00:24,  2.74it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  90%|█████████ | 604/671 [03:40<00:24,  2.74it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  90%|█████████ | 605/671 [03:40<00:24,  2.74it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  90%|█████████ | 606/671 [03:40<00:23,  2.75it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  90%|█████████ | 607/671 [03:40<00:23,  2.75it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  91%|█████████ | 608/671 [03:40<00:22,  2.75it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  91%|█████████ | 609/671 [03:41<00:22,  2.75it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  91%|█████████ | 610/671 [03:41<00:22,  2.76it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  91%|█████████ | 611/671 [03:41<00:21,  2.76it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  91%|█████████ | 612/671 [03:41<00:21,  2.76it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  91%|█████████▏| 613/671 [03:41<00:20,  2.76it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  92%|█████████▏| 614/671 [03:42<00:20,  2.77it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  92%|█████████▏| 615/671 [03:42<00:20,  2.77it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  92%|█████████▏| 616/671 [03:42<00:19,  2.77it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  92%|█████████▏| 617/671 [03:42<00:19,  2.77it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  92%|█████████▏| 618/671 [03:42<00:19,  2.78it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  92%|█████████▏| 619/671 [03:42<00:18,  2.78it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  92%|█████████▏| 620/671 [03:43<00:18,  2.78it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  93%|█████████▎| 621/671 [03:43<00:17,  2.78it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  93%|█████████▎| 622/671 [03:43<00:17,  2.78it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  93%|█████████▎| 623/671 [03:43<00:17,  2.79it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  93%|█████████▎| 624/671 [03:43<00:16,  2.79it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  93%|█████████▎| 625/671 [03:43<00:16,  2.79it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  93%|█████████▎| 626/671 [03:44<00:16,  2.79it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  93%|█████████▎| 627/671 [03:44<00:15,  2.80it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  94%|█████████▎| 628/671 [03:44<00:15,  2.80it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  94%|█████████▎| 629/671 [03:44<00:14,  2.80it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  94%|█████████▍| 630/671 [03:44<00:14,  2.80it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  94%|█████████▍| 631/671 [03:44<00:14,  2.81it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  94%|█████████▍| 632/671 [03:45<00:13,  2.81it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  94%|█████████▍| 633/671 [03:45<00:13,  2.81it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  94%|█████████▍| 634/671 [03:45<00:13,  2.81it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  95%|█████████▍| 635/671 [03:45<00:12,  2.81it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  95%|█████████▍| 636/671 [03:45<00:12,  2.82it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  95%|█████████▍| 637/671 [03:45<00:12,  2.82it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  95%|█████████▌| 638/671 [03:46<00:11,  2.82it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  95%|█████████▌| 639/671 [03:46<00:11,  2.82it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  95%|█████████▌| 640/671 [03:46<00:10,  2.83it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  96%|█████████▌| 641/671 [03:46<00:10,  2.83it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|█████████▌| 642/671 [03:46<00:10,  2.83it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  96%|█████████▌| 643/671 [03:46<00:09,  2.83it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  96%|█████████▌| 644/671 [03:47<00:09,  2.84it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  96%|█████████▌| 645/671 [03:47<00:09,  2.84it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  96%|█████████▋| 646/671 [03:47<00:08,  2.84it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  96%|█████████▋| 647/671 [03:47<00:08,  2.84it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  97%|█████████▋| 648/671 [03:47<00:08,  2.84it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  97%|█████████▋| 649/671 [03:47<00:07,  2.85it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  97%|█████████▋| 650/671 [03:48<00:07,  2.85it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  97%|█████████▋| 651/671 [03:48<00:07,  2.85it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  97%|█████████▋| 652/671 [03:48<00:06,  2.85it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  97%|█████████▋| 653/671 [03:48<00:06,  2.86it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  97%|█████████▋| 654/671 [03:48<00:05,  2.86it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  98%|█████████▊| 655/671 [03:49<00:05,  2.86it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  98%|█████████▊| 656/671 [03:49<00:05,  2.86it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  98%|█████████▊| 657/671 [03:49<00:04,  2.86it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  98%|█████████▊| 658/671 [03:49<00:04,  2.87it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  98%|█████████▊| 659/671 [03:49<00:04,  2.87it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  98%|█████████▊| 660/671 [03:49<00:03,  2.87it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  99%|█████████▊| 661/671 [03:50<00:03,  2.87it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  99%|█████████▊| 662/671 [03:50<00:03,  2.88it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  99%|█████████▉| 663/671 [03:50<00:02,  2.88it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  99%|█████████▉| 664/671 [03:50<00:02,  2.88it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  99%|█████████▉| 665/671 [03:50<00:02,  2.88it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  99%|█████████▉| 666/671 [03:50<00:01,  2.88it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1:  99%|█████████▉| 667/671 [03:51<00:01,  2.89it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1: 100%|█████████▉| 668/671 [03:51<00:01,  2.89it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1: 100%|█████████▉| 669/671 [03:51<00:00,  2.89it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1: 100%|█████████▉| 670/671 [03:51<00:00,  2.89it/s, loss=0.020, val_loss_step=0.0273, train_loss_step=0.0181, val_loss_epoch=0.0304, train_loss_epoch=0.0246]\n",
      "Epoch 1: 100%|██████████| 671/671 [03:52<00:00,  2.89it/s, loss=0.020, val_loss_step=0.0162, train_loss_step=0.0181, val_loss_epoch=0.0202, train_loss_epoch=0.0246]\n",
      "Epoch 2:  89%|████████▉ | 597/671 [03:38<00:27,  2.73it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 598/671 [03:39<00:26,  2.73it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  89%|████████▉ | 599/671 [03:39<00:26,  2.73it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  89%|████████▉ | 600/671 [03:39<00:25,  2.73it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|████████▉ | 601/671 [03:39<00:25,  2.74it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|████████▉ | 602/671 [03:39<00:25,  2.74it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|████████▉ | 603/671 [03:39<00:24,  2.74it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 604/671 [03:40<00:24,  2.74it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 605/671 [03:40<00:24,  2.75it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 606/671 [03:40<00:23,  2.75it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 607/671 [03:40<00:23,  2.75it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 608/671 [03:40<00:22,  2.75it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 609/671 [03:41<00:22,  2.76it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 610/671 [03:41<00:22,  2.76it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 611/671 [03:41<00:21,  2.76it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 612/671 [03:41<00:21,  2.76it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████▏| 613/671 [03:41<00:20,  2.77it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 614/671 [03:41<00:20,  2.77it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 615/671 [03:42<00:20,  2.77it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  92%|█████████▏| 616/671 [03:42<00:19,  2.77it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 617/671 [03:42<00:19,  2.77it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 618/671 [03:42<00:19,  2.78it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 619/671 [03:42<00:18,  2.78it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 620/671 [03:42<00:18,  2.78it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 621/671 [03:43<00:17,  2.78it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 622/671 [03:43<00:17,  2.79it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 623/671 [03:43<00:17,  2.79it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 624/671 [03:43<00:16,  2.79it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 625/671 [03:43<00:16,  2.79it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 626/671 [03:43<00:16,  2.80it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 627/671 [03:44<00:15,  2.80it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▎| 628/671 [03:44<00:15,  2.80it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▎| 629/671 [03:44<00:14,  2.80it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 630/671 [03:44<00:14,  2.81it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 631/671 [03:44<00:14,  2.81it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 632/671 [03:44<00:13,  2.81it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 633/671 [03:45<00:13,  2.81it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 634/671 [03:45<00:13,  2.81it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▍| 635/671 [03:45<00:12,  2.82it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▍| 636/671 [03:45<00:12,  2.82it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▍| 637/671 [03:45<00:12,  2.82it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▌| 638/671 [03:45<00:11,  2.82it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▌| 639/671 [03:46<00:11,  2.83it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▌| 640/671 [03:46<00:10,  2.83it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 641/671 [03:46<00:10,  2.83it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 642/671 [03:46<00:10,  2.83it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 643/671 [03:46<00:09,  2.84it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 644/671 [03:46<00:09,  2.84it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 645/671 [03:47<00:09,  2.84it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▋| 646/671 [03:47<00:08,  2.84it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▋| 647/671 [03:47<00:08,  2.84it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 648/671 [03:47<00:08,  2.85it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 649/671 [03:47<00:07,  2.85it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 650/671 [03:47<00:07,  2.85it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 651/671 [03:48<00:07,  2.85it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 652/671 [03:48<00:06,  2.86it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 653/671 [03:48<00:06,  2.86it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 654/671 [03:48<00:05,  2.86it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 655/671 [03:48<00:05,  2.86it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 656/671 [03:48<00:05,  2.87it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 657/671 [03:49<00:04,  2.87it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 658/671 [03:49<00:04,  2.87it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 659/671 [03:49<00:04,  2.87it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 660/671 [03:49<00:03,  2.87it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▊| 661/671 [03:49<00:03,  2.88it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▊| 662/671 [03:49<00:03,  2.88it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 663/671 [03:50<00:02,  2.88it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 664/671 [03:50<00:02,  2.88it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  99%|█████████▉| 665/671 [03:50<00:02,  2.88it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 666/671 [03:50<00:01,  2.89it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 667/671 [03:50<00:01,  2.89it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|█████████▉| 668/671 [03:51<00:01,  2.89it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|█████████▉| 669/671 [03:51<00:00,  2.89it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|█████████▉| 670/671 [03:51<00:00,  2.90it/s, loss=0.019, val_loss_step=0.0162, train_loss_step=0.0192, val_loss_epoch=0.0202, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|██████████| 671/671 [03:51<00:00,  2.90it/s, loss=0.019, val_loss_step=0.0175, train_loss_step=0.0192, val_loss_epoch=0.0219, train_loss_epoch=0.0195]\n",
      "Epoch 3:  89%|████████▉ | 597/671 [03:38<00:27,  2.73it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 598/671 [03:38<00:26,  2.73it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  89%|████████▉ | 600/671 [03:39<00:25,  2.74it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|████████▉ | 601/671 [03:39<00:25,  2.74it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|████████▉ | 602/671 [03:39<00:25,  2.74it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|████████▉ | 603/671 [03:39<00:24,  2.75it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|█████████ | 604/671 [03:39<00:24,  2.75it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|█████████ | 605/671 [03:39<00:23,  2.75it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|█████████ | 606/671 [03:40<00:23,  2.75it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  90%|█████████ | 607/671 [03:40<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 608/671 [03:40<00:22,  2.76it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 609/671 [03:40<00:22,  2.76it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 610/671 [03:40<00:22,  2.76it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████ | 612/671 [03:41<00:21,  2.77it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  91%|█████████▏| 613/671 [03:41<00:20,  2.77it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 614/671 [03:41<00:20,  2.77it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 615/671 [03:41<00:20,  2.77it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 616/671 [03:41<00:19,  2.78it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 617/671 [03:41<00:19,  2.78it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 618/671 [03:42<00:19,  2.78it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 619/671 [03:42<00:18,  2.78it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  92%|█████████▏| 620/671 [03:42<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 621/671 [03:42<00:17,  2.79it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 622/671 [03:42<00:17,  2.79it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 623/671 [03:42<00:17,  2.79it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 624/671 [03:43<00:16,  2.80it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 625/671 [03:43<00:16,  2.80it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 626/671 [03:43<00:16,  2.80it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  93%|█████████▎| 627/671 [03:43<00:15,  2.80it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▎| 629/671 [03:44<00:14,  2.81it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▍| 630/671 [03:44<00:14,  2.81it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▍| 631/671 [03:44<00:14,  2.81it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▍| 632/671 [03:44<00:13,  2.81it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  94%|█████████▍| 634/671 [03:44<00:13,  2.82it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▍| 635/671 [03:45<00:12,  2.82it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▍| 636/671 [03:45<00:12,  2.82it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▍| 637/671 [03:45<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▌| 638/671 [03:45<00:11,  2.83it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  95%|█████████▌| 639/671 [03:45<00:11,  2.83it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  95%|█████████▌| 640/671 [03:45<00:10,  2.83it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 641/671 [03:46<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 642/671 [03:46<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 643/671 [03:46<00:09,  2.84it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 644/671 [03:46<00:09,  2.84it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▌| 645/671 [03:46<00:09,  2.84it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▋| 646/671 [03:46<00:08,  2.85it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  96%|█████████▋| 647/671 [03:47<00:08,  2.85it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 648/671 [03:47<00:08,  2.85it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 649/671 [03:47<00:07,  2.85it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 650/671 [03:47<00:07,  2.86it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 651/671 [03:47<00:06,  2.86it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 652/671 [03:47<00:06,  2.86it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 653/671 [03:48<00:06,  2.86it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  97%|█████████▋| 654/671 [03:48<00:05,  2.87it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 655/671 [03:48<00:05,  2.87it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 656/671 [03:48<00:05,  2.87it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 657/671 [03:48<00:04,  2.87it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 658/671 [03:48<00:04,  2.87it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 659/671 [03:49<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  98%|█████████▊| 660/671 [03:49<00:03,  2.88it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▊| 661/671 [03:49<00:03,  2.88it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▊| 662/671 [03:49<00:03,  2.88it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 664/671 [03:49<00:02,  2.89it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 665/671 [03:50<00:02,  2.89it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 666/671 [03:50<00:01,  2.89it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3:  99%|█████████▉| 667/671 [03:50<00:01,  2.89it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3: 100%|█████████▉| 668/671 [03:50<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3: 100%|█████████▉| 669/671 [03:50<00:00,  2.90it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3: 100%|█████████▉| 670/671 [03:50<00:00,  2.90it/s, loss=0.018, val_loss_step=0.0175, train_loss_step=0.0185, val_loss_epoch=0.0219, train_loss_epoch=0.0189]\n",
      "Epoch 3: 100%|██████████| 671/671 [03:51<00:00,  2.90it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0185, val_loss_epoch=0.0195, train_loss_epoch=0.0189]\n",
      "Epoch 4:  89%|████████▉ | 597/671 [03:37<00:27,  2.74it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 598/671 [03:38<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  89%|████████▉ | 599/671 [03:38<00:26,  2.74it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  89%|████████▉ | 600/671 [03:38<00:25,  2.74it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  90%|████████▉ | 601/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  90%|████████▉ | 602/671 [03:38<00:25,  2.75it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  90%|████████▉ | 603/671 [03:39<00:24,  2.75it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  90%|█████████ | 604/671 [03:39<00:24,  2.75it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  90%|█████████ | 605/671 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  90%|█████████ | 606/671 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  90%|█████████ | 607/671 [03:39<00:23,  2.76it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  91%|█████████ | 608/671 [03:39<00:22,  2.76it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  91%|█████████ | 609/671 [03:40<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  91%|█████████ | 610/671 [03:40<00:22,  2.77it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  91%|█████████ | 611/671 [03:40<00:21,  2.77it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  91%|█████████ | 612/671 [03:40<00:21,  2.77it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  91%|█████████▏| 613/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  92%|█████████▏| 614/671 [03:40<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  92%|█████████▏| 615/671 [03:41<00:20,  2.78it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  92%|█████████▏| 616/671 [03:41<00:19,  2.78it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  92%|█████████▏| 617/671 [03:41<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  92%|█████████▏| 618/671 [03:41<00:19,  2.79it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  92%|█████████▏| 619/671 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  92%|█████████▏| 620/671 [03:41<00:18,  2.79it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  93%|█████████▎| 621/671 [03:42<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  93%|█████████▎| 622/671 [03:42<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  93%|█████████▎| 623/671 [03:42<00:17,  2.80it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  93%|█████████▎| 624/671 [03:42<00:16,  2.80it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  93%|█████████▎| 625/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  93%|█████████▎| 626/671 [03:42<00:16,  2.81it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  93%|█████████▎| 627/671 [03:43<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  94%|█████████▎| 628/671 [03:43<00:15,  2.81it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  94%|█████████▎| 629/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  94%|█████████▍| 630/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  94%|█████████▍| 631/671 [03:43<00:14,  2.82it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  94%|█████████▍| 632/671 [03:43<00:13,  2.82it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  94%|█████████▍| 633/671 [03:44<00:13,  2.82it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  94%|█████████▍| 634/671 [03:44<00:13,  2.83it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  95%|█████████▍| 635/671 [03:44<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  95%|█████████▍| 636/671 [03:44<00:12,  2.83it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  95%|█████████▍| 637/671 [03:44<00:11,  2.83it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  95%|█████████▌| 638/671 [03:44<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  95%|█████████▌| 639/671 [03:45<00:11,  2.84it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  95%|█████████▌| 640/671 [03:45<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  96%|█████████▌| 641/671 [03:45<00:10,  2.84it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  96%|█████████▌| 642/671 [03:45<00:10,  2.85it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  96%|█████████▌| 643/671 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  96%|█████████▌| 644/671 [03:45<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  96%|█████████▌| 645/671 [03:46<00:09,  2.85it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  96%|█████████▋| 646/671 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  96%|█████████▋| 647/671 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  97%|█████████▋| 648/671 [03:46<00:08,  2.86it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  97%|█████████▋| 649/671 [03:46<00:07,  2.86it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  97%|█████████▋| 650/671 [03:46<00:07,  2.86it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  97%|█████████▋| 651/671 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  97%|█████████▋| 652/671 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  97%|█████████▋| 653/671 [03:47<00:06,  2.87it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  97%|█████████▋| 654/671 [03:47<00:05,  2.87it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  98%|█████████▊| 655/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  98%|█████████▊| 656/671 [03:47<00:05,  2.88it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  98%|█████████▊| 657/671 [03:48<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  98%|█████████▊| 658/671 [03:48<00:04,  2.88it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  98%|█████████▊| 659/671 [03:48<00:04,  2.89it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  98%|█████████▊| 660/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  99%|█████████▊| 661/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  99%|█████████▊| 662/671 [03:48<00:03,  2.89it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  99%|█████████▉| 663/671 [03:49<00:02,  2.89it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  99%|█████████▉| 664/671 [03:49<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  99%|█████████▉| 665/671 [03:49<00:02,  2.90it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  99%|█████████▉| 666/671 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4:  99%|█████████▉| 667/671 [03:49<00:01,  2.90it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4: 100%|█████████▉| 668/671 [03:49<00:01,  2.91it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4: 100%|█████████▉| 669/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4: 100%|█████████▉| 670/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 4: 100%|██████████| 671/671 [03:50<00:00,  2.91it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0183, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 597/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 598/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  89%|████████▉ | 599/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  90%|████████▉ | 601/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  90%|████████▉ | 602/671 [03:37<00:24,  2.77it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  90%|████████▉ | 603/671 [03:37<00:24,  2.77it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  90%|█████████ | 604/671 [03:37<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  90%|█████████ | 605/671 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  90%|█████████ | 606/671 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  90%|█████████ | 607/671 [03:37<00:22,  2.78it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  91%|█████████ | 608/671 [03:38<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  91%|█████████ | 609/671 [03:38<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  91%|█████████ | 610/671 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  91%|█████████ | 611/671 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  91%|█████████▏| 613/671 [03:38<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  92%|█████████▏| 614/671 [03:39<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  92%|█████████▏| 615/671 [03:39<00:19,  2.80it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  92%|█████████▏| 616/671 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  92%|█████████▏| 617/671 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  92%|█████████▏| 618/671 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  92%|█████████▏| 619/671 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  92%|█████████▏| 620/671 [03:40<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  93%|█████████▎| 621/671 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  93%|█████████▎| 622/671 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  93%|█████████▎| 623/671 [03:40<00:16,  2.82it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  93%|█████████▎| 625/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  93%|█████████▎| 626/671 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  93%|█████████▎| 627/671 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  94%|█████████▎| 628/671 [03:41<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  94%|█████████▎| 629/671 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  94%|█████████▍| 630/671 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  94%|█████████▍| 631/671 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  94%|█████████▍| 632/671 [03:42<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  94%|█████████▍| 633/671 [03:42<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  94%|█████████▍| 634/671 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  95%|█████████▍| 635/671 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  95%|█████████▍| 636/671 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  95%|█████████▍| 637/671 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  95%|█████████▌| 638/671 [03:43<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  95%|█████████▌| 639/671 [03:43<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  95%|█████████▌| 640/671 [03:43<00:10,  2.86it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  96%|█████████▌| 642/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  96%|█████████▌| 643/671 [03:43<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  96%|█████████▌| 644/671 [03:44<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  96%|█████████▌| 645/671 [03:44<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  96%|█████████▋| 646/671 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  96%|█████████▋| 647/671 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  97%|█████████▋| 648/671 [03:44<00:07,  2.88it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  97%|█████████▋| 650/671 [03:45<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  97%|█████████▋| 651/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  97%|█████████▋| 652/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  97%|█████████▋| 653/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  98%|█████████▊| 655/671 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  98%|█████████▊| 656/671 [03:46<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  98%|█████████▊| 657/671 [03:46<00:04,  2.90it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  98%|█████████▊| 658/671 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  98%|█████████▊| 659/671 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  98%|█████████▊| 660/671 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  99%|█████████▊| 661/671 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  99%|█████████▊| 662/671 [03:47<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  99%|█████████▉| 663/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  99%|█████████▉| 664/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  99%|█████████▉| 665/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  99%|█████████▉| 666/671 [03:47<00:01,  2.92it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5:  99%|█████████▉| 667/671 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5: 100%|█████████▉| 668/671 [03:48<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5: 100%|█████████▉| 669/671 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5: 100%|█████████▉| 670/671 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0151, train_loss_step=0.0178, val_loss_epoch=0.0183, train_loss_epoch=0.0179]\n",
      "Epoch 5: 100%|██████████| 671/671 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0163, train_loss_step=0.0178, val_loss_epoch=0.0199, train_loss_epoch=0.0179]\n",
      "Epoch 6:  89%|████████▉ | 597/671 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 598/671 [03:36<00:26,  2.76it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  89%|████████▉ | 599/671 [03:36<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|████████▉ | 601/671 [03:36<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|████████▉ | 602/671 [03:37<00:24,  2.77it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|████████▉ | 603/671 [03:37<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|█████████ | 604/671 [03:37<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|█████████ | 605/671 [03:37<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|█████████ | 606/671 [03:37<00:23,  2.78it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████ | 608/671 [03:38<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████ | 609/671 [03:38<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  91%|█████████ | 610/671 [03:38<00:21,  2.79it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████ | 611/671 [03:38<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  91%|█████████▏| 613/671 [03:38<00:20,  2.80it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 614/671 [03:39<00:20,  2.80it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 615/671 [03:39<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 616/671 [03:39<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 617/671 [03:39<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 618/671 [03:39<00:18,  2.81it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  92%|█████████▏| 620/671 [03:40<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 621/671 [03:40<00:17,  2.82it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 622/671 [03:40<00:17,  2.82it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 623/671 [03:40<00:16,  2.82it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 625/671 [03:40<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 626/671 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  93%|█████████▎| 627/671 [03:41<00:15,  2.83it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▎| 628/671 [03:41<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▎| 629/671 [03:41<00:14,  2.84it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 630/671 [03:41<00:14,  2.84it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 631/671 [03:41<00:14,  2.84it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 632/671 [03:42<00:13,  2.85it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 633/671 [03:42<00:13,  2.85it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  94%|█████████▍| 634/671 [03:42<00:12,  2.85it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▍| 635/671 [03:42<00:12,  2.85it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▍| 637/671 [03:42<00:11,  2.86it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▌| 638/671 [03:43<00:11,  2.86it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▌| 639/671 [03:43<00:11,  2.86it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  95%|█████████▌| 640/671 [03:43<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 642/671 [03:43<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 643/671 [03:43<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 644/671 [03:44<00:09,  2.87it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▌| 645/671 [03:44<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▋| 646/671 [03:44<00:08,  2.88it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  96%|█████████▋| 647/671 [03:44<00:08,  2.88it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 648/671 [03:44<00:07,  2.88it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 650/671 [03:45<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 651/671 [03:45<00:06,  2.89it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 652/671 [03:45<00:06,  2.89it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 653/671 [03:45<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 655/671 [03:45<00:05,  2.90it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 656/671 [03:46<00:05,  2.90it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 657/671 [03:46<00:04,  2.90it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 658/671 [03:46<00:04,  2.91it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  98%|█████████▊| 659/671 [03:46<00:04,  2.91it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  98%|█████████▊| 660/671 [03:46<00:03,  2.91it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▊| 661/671 [03:46<00:03,  2.91it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▊| 662/671 [03:47<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 663/671 [03:47<00:02,  2.92it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 664/671 [03:47<00:02,  2.92it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 665/671 [03:47<00:02,  2.92it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 666/671 [03:47<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6:  99%|█████████▉| 667/671 [03:47<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6: 100%|█████████▉| 668/671 [03:48<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6: 100%|█████████▉| 669/671 [03:48<00:00,  2.93it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6: 100%|█████████▉| 670/671 [03:48<00:00,  2.93it/s, loss=0.017, val_loss_step=0.0163, train_loss_step=0.0161, val_loss_epoch=0.0199, train_loss_epoch=0.0177]\n",
      "Epoch 6: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0161, val_loss_epoch=0.0196, train_loss_epoch=0.0177]\n",
      "Epoch 7:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 598/671 [03:36<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  89%|████████▉ | 599/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  90%|████████▉ | 601/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  90%|████████▉ | 603/671 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  90%|█████████ | 604/671 [03:37<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  90%|█████████ | 605/671 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  90%|█████████ | 606/671 [03:37<00:23,  2.79it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  91%|█████████ | 608/671 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  91%|█████████ | 609/671 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  91%|█████████ | 610/671 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  91%|█████████ | 611/671 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  91%|█████████▏| 613/671 [03:38<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  92%|█████████▏| 615/671 [03:38<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  92%|█████████▏| 616/671 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  92%|█████████▏| 617/671 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  92%|█████████▏| 618/671 [03:39<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  92%|█████████▏| 620/671 [03:39<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  93%|█████████▎| 621/671 [03:39<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  93%|█████████▎| 622/671 [03:40<00:17,  2.83it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  93%|█████████▎| 623/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  93%|█████████▎| 625/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  94%|█████████▎| 628/671 [03:41<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  94%|█████████▎| 629/671 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  94%|█████████▍| 630/671 [03:41<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  94%|█████████▍| 632/671 [03:41<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  94%|█████████▍| 633/671 [03:41<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  94%|█████████▍| 634/671 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  95%|█████████▍| 635/671 [03:42<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  95%|█████████▍| 637/671 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  95%|█████████▌| 638/671 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  95%|█████████▌| 640/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  96%|█████████▌| 642/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  96%|█████████▌| 645/671 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  96%|█████████▋| 646/671 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  96%|█████████▋| 647/671 [03:44<00:08,  2.89it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  97%|█████████▋| 648/671 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  97%|█████████▋| 650/671 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  97%|█████████▋| 651/671 [03:44<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  97%|█████████▋| 652/671 [03:45<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  97%|█████████▋| 653/671 [03:45<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  98%|█████████▊| 655/671 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  98%|█████████▊| 657/671 [03:45<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  98%|█████████▊| 658/671 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  98%|█████████▊| 659/671 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  98%|█████████▊| 660/671 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  99%|█████████▊| 662/671 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  99%|█████████▉| 663/671 [03:46<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  99%|█████████▉| 664/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  99%|█████████▉| 665/671 [03:47<00:02,  2.93it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  99%|█████████▉| 666/671 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7:  99%|█████████▉| 667/671 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7: 100%|█████████▉| 668/671 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7: 100%|█████████▉| 670/671 [03:48<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0162, train_loss_step=0.0184, val_loss_epoch=0.0196, train_loss_epoch=0.0175]\n",
      "Epoch 7: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.018, val_loss_step=0.016, train_loss_step=0.0184, val_loss_epoch=0.0208, train_loss_epoch=0.0175] \n",
      "Epoch 8:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 598/671 [03:36<00:26,  2.77it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  89%|████████▉ | 599/671 [03:36<00:25,  2.77it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  90%|████████▉ | 603/671 [03:36<00:24,  2.78it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  90%|█████████ | 604/671 [03:37<00:24,  2.78it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  90%|█████████ | 605/671 [03:37<00:23,  2.79it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  90%|█████████ | 606/671 [03:37<00:23,  2.79it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  91%|█████████ | 608/671 [03:37<00:22,  2.79it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  91%|█████████ | 611/671 [03:38<00:21,  2.80it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  92%|█████████▏| 615/671 [03:38<00:19,  2.81it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  92%|█████████▏| 616/671 [03:38<00:19,  2.81it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  92%|█████████▏| 617/671 [03:39<00:19,  2.82it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  92%|█████████▏| 618/671 [03:39<00:18,  2.82it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  92%|█████████▏| 620/671 [03:39<00:18,  2.82it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  93%|█████████▎| 621/671 [03:39<00:17,  2.82it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  93%|█████████▎| 623/671 [03:40<00:16,  2.83it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  93%|█████████▎| 625/671 [03:40<00:16,  2.83it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  94%|█████████▎| 628/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  94%|█████████▎| 629/671 [03:41<00:14,  2.84it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  94%|█████████▍| 630/671 [03:41<00:14,  2.85it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  94%|█████████▍| 632/671 [03:41<00:13,  2.85it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  94%|█████████▍| 633/671 [03:41<00:13,  2.85it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  95%|█████████▍| 635/671 [03:42<00:12,  2.86it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  95%|█████████▍| 637/671 [03:42<00:11,  2.86it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  95%|█████████▌| 640/671 [03:42<00:10,  2.87it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  96%|█████████▌| 642/671 [03:43<00:10,  2.88it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  96%|█████████▌| 645/671 [03:43<00:09,  2.88it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  96%|█████████▋| 646/671 [03:43<00:08,  2.88it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  96%|█████████▋| 647/671 [03:44<00:08,  2.89it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  97%|█████████▋| 648/671 [03:44<00:07,  2.89it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  97%|█████████▋| 650/671 [03:44<00:07,  2.89it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  97%|█████████▋| 653/671 [03:45<00:06,  2.90it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  98%|█████████▊| 657/671 [03:45<00:04,  2.91it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  98%|█████████▊| 658/671 [03:45<00:04,  2.91it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  98%|█████████▊| 659/671 [03:46<00:04,  2.91it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  98%|█████████▊| 660/671 [03:46<00:03,  2.92it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  99%|█████████▊| 662/671 [03:46<00:03,  2.92it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  99%|█████████▉| 663/671 [03:46<00:02,  2.92it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  99%|█████████▉| 665/671 [03:47<00:02,  2.93it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  99%|█████████▉| 666/671 [03:47<00:01,  2.93it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8:  99%|█████████▉| 667/671 [03:47<00:01,  2.93it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8: 100%|█████████▉| 670/671 [03:47<00:00,  2.94it/s, loss=0.016, val_loss_step=0.016, train_loss_step=0.0149, val_loss_epoch=0.0208, train_loss_epoch=0.0173]\n",
      "Epoch 8: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.016, val_loss_step=0.0212, train_loss_step=0.0149, val_loss_epoch=0.0243, train_loss_epoch=0.0173]\n",
      "Epoch 9:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  89%|████████▉ | 599/671 [03:36<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  89%|████████▉ | 600/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  90%|████████▉ | 603/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  90%|█████████ | 605/671 [03:37<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  90%|█████████ | 606/671 [03:37<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  91%|█████████ | 611/671 [03:38<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  91%|█████████ | 612/671 [03:38<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  92%|█████████▏| 615/671 [03:38<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  92%|█████████▏| 617/671 [03:39<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  92%|█████████▏| 618/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  92%|█████████▏| 620/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  93%|█████████▎| 623/671 [03:39<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  94%|█████████▎| 628/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  94%|█████████▍| 630/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  94%|█████████▍| 632/671 [03:41<00:13,  2.85it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  95%|█████████▍| 635/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  95%|█████████▍| 637/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  95%|█████████▌| 640/671 [03:42<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  96%|█████████▌| 641/671 [03:42<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  96%|█████████▌| 642/671 [03:43<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  96%|█████████▌| 645/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  97%|█████████▋| 648/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  97%|█████████▋| 653/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  97%|█████████▋| 654/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  98%|█████████▊| 657/671 [03:45<00:04,  2.91it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  98%|█████████▊| 658/671 [03:45<00:04,  2.91it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  98%|█████████▊| 660/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  99%|█████████▊| 662/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  99%|█████████▉| 665/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  99%|█████████▉| 666/671 [03:47<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9:  99%|█████████▉| 667/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9: 100%|█████████▉| 670/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0191, val_loss_epoch=0.0243, train_loss_epoch=0.0171]\n",
      "Epoch 9: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0626, train_loss_step=0.0191, val_loss_epoch=0.0651, train_loss_epoch=0.0171]\n",
      "Epoch 10:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  90%|█████████ | 606/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  90%|█████████ | 607/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  91%|█████████ | 612/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  92%|█████████▏| 618/671 [03:38<00:18,  2.82it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  92%|█████████▏| 619/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  95%|█████████▍| 635/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  95%|█████████▍| 637/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  96%|█████████▌| 644/671 [03:43<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  96%|█████████▌| 645/671 [03:43<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  97%|█████████▋| 648/671 [03:43<00:07,  2.89it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  97%|█████████▋| 649/671 [03:44<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  99%|█████████▊| 662/671 [03:46<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  99%|█████████▉| 665/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0626, train_loss_step=0.0187, val_loss_epoch=0.0651, train_loss_epoch=0.0169]\n",
      "Epoch 10: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.109, train_loss_step=0.0187, val_loss_epoch=0.126, train_loss_epoch=0.0169]  \n",
      "Epoch 11:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  89%|████████▉ | 599/671 [03:35<00:25,  2.77it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  89%|████████▉ | 600/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|████████▉ | 603/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|█████████ | 606/671 [03:37<00:23,  2.79it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 611/671 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 612/671 [03:38<00:21,  2.81it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 615/671 [03:38<00:19,  2.81it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 618/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 623/671 [03:39<00:16,  2.83it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 624/671 [03:40<00:16,  2.84it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 630/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▍| 635/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▍| 637/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▌| 640/671 [03:42<00:10,  2.87it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 642/671 [03:43<00:10,  2.88it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 645/671 [03:43<00:09,  2.89it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 648/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 649/671 [03:44<00:07,  2.90it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 653/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 657/671 [03:45<00:04,  2.91it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▊| 662/671 [03:46<00:03,  2.93it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▉| 665/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▉| 666/671 [03:46<00:01,  2.93it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▉| 667/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11: 100%|█████████▉| 670/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.109, train_loss_step=0.0182, val_loss_epoch=0.126, train_loss_epoch=0.0167]\n",
      "Epoch 11: 100%|██████████| 671/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0312, train_loss_step=0.0182, val_loss_epoch=0.0359, train_loss_epoch=0.0167]\n",
      "Epoch 12:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|█████████ | 606/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  90%|█████████ | 607/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████ | 612/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 618/671 [03:38<00:18,  2.82it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 619/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 623/671 [03:39<00:16,  2.83it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▍| 635/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▍| 637/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 644/671 [03:43<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▌| 645/671 [03:43<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 648/671 [03:43<00:07,  2.89it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 649/671 [03:44<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 657/671 [03:45<00:04,  2.91it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▊| 662/671 [03:46<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 665/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12:  99%|█████████▉| 667/671 [03:47<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12: 100%|█████████▉| 670/671 [03:47<00:00,  2.94it/s, loss=0.016, val_loss_step=0.0312, train_loss_step=0.0219, val_loss_epoch=0.0359, train_loss_epoch=0.0166]\n",
      "Epoch 12: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.016, val_loss_step=0.0146, train_loss_step=0.0219, val_loss_epoch=0.0202, train_loss_epoch=0.0166]\n",
      "Epoch 13:  89%|████████▉ | 597/671 [03:35<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|█████████ | 606/671 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████ | 612/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  91%|█████████▏| 613/671 [03:37<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 618/671 [03:38<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 625/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  93%|█████████▎| 627/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 631/671 [03:40<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 643/671 [03:42<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 644/671 [03:43<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▌| 645/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 655/671 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▊| 662/671 [03:46<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0146, train_loss_step=0.0195, val_loss_epoch=0.0202, train_loss_epoch=0.0165]\n",
      "Epoch 13: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0226, train_loss_step=0.0195, val_loss_epoch=0.0258, train_loss_epoch=0.0165]\n",
      "Epoch 14:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 606/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 607/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 612/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 618/671 [03:38<00:18,  2.82it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 619/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▍| 635/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▍| 637/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 644/671 [03:43<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 645/671 [03:43<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 648/671 [03:43<00:07,  2.89it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 649/671 [03:44<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▊| 662/671 [03:46<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 665/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0226, train_loss_step=0.0153, val_loss_epoch=0.0258, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0491, train_loss_step=0.0153, val_loss_epoch=0.0569, train_loss_epoch=0.0164]\n",
      "Epoch 15:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|█████████ | 606/671 [03:36<00:23,  2.79it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|█████████ | 607/671 [03:37<00:22,  2.80it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 612/671 [03:37<00:21,  2.81it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 618/671 [03:38<00:18,  2.82it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 619/671 [03:39<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▍| 635/671 [03:41<00:12,  2.86it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▍| 637/671 [03:42<00:11,  2.87it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 645/671 [03:43<00:09,  2.89it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 648/671 [03:43<00:07,  2.89it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 649/671 [03:44<00:07,  2.90it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▊| 662/671 [03:46<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 665/671 [03:46<00:02,  2.93it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 667/671 [03:47<00:01,  2.94it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0491, train_loss_step=0.0139, val_loss_epoch=0.0569, train_loss_epoch=0.0162]\n",
      "Epoch 15: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0139, val_loss_epoch=0.0177, train_loss_epoch=0.0162]\n",
      "Epoch 16:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|████████▉ | 603/671 [03:35<00:24,  2.79it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████ | 610/671 [03:36<00:21,  2.81it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 615/671 [03:37<00:19,  2.82it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 622/671 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 624/671 [03:39<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▎| 629/671 [03:40<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  95%|█████████▌| 640/671 [03:41<00:10,  2.88it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▌| 641/671 [03:42<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 649/671 [03:43<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 652/671 [03:43<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  97%|█████████▋| 654/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16: 100%|█████████▉| 670/671 [03:46<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0205, val_loss_epoch=0.0177, train_loss_epoch=0.0161]\n",
      "Epoch 16: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0129, train_loss_step=0.0205, val_loss_epoch=0.0173, train_loss_epoch=0.0161]\n",
      "Epoch 17:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|█████████ | 604/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 608/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 609/671 [03:37<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  92%|█████████▏| 620/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 621/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 625/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  93%|█████████▎| 627/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  94%|█████████▍| 634/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▌| 639/671 [03:42<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▌| 645/671 [03:42<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▋| 646/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 650/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▉| 663/671 [03:45<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▉| 664/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0129, train_loss_step=0.0187, val_loss_epoch=0.0173, train_loss_epoch=0.016]\n",
      "Epoch 17: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0187, val_loss_epoch=0.0179, train_loss_epoch=0.016] \n",
      "Epoch 18:  89%|████████▉ | 597/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  90%|████████▉ | 601/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  90%|████████▉ | 602/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  91%|█████████▏| 613/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  92%|█████████▏| 614/671 [03:38<00:20,  2.82it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  93%|█████████▎| 625/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  93%|█████████▎| 627/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  94%|█████████▍| 631/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  95%|█████████▌| 639/671 [03:42<00:11,  2.88it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  96%|█████████▌| 644/671 [03:43<00:09,  2.89it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  96%|█████████▌| 645/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  98%|█████████▊| 655/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  98%|█████████▊| 656/671 [03:45<00:05,  2.92it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18: 100%|█████████▉| 668/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18: 100%|█████████▉| 669/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.013, train_loss_step=0.0216, val_loss_epoch=0.0179, train_loss_epoch=0.0159]\n",
      "Epoch 18: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0125, train_loss_step=0.0216, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 604/671 [03:36<00:23,  2.79it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 608/671 [03:36<00:22,  2.80it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 609/671 [03:37<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 620/671 [03:38<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 621/671 [03:39<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 633/671 [03:40<00:13,  2.86it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 634/671 [03:41<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 645/671 [03:42<00:08,  2.89it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▋| 646/671 [03:43<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 650/671 [03:43<00:07,  2.90it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 663/671 [03:45<00:02,  2.93it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  99%|█████████▉| 664/671 [03:46<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0125, train_loss_step=0.0104, val_loss_epoch=0.0169, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0104, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|████████▉ | 603/671 [03:35<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|█████████ | 604/671 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 608/671 [03:36<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 615/671 [03:37<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 620/671 [03:38<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▎| 629/671 [03:40<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 634/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 645/671 [03:42<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▋| 646/671 [03:43<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 664/671 [03:46<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0127, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 20: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0126, train_loss_step=0.0144, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 21:  89%|████████▉ | 597/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|████████▉ | 601/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|████████▉ | 602/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  91%|█████████▏| 613/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 618/671 [03:38<00:18,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 625/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  93%|█████████▎| 627/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 631/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▌| 639/671 [03:42<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 643/671 [03:42<00:09,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 644/671 [03:43<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▌| 645/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 655/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 656/671 [03:45<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▊| 662/671 [03:46<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0158]\n",
      "Epoch 21: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0141, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|█████████ | 604/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 608/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 609/671 [03:37<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  92%|█████████▏| 620/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 621/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 633/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  94%|█████████▍| 634/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▌| 645/671 [03:42<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▋| 646/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 650/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 663/671 [03:45<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 664/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.0168, train_loss_epoch=0.0158]\n",
      "Epoch 22: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0151, val_loss_epoch=0.017, train_loss_epoch=0.0158] \n",
      "Epoch 23:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 598/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|████████▉ | 603/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 610/671 [03:36<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 615/671 [03:37<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 622/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 624/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▎| 629/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 632/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▌| 640/671 [03:41<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 641/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 649/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 652/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 654/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|█████████▉| 670/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0126, train_loss_step=0.0137, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0137, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 604/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 608/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 609/671 [03:37<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 620/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 621/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 625/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 627/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 634/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▌| 639/671 [03:42<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 645/671 [03:42<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 650/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 663/671 [03:45<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 664/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0142, train_loss_step=0.0179, val_loss_epoch=0.018, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0135, train_loss_step=0.0179, val_loss_epoch=0.0184, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0135, train_loss_step=0.0179, val_loss_epoch=0.0184, train_loss_epoch=0.0159]\n",
      "Test iterations: 136\n",
      "Testing: 100%|██████████| 136/136 [00:20<00:00,  6.65it/s]Logits: tensor([[ -8.2188,  -8.6719,  -6.9375,  ...,  -6.1680,  -4.7695,  -5.9023],\n",
      "        [ -8.7578,  -8.8438,  -7.4727,  ...,  -7.0078,  -5.6641,  -6.7891],\n",
      "        [-14.6484, -14.1797, -10.4766,  ..., -11.4141,  -7.4102, -11.1562],\n",
      "        ...,\n",
      "        [ -7.8750,  -7.4023,  -6.6289,  ...,  -6.4492,  -5.3477,  -6.2305],\n",
      "        [ -8.3438,  -8.5078,  -6.9492,  ...,  -6.3750,  -4.9531,  -6.0781],\n",
      "        [ -7.3711,  -6.6445,  -6.4258,  ...,  -6.3008,  -5.6992,  -6.2656]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[2.6941e-04 1.7130e-04 9.6989e-04 ... 2.0905e-03 8.4152e-03 2.7256e-03]\n",
      " [1.5724e-04 1.4424e-04 5.6791e-04 ... 9.0408e-04 3.4561e-03 1.1244e-03]\n",
      " [4.1723e-07 7.1526e-07 2.8193e-05 ... 1.1027e-05 6.0463e-04 1.4305e-05]\n",
      " ...\n",
      " [3.8004e-04 6.0940e-04 1.3199e-03 ... 1.5793e-03 4.7379e-03 1.9646e-03]\n",
      " [2.3782e-04 2.0182e-04 9.5844e-04 ... 1.7004e-03 7.0114e-03 2.2869e-03]\n",
      " [6.2895e-04 1.2999e-03 1.6165e-03 ... 1.8311e-03 3.3379e-03 1.8969e-03]]\n",
      "Testing: 100%|██████████| 136/136 [00:20<00:00,  6.55it/s]\n",
      "==================== Fold 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 11 M  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 74\n",
      "Train iterations: 597                                                 \n",
      "Epoch 0:  89%|████████▉ | 597/671 [03:35<00:26,  2.76it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 598/671 [03:36<00:26,  2.76it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  89%|████████▉ | 599/671 [03:36<00:26,  2.77it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  90%|████████▉ | 601/671 [03:36<00:25,  2.77it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  90%|████████▉ | 602/671 [03:37<00:24,  2.77it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  90%|████████▉ | 603/671 [03:37<00:24,  2.78it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  90%|█████████ | 604/671 [03:37<00:24,  2.78it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  90%|█████████ | 605/671 [03:37<00:23,  2.78it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  90%|█████████ | 606/671 [03:37<00:23,  2.78it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  91%|█████████ | 608/671 [03:38<00:22,  2.79it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  91%|█████████ | 609/671 [03:38<00:22,  2.79it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  91%|█████████ | 610/671 [03:38<00:21,  2.79it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  91%|█████████ | 611/671 [03:38<00:21,  2.80it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  91%|█████████▏| 613/671 [03:38<00:20,  2.80it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  92%|█████████▏| 614/671 [03:39<00:20,  2.80it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  92%|█████████▏| 615/671 [03:39<00:19,  2.81it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  92%|█████████▏| 616/671 [03:39<00:19,  2.81it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  92%|█████████▏| 617/671 [03:39<00:19,  2.81it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  92%|█████████▏| 618/671 [03:39<00:18,  2.81it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  92%|█████████▏| 620/671 [03:40<00:18,  2.82it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  93%|█████████▎| 621/671 [03:40<00:17,  2.82it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  93%|█████████▎| 622/671 [03:40<00:17,  2.82it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  93%|█████████▎| 623/671 [03:40<00:16,  2.82it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  93%|█████████▎| 625/671 [03:40<00:16,  2.83it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  93%|█████████▎| 626/671 [03:41<00:15,  2.83it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  93%|█████████▎| 627/671 [03:41<00:15,  2.83it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  94%|█████████▎| 628/671 [03:41<00:15,  2.84it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  94%|█████████▎| 629/671 [03:41<00:14,  2.84it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  94%|█████████▍| 630/671 [03:41<00:14,  2.84it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  94%|█████████▍| 631/671 [03:41<00:14,  2.84it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  94%|█████████▍| 632/671 [03:42<00:13,  2.85it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  94%|█████████▍| 633/671 [03:42<00:13,  2.85it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  94%|█████████▍| 634/671 [03:42<00:12,  2.85it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  95%|█████████▍| 635/671 [03:42<00:12,  2.85it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  95%|█████████▍| 637/671 [03:42<00:11,  2.86it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  95%|█████████▌| 638/671 [03:43<00:11,  2.86it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  95%|█████████▌| 639/671 [03:43<00:11,  2.86it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  95%|█████████▌| 640/671 [03:43<00:10,  2.86it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  96%|█████████▌| 642/671 [03:43<00:10,  2.87it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  96%|█████████▌| 643/671 [03:43<00:09,  2.87it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  96%|█████████▌| 644/671 [03:44<00:09,  2.87it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  96%|█████████▌| 645/671 [03:44<00:09,  2.88it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  96%|█████████▋| 646/671 [03:44<00:08,  2.88it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  96%|█████████▋| 647/671 [03:44<00:08,  2.88it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  97%|█████████▋| 648/671 [03:44<00:07,  2.88it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  97%|█████████▋| 650/671 [03:45<00:07,  2.89it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  97%|█████████▋| 651/671 [03:45<00:06,  2.89it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  97%|█████████▋| 652/671 [03:45<00:06,  2.89it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  97%|█████████▋| 653/671 [03:45<00:06,  2.90it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  98%|█████████▊| 655/671 [03:45<00:05,  2.90it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  98%|█████████▊| 656/671 [03:46<00:05,  2.90it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  98%|█████████▊| 657/671 [03:46<00:04,  2.90it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  98%|█████████▊| 658/671 [03:46<00:04,  2.91it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  98%|█████████▊| 659/671 [03:46<00:04,  2.91it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  98%|█████████▊| 660/671 [03:46<00:03,  2.91it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  99%|█████████▊| 661/671 [03:46<00:03,  2.91it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  99%|█████████▊| 662/671 [03:47<00:03,  2.92it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  99%|█████████▉| 663/671 [03:47<00:02,  2.92it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  99%|█████████▉| 664/671 [03:47<00:02,  2.92it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  99%|█████████▉| 665/671 [03:47<00:02,  2.92it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|█████████▉| 666/671 [03:47<00:01,  2.92it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0:  99%|█████████▉| 667/671 [03:47<00:01,  2.93it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0: 100%|█████████▉| 668/671 [03:48<00:01,  2.93it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0: 100%|█████████▉| 669/671 [03:48<00:00,  2.93it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0: 100%|█████████▉| 670/671 [03:48<00:00,  2.93it/s, loss=0.020, val_loss_step=0.699, train_loss_step=0.0218]\n",
      "Epoch 0: 100%|██████████| 671/671 [03:48<00:00,  2.93it/s, loss=0.020, val_loss_step=0.0209, train_loss_step=0.0218, val_loss_epoch=0.0205]\n",
      "Epoch 1:  89%|████████▉ | 597/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 598/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  89%|████████▉ | 599/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|████████▉ | 601/671 [03:37<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|████████▉ | 602/671 [03:37<00:24,  2.77it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|████████▉ | 603/671 [03:37<00:24,  2.77it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|█████████ | 604/671 [03:37<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|█████████ | 605/671 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|█████████ | 606/671 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  90%|█████████ | 607/671 [03:38<00:22,  2.78it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 608/671 [03:38<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 609/671 [03:38<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 610/671 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 611/671 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  91%|█████████▏| 613/671 [03:39<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 614/671 [03:39<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 615/671 [03:39<00:19,  2.80it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 616/671 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 617/671 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 618/671 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 619/671 [03:40<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  92%|█████████▏| 620/671 [03:40<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 621/671 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 622/671 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 623/671 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 625/671 [03:41<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 626/671 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  93%|█████████▎| 627/671 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▎| 628/671 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▎| 629/671 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 630/671 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 631/671 [03:42<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 632/671 [03:42<00:13,  2.84it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 633/671 [03:42<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  94%|█████████▍| 634/671 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▍| 635/671 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▍| 636/671 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▍| 637/671 [03:43<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▌| 638/671 [03:43<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▌| 639/671 [03:43<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  95%|█████████▌| 640/671 [03:43<00:10,  2.86it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|█████████▌| 642/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▌| 643/671 [03:44<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▌| 644/671 [03:44<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▌| 645/671 [03:44<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▋| 646/671 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  96%|█████████▋| 647/671 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 648/671 [03:44<00:07,  2.88it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 649/671 [03:45<00:07,  2.88it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 650/671 [03:45<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 651/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 652/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 653/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 655/671 [03:46<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 656/671 [03:46<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 657/671 [03:46<00:04,  2.90it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 658/671 [03:46<00:04,  2.90it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 659/671 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  98%|█████████▊| 660/671 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▊| 661/671 [03:47<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▊| 662/671 [03:47<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 663/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 664/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 665/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 666/671 [03:47<00:01,  2.92it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1:  99%|█████████▉| 667/671 [03:48<00:01,  2.92it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1: 100%|█████████▉| 668/671 [03:48<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1: 100%|█████████▉| 669/671 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1: 100%|█████████▉| 670/671 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0209, train_loss_step=0.0147, val_loss_epoch=0.0205, train_loss_epoch=0.0257]\n",
      "Epoch 1: 100%|██████████| 671/671 [03:49<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0147, val_loss_epoch=0.0193, train_loss_epoch=0.0257]\n",
      "Epoch 2:  89%|████████▉ | 597/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 598/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  89%|████████▉ | 599/671 [03:37<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|████████▉ | 601/671 [03:37<00:25,  2.76it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|████████▉ | 602/671 [03:37<00:24,  2.77it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|████████▉ | 603/671 [03:37<00:24,  2.77it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 604/671 [03:37<00:24,  2.77it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 605/671 [03:38<00:23,  2.77it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 606/671 [03:38<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  90%|█████████ | 607/671 [03:38<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 608/671 [03:38<00:22,  2.78it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 609/671 [03:38<00:22,  2.78it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 610/671 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 611/671 [03:39<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████ | 612/671 [03:39<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  91%|█████████▏| 613/671 [03:39<00:20,  2.79it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 614/671 [03:39<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 615/671 [03:39<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  92%|█████████▏| 616/671 [03:39<00:19,  2.80it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 617/671 [03:40<00:19,  2.80it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 618/671 [03:40<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 619/671 [03:40<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  92%|█████████▏| 620/671 [03:40<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 621/671 [03:40<00:17,  2.81it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 622/671 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 623/671 [03:41<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 624/671 [03:41<00:16,  2.82it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 625/671 [03:41<00:16,  2.82it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 626/671 [03:41<00:15,  2.82it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  93%|█████████▎| 627/671 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▎| 628/671 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▎| 629/671 [03:42<00:14,  2.83it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 630/671 [03:42<00:14,  2.83it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 631/671 [03:42<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 632/671 [03:42<00:13,  2.84it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 633/671 [03:42<00:13,  2.84it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  94%|█████████▍| 634/671 [03:42<00:13,  2.84it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▍| 635/671 [03:43<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▍| 636/671 [03:43<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▍| 637/671 [03:43<00:11,  2.85it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▌| 638/671 [03:43<00:11,  2.85it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▌| 639/671 [03:43<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  95%|█████████▌| 640/671 [03:43<00:10,  2.86it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 641/671 [03:44<00:10,  2.86it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 642/671 [03:44<00:10,  2.86it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 643/671 [03:44<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 644/671 [03:44<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▌| 645/671 [03:44<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▋| 646/671 [03:44<00:08,  2.87it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  96%|█████████▋| 647/671 [03:45<00:08,  2.87it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 648/671 [03:45<00:07,  2.88it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 649/671 [03:45<00:07,  2.88it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 650/671 [03:45<00:07,  2.88it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 651/671 [03:45<00:06,  2.88it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 652/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 653/671 [03:46<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  97%|█████████▋| 654/671 [03:46<00:05,  2.89it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 655/671 [03:46<00:05,  2.89it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 656/671 [03:46<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 657/671 [03:46<00:04,  2.90it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 658/671 [03:46<00:04,  2.90it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 659/671 [03:47<00:04,  2.90it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  98%|█████████▊| 660/671 [03:47<00:03,  2.90it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▊| 661/671 [03:47<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▊| 662/671 [03:47<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 663/671 [03:47<00:02,  2.91it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 664/671 [03:47<00:02,  2.91it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  99%|█████████▉| 665/671 [03:48<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 666/671 [03:48<00:01,  2.92it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2:  99%|█████████▉| 667/671 [03:48<00:01,  2.92it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|█████████▉| 668/671 [03:48<00:01,  2.92it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|█████████▉| 669/671 [03:48<00:00,  2.92it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|█████████▉| 670/671 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0205, train_loss_step=0.0149, val_loss_epoch=0.0193, train_loss_epoch=0.0195]\n",
      "Epoch 2: 100%|██████████| 671/671 [03:49<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0254, train_loss_step=0.0149, val_loss_epoch=0.0246, train_loss_epoch=0.0195]\n",
      "Epoch 3:  89%|████████▉ | 597/671 [03:36<00:26,  2.76it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 598/671 [03:36<00:26,  2.76it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  89%|████████▉ | 599/671 [03:36<00:26,  2.76it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  89%|████████▉ | 600/671 [03:37<00:25,  2.76it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  90%|████████▉ | 601/671 [03:37<00:25,  2.77it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  90%|████████▉ | 602/671 [03:37<00:24,  2.77it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  90%|████████▉ | 603/671 [03:37<00:24,  2.77it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  90%|█████████ | 604/671 [03:37<00:24,  2.77it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  90%|█████████ | 605/671 [03:37<00:23,  2.78it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  90%|█████████ | 606/671 [03:38<00:23,  2.78it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  90%|█████████ | 607/671 [03:38<00:23,  2.78it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  91%|█████████ | 608/671 [03:38<00:22,  2.78it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  91%|█████████ | 609/671 [03:38<00:22,  2.79it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  91%|█████████ | 610/671 [03:38<00:21,  2.79it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  91%|█████████ | 611/671 [03:38<00:21,  2.79it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  91%|█████████ | 612/671 [03:39<00:21,  2.79it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  91%|█████████▏| 613/671 [03:39<00:20,  2.80it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  92%|█████████▏| 614/671 [03:39<00:20,  2.80it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  92%|█████████▏| 615/671 [03:39<00:19,  2.80it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  92%|█████████▏| 616/671 [03:39<00:19,  2.80it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  92%|█████████▏| 617/671 [03:39<00:19,  2.81it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  92%|█████████▏| 618/671 [03:40<00:18,  2.81it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  92%|█████████▏| 619/671 [03:40<00:18,  2.81it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  92%|█████████▏| 620/671 [03:40<00:18,  2.81it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  93%|█████████▎| 621/671 [03:40<00:17,  2.82it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  93%|█████████▎| 622/671 [03:40<00:17,  2.82it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  93%|█████████▎| 623/671 [03:40<00:17,  2.82it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  93%|█████████▎| 624/671 [03:41<00:16,  2.82it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  93%|█████████▎| 625/671 [03:41<00:16,  2.83it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  93%|█████████▎| 626/671 [03:41<00:15,  2.83it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  93%|█████████▎| 627/671 [03:41<00:15,  2.83it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  94%|█████████▎| 628/671 [03:41<00:15,  2.83it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  94%|█████████▎| 629/671 [03:41<00:14,  2.83it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  94%|█████████▍| 630/671 [03:42<00:14,  2.84it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  94%|█████████▍| 631/671 [03:42<00:14,  2.84it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  94%|█████████▍| 632/671 [03:42<00:13,  2.84it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  94%|█████████▍| 633/671 [03:42<00:13,  2.84it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  94%|█████████▍| 634/671 [03:42<00:12,  2.85it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  95%|█████████▍| 635/671 [03:42<00:12,  2.85it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  95%|█████████▍| 636/671 [03:43<00:12,  2.85it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  95%|█████████▍| 637/671 [03:43<00:11,  2.85it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  95%|█████████▌| 638/671 [03:43<00:11,  2.86it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  95%|█████████▌| 639/671 [03:43<00:11,  2.86it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  95%|█████████▌| 640/671 [03:43<00:10,  2.86it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  96%|█████████▌| 641/671 [03:43<00:10,  2.86it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  96%|█████████▌| 642/671 [03:44<00:10,  2.87it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  96%|█████████▌| 643/671 [03:44<00:09,  2.87it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  96%|█████████▌| 644/671 [03:44<00:09,  2.87it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  96%|█████████▌| 645/671 [03:44<00:09,  2.87it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  96%|█████████▋| 646/671 [03:44<00:08,  2.87it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  96%|█████████▋| 647/671 [03:44<00:08,  2.88it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  97%|█████████▋| 648/671 [03:45<00:07,  2.88it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  97%|█████████▋| 649/671 [03:45<00:07,  2.88it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  97%|█████████▋| 650/671 [03:45<00:07,  2.88it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  97%|█████████▋| 651/671 [03:45<00:06,  2.89it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  97%|█████████▋| 652/671 [03:45<00:06,  2.89it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  97%|█████████▋| 653/671 [03:45<00:06,  2.89it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  97%|█████████▋| 654/671 [03:46<00:05,  2.89it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  98%|█████████▊| 655/671 [03:46<00:05,  2.90it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  98%|█████████▊| 656/671 [03:46<00:05,  2.90it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  98%|█████████▊| 657/671 [03:46<00:04,  2.90it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  98%|█████████▊| 658/671 [03:46<00:04,  2.90it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  98%|█████████▊| 659/671 [03:46<00:04,  2.90it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  98%|█████████▊| 660/671 [03:47<00:03,  2.91it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  99%|█████████▊| 661/671 [03:47<00:03,  2.91it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  99%|█████████▊| 662/671 [03:47<00:03,  2.91it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  99%|█████████▉| 663/671 [03:47<00:02,  2.91it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  99%|█████████▉| 664/671 [03:47<00:02,  2.92it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  99%|█████████▉| 665/671 [03:47<00:02,  2.92it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  99%|█████████▉| 666/671 [03:48<00:01,  2.92it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3:  99%|█████████▉| 667/671 [03:48<00:01,  2.92it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3: 100%|█████████▉| 668/671 [03:48<00:01,  2.93it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3: 100%|█████████▉| 669/671 [03:48<00:00,  2.93it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3: 100%|█████████▉| 670/671 [03:48<00:00,  2.93it/s, loss=0.019, val_loss_step=0.0254, train_loss_step=0.0278, val_loss_epoch=0.0246, train_loss_epoch=0.019]\n",
      "Epoch 3: 100%|██████████| 671/671 [03:49<00:00,  2.93it/s, loss=0.019, val_loss_step=0.0198, train_loss_step=0.0278, val_loss_epoch=0.0193, train_loss_epoch=0.019]\n",
      "Epoch 4:  89%|████████▉ | 597/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 598/671 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  89%|████████▉ | 599/671 [03:36<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|████████▉ | 601/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|████████▉ | 602/671 [03:37<00:24,  2.77it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|████████▉ | 603/671 [03:37<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|█████████ | 604/671 [03:37<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|█████████ | 605/671 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|█████████ | 606/671 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  90%|█████████ | 607/671 [03:37<00:22,  2.78it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 608/671 [03:38<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 609/671 [03:38<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 610/671 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 611/671 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  91%|█████████▏| 613/671 [03:38<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 614/671 [03:39<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 615/671 [03:39<00:19,  2.80it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 616/671 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 617/671 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 618/671 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 619/671 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  92%|█████████▏| 620/671 [03:40<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 621/671 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 622/671 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 623/671 [03:40<00:16,  2.82it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 625/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 626/671 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  93%|█████████▎| 627/671 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▎| 628/671 [03:41<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▎| 629/671 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 630/671 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 631/671 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 632/671 [03:42<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 633/671 [03:42<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  94%|█████████▍| 634/671 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▍| 635/671 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▍| 637/671 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▌| 638/671 [03:43<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▌| 639/671 [03:43<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  95%|█████████▌| 640/671 [03:43<00:10,  2.86it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 642/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 643/671 [03:43<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 644/671 [03:44<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▌| 645/671 [03:44<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▋| 646/671 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  96%|█████████▋| 647/671 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 648/671 [03:44<00:07,  2.88it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 650/671 [03:45<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 651/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 652/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 653/671 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 655/671 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 656/671 [03:46<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 657/671 [03:46<00:04,  2.90it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 658/671 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 659/671 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  98%|█████████▊| 660/671 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▊| 661/671 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  99%|█████████▊| 662/671 [03:47<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 663/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 664/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 665/671 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 666/671 [03:47<00:01,  2.92it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4:  99%|█████████▉| 667/671 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4: 100%|█████████▉| 668/671 [03:48<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4: 100%|█████████▉| 669/671 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4: 100%|█████████▉| 670/671 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0175, val_loss_epoch=0.0193, train_loss_epoch=0.0186]\n",
      "Epoch 4: 100%|██████████| 671/671 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0191, train_loss_step=0.0175, val_loss_epoch=0.019, train_loss_epoch=0.0186] \n",
      "Epoch 5:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 599/671 [03:36<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|████████▉ | 603/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 604/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 605/671 [03:37<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 606/671 [03:37<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 608/671 [03:37<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 611/671 [03:38<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 615/671 [03:38<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 616/671 [03:38<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 617/671 [03:39<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 618/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 620/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 623/671 [03:40<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▎| 628/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▎| 629/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 630/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 632/671 [03:41<00:13,  2.85it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 633/671 [03:41<00:13,  2.85it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▍| 635/671 [03:42<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▍| 637/671 [03:42<00:11,  2.86it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▌| 640/671 [03:42<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 642/671 [03:43<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 645/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▋| 647/671 [03:44<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 648/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 650/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 653/671 [03:45<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 657/671 [03:45<00:04,  2.91it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 658/671 [03:45<00:04,  2.91it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 659/671 [03:46<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 660/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▊| 662/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 663/671 [03:46<00:02,  2.92it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 665/671 [03:47<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 666/671 [03:47<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 667/671 [03:47<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|█████████▉| 670/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0191, train_loss_step=0.0105, val_loss_epoch=0.019, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0105, val_loss_epoch=0.0203, train_loss_epoch=0.0183]\n",
      "Epoch 6:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|█████████ | 606/671 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  90%|█████████ | 607/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████ | 612/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 618/671 [03:38<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 623/671 [03:39<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▍| 635/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▍| 637/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▌| 645/671 [03:43<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 648/671 [03:43<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 649/671 [03:44<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▊| 662/671 [03:46<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 665/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6:  99%|█████████▉| 667/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6: 100%|█████████▉| 670/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0192, train_loss_step=0.0102, val_loss_epoch=0.0203, train_loss_epoch=0.0181]\n",
      "Epoch 6: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0102, val_loss_epoch=0.0186, train_loss_epoch=0.0181]\n",
      "Epoch 7:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  89%|████████▉ | 599/671 [03:36<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  90%|████████▉ | 603/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  90%|█████████ | 604/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  90%|█████████ | 605/671 [03:37<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  90%|█████████ | 606/671 [03:37<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  91%|█████████ | 608/671 [03:37<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  91%|█████████ | 611/671 [03:38<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  92%|█████████▏| 615/671 [03:38<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  92%|█████████▏| 616/671 [03:38<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  92%|█████████▏| 617/671 [03:39<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  92%|█████████▏| 618/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  92%|█████████▏| 620/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  93%|█████████▎| 623/671 [03:40<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  94%|█████████▎| 628/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  94%|█████████▎| 629/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  94%|█████████▍| 630/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  94%|█████████▍| 632/671 [03:41<00:13,  2.85it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  95%|█████████▍| 635/671 [03:42<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  95%|█████████▍| 637/671 [03:42<00:11,  2.86it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  95%|█████████▌| 640/671 [03:42<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  96%|█████████▌| 642/671 [03:43<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  96%|█████████▌| 645/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  96%|█████████▋| 647/671 [03:44<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  97%|█████████▋| 648/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  97%|█████████▋| 653/671 [03:45<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  98%|█████████▊| 657/671 [03:45<00:04,  2.91it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  98%|█████████▊| 658/671 [03:45<00:04,  2.91it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  98%|█████████▊| 660/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  99%|█████████▊| 662/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  99%|█████████▉| 665/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  99%|█████████▉| 666/671 [03:47<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7:  99%|█████████▉| 667/671 [03:47<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7: 100%|█████████▉| 670/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0178, train_loss_step=0.0165, val_loss_epoch=0.0186, train_loss_epoch=0.0179]\n",
      "Epoch 7: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0212, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0179]\n",
      "Epoch 8:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  89%|████████▉ | 599/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  89%|████████▉ | 600/671 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  90%|████████▉ | 603/671 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  90%|█████████ | 604/671 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  90%|█████████ | 605/671 [03:37<00:23,  2.79it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  90%|█████████ | 606/671 [03:37<00:23,  2.79it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  91%|█████████ | 608/671 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  91%|█████████ | 611/671 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  91%|█████████ | 612/671 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  92%|█████████▏| 615/671 [03:38<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  92%|█████████▏| 616/671 [03:38<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  92%|█████████▏| 617/671 [03:39<00:19,  2.82it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  92%|█████████▏| 618/671 [03:39<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  92%|█████████▏| 620/671 [03:39<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  93%|█████████▎| 623/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  93%|█████████▎| 624/671 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  94%|█████████▎| 628/671 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  94%|█████████▎| 629/671 [03:41<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  94%|█████████▍| 630/671 [03:41<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  94%|█████████▍| 632/671 [03:41<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  94%|█████████▍| 633/671 [03:41<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  95%|█████████▍| 635/671 [03:42<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  95%|█████████▍| 637/671 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  95%|█████████▌| 640/671 [03:42<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  96%|█████████▌| 641/671 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  96%|█████████▌| 642/671 [03:43<00:10,  2.88it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  96%|█████████▌| 645/671 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  96%|█████████▋| 647/671 [03:44<00:08,  2.89it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  97%|█████████▋| 648/671 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  97%|█████████▋| 650/671 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  97%|█████████▋| 653/671 [03:45<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  97%|█████████▋| 654/671 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  98%|█████████▊| 657/671 [03:45<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  98%|█████████▊| 658/671 [03:45<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  98%|█████████▊| 659/671 [03:46<00:04,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  98%|█████████▊| 660/671 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  99%|█████████▊| 662/671 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  99%|█████████▉| 663/671 [03:46<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  99%|█████████▉| 665/671 [03:47<00:02,  2.93it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  99%|█████████▉| 666/671 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8:  99%|█████████▉| 667/671 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8: 100%|█████████▉| 670/671 [03:47<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.00855, val_loss_epoch=0.0212, train_loss_epoch=0.0176]\n",
      "Epoch 8: 100%|██████████| 671/671 [03:48<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0531, train_loss_step=0.00855, val_loss_epoch=0.0515, train_loss_epoch=0.0176]\n",
      "Epoch 9:  89%|████████▉ | 597/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 598/671 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  89%|████████▉ | 599/671 [03:35<00:25,  2.77it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  89%|████████▉ | 600/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  90%|████████▉ | 601/671 [03:36<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  90%|████████▉ | 602/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  90%|████████▉ | 603/671 [03:36<00:24,  2.78it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  90%|█████████ | 606/671 [03:37<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  90%|█████████ | 607/671 [03:37<00:22,  2.79it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  91%|█████████ | 610/671 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  91%|█████████ | 611/671 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  91%|█████████ | 612/671 [03:38<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  91%|█████████▏| 613/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  92%|█████████▏| 614/671 [03:38<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  92%|█████████▏| 615/671 [03:38<00:19,  2.81it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  92%|█████████▏| 618/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  92%|█████████▏| 619/671 [03:39<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  93%|█████████▎| 622/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  93%|█████████▎| 623/671 [03:39<00:16,  2.83it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  93%|█████████▎| 624/671 [03:40<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  93%|█████████▎| 625/671 [03:40<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  93%|█████████▎| 626/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  93%|█████████▎| 627/671 [03:40<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  94%|█████████▍| 630/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  94%|█████████▍| 631/671 [03:41<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  94%|█████████▍| 632/671 [03:41<00:13,  2.85it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  95%|█████████▍| 635/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  95%|█████████▍| 636/671 [03:42<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  95%|█████████▍| 637/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  95%|█████████▌| 639/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  95%|█████████▌| 640/671 [03:42<00:10,  2.87it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  96%|█████████▌| 642/671 [03:43<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  96%|█████████▌| 643/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  96%|█████████▌| 644/671 [03:43<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  96%|█████████▌| 645/671 [03:43<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  96%|█████████▋| 647/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  97%|█████████▋| 648/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  97%|█████████▋| 649/671 [03:44<00:07,  2.89it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  97%|█████████▋| 650/671 [03:44<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  97%|█████████▋| 652/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  97%|█████████▋| 653/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  97%|█████████▋| 654/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  98%|█████████▊| 655/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  98%|█████████▊| 656/671 [03:45<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  98%|█████████▊| 657/671 [03:45<00:04,  2.91it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  98%|█████████▊| 660/671 [03:45<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  99%|█████████▊| 661/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  99%|█████████▊| 662/671 [03:46<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  99%|█████████▉| 665/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  99%|█████████▉| 666/671 [03:46<00:01,  2.93it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9:  99%|█████████▉| 667/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9: 100%|█████████▉| 668/671 [03:47<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9: 100%|█████████▉| 669/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9: 100%|█████████▉| 670/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0531, train_loss_step=0.0138, val_loss_epoch=0.0515, train_loss_epoch=0.0174]\n",
      "Epoch 9: 100%|██████████| 671/671 [03:47<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0138, val_loss_epoch=0.03, train_loss_epoch=0.0174]  \n",
      "Epoch 10:  89%|████████▉ | 597/671 [03:35<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  90%|████████▉ | 601/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  90%|████████▉ | 602/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  91%|█████████▏| 613/671 [03:37<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  92%|█████████▏| 614/671 [03:38<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  93%|█████████▎| 625/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  93%|█████████▎| 626/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  93%|█████████▎| 627/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  94%|█████████▍| 632/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  95%|█████████▌| 638/671 [03:42<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  95%|█████████▌| 639/671 [03:42<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  96%|█████████▌| 645/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  97%|█████████▋| 650/671 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  98%|█████████▊| 655/671 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10: 100%|█████████▉| 668/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10: 100%|█████████▉| 669/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0308, train_loss_step=0.0238, val_loss_epoch=0.03, train_loss_epoch=0.0172]\n",
      "Epoch 10: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0203, train_loss_step=0.0238, val_loss_epoch=0.0206, train_loss_epoch=0.0172]\n",
      "Epoch 11:  89%|████████▉ | 597/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|████████▉ | 601/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|████████▉ | 602/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  91%|█████████▏| 613/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 614/671 [03:38<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 625/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  93%|█████████▎| 626/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  93%|█████████▎| 627/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▌| 638/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▌| 639/671 [03:42<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▌| 645/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 650/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 655/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11: 100%|█████████▉| 668/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11: 100%|█████████▉| 669/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0203, train_loss_step=0.0123, val_loss_epoch=0.0206, train_loss_epoch=0.017]\n",
      "Epoch 11: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.0123, val_loss_epoch=0.0609, train_loss_epoch=0.017]\n",
      "Epoch 12:  89%|████████▉ | 597/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  90%|████████▉ | 601/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  90%|████████▉ | 602/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  90%|█████████ | 604/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  90%|█████████ | 605/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  91%|█████████ | 608/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  91%|█████████ | 609/671 [03:37<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  91%|█████████▏| 613/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  92%|█████████▏| 614/671 [03:38<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  92%|█████████▏| 615/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  92%|█████████▏| 617/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  92%|█████████▏| 620/671 [03:39<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  93%|█████████▎| 621/671 [03:39<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  93%|█████████▎| 625/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  93%|█████████▎| 626/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  93%|█████████▎| 627/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  94%|█████████▎| 629/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  94%|█████████▍| 630/671 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  94%|█████████▍| 633/671 [03:41<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  94%|█████████▍| 634/671 [03:41<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  95%|█████████▌| 638/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  95%|█████████▌| 639/671 [03:42<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  96%|█████████▌| 642/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  96%|█████████▌| 645/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  96%|█████████▋| 646/671 [03:43<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  97%|█████████▋| 650/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  97%|█████████▋| 651/671 [03:44<00:06,  2.90it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  98%|█████████▊| 655/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  98%|█████████▊| 657/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  98%|█████████▊| 659/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  99%|█████████▉| 663/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  99%|█████████▉| 664/671 [03:46<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12: 100%|█████████▉| 668/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12: 100%|█████████▉| 669/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0613, train_loss_step=0.00952, val_loss_epoch=0.0609, train_loss_epoch=0.0167]\n",
      "Epoch 12: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.00952, val_loss_epoch=0.0593, train_loss_epoch=0.0167]\n",
      "Epoch 13:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  89%|████████▉ | 598/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  89%|████████▉ | 599/671 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  90%|████████▉ | 603/671 [03:35<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  90%|█████████ | 605/671 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  90%|█████████ | 607/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  91%|█████████ | 610/671 [03:36<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  91%|█████████ | 611/671 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  92%|█████████▏| 615/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  92%|█████████▏| 617/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  92%|█████████▏| 619/671 [03:38<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  93%|█████████▎| 622/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  93%|█████████▎| 623/671 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  93%|█████████▎| 624/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  93%|█████████▎| 627/671 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  94%|█████████▎| 629/671 [03:39<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  94%|█████████▍| 632/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  95%|█████████▍| 635/671 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  95%|█████████▍| 636/671 [03:41<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  95%|█████████▌| 640/671 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  96%|█████████▌| 641/671 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  96%|█████████▌| 644/671 [03:42<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  96%|█████████▋| 647/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  97%|█████████▋| 648/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  97%|█████████▋| 649/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  97%|█████████▋| 652/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  97%|█████████▋| 653/671 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  97%|█████████▋| 654/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  98%|█████████▊| 657/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  98%|█████████▊| 659/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  99%|█████████▊| 661/671 [03:45<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  99%|█████████▉| 665/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  99%|█████████▉| 666/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13: 100%|█████████▉| 670/671 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0606, train_loss_step=0.0185, val_loss_epoch=0.0593, train_loss_epoch=0.0166]\n",
      "Epoch 13: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0174, train_loss_step=0.0185, val_loss_epoch=0.0174, train_loss_epoch=0.0166]\n",
      "Epoch 14:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 604/671 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 608/671 [03:36<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 615/671 [03:37<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  92%|█████████▏| 620/671 [03:38<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▎| 629/671 [03:40<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 633/671 [03:40<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  94%|█████████▍| 634/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▌| 645/671 [03:42<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  96%|█████████▋| 646/671 [03:43<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 664/671 [03:46<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0174, train_loss_step=0.0201, val_loss_epoch=0.0174, train_loss_epoch=0.0164]\n",
      "Epoch 14: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0169, train_loss_step=0.0201, val_loss_epoch=0.0172, train_loss_epoch=0.0164]\n",
      "Epoch 15:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  89%|████████▉ | 598/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|████████▉ | 603/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 610/671 [03:36<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 615/671 [03:37<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 622/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 624/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▎| 629/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  95%|█████████▌| 640/671 [03:41<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 641/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 652/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  97%|█████████▋| 654/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████▉| 670/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.0154, val_loss_epoch=0.0172, train_loss_epoch=0.0163]\n",
      "Epoch 15: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0154, val_loss_epoch=0.017, train_loss_epoch=0.0163] \n",
      "Epoch 16:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  89%|████████▉ | 600/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  90%|████████▉ | 603/671 [03:36<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  90%|█████████ | 604/671 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  91%|█████████ | 608/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  91%|█████████ | 612/671 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  92%|█████████▏| 615/671 [03:37<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  92%|█████████▏| 616/671 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  92%|█████████▏| 620/671 [03:38<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  94%|█████████▎| 629/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  94%|█████████▍| 633/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  94%|█████████▍| 634/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  95%|█████████▍| 637/671 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  95%|█████████▌| 640/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  96%|█████████▌| 641/671 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  96%|█████████▌| 645/671 [03:42<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  96%|█████████▋| 646/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  97%|█████████▋| 650/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  97%|█████████▋| 652/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  97%|█████████▋| 654/671 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  98%|█████████▊| 658/671 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  99%|█████████▉| 664/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16:  99%|█████████▉| 667/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16: 100%|█████████▉| 670/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0186, val_loss_epoch=0.017, train_loss_epoch=0.0162]\n",
      "Epoch 16: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0166, train_loss_step=0.0186, val_loss_epoch=0.0169, train_loss_epoch=0.0162]\n",
      "Epoch 17:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  89%|████████▉ | 598/671 [03:34<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  89%|████████▉ | 599/671 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  90%|████████▉ | 603/671 [03:35<00:24,  2.80it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  90%|█████████ | 605/671 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  90%|█████████ | 607/671 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  91%|█████████ | 610/671 [03:36<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  91%|█████████ | 611/671 [03:36<00:21,  2.82it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  92%|█████████▏| 615/671 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  92%|█████████▏| 617/671 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  92%|█████████▏| 619/671 [03:38<00:18,  2.84it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  93%|█████████▎| 622/671 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  93%|█████████▎| 623/671 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  93%|█████████▎| 624/671 [03:39<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  93%|█████████▎| 627/671 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  94%|█████████▎| 629/671 [03:39<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  94%|█████████▍| 631/671 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  94%|█████████▍| 632/671 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  95%|█████████▍| 635/671 [03:40<00:12,  2.88it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  95%|█████████▍| 636/671 [03:41<00:12,  2.88it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  95%|█████████▌| 640/671 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  96%|█████████▌| 641/671 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  96%|█████████▌| 642/671 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  96%|█████████▌| 644/671 [03:42<00:09,  2.90it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  96%|█████████▋| 647/671 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  97%|█████████▋| 648/671 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  97%|█████████▋| 649/671 [03:43<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  97%|█████████▋| 652/671 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  97%|█████████▋| 653/671 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  97%|█████████▋| 654/671 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  98%|█████████▊| 657/671 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  98%|█████████▊| 659/671 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  98%|█████████▊| 660/671 [03:44<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  99%|█████████▊| 661/671 [03:45<00:03,  2.94it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  99%|█████████▉| 665/671 [03:45<00:02,  2.95it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17:  99%|█████████▉| 666/671 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17: 100%|█████████▉| 670/671 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.0166, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0161]\n",
      "Epoch 17: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0182, val_loss_epoch=0.0166, train_loss_epoch=0.0161]\n",
      "Epoch 18:  89%|████████▉ | 597/671 [03:34<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  89%|████████▉ | 598/671 [03:34<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  89%|████████▉ | 599/671 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  89%|████████▉ | 600/671 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|████████▉ | 602/671 [03:35<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|████████▉ | 603/671 [03:35<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|█████████ | 605/671 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|█████████ | 606/671 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  90%|█████████ | 607/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 610/671 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 611/671 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████ | 612/671 [03:36<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 614/671 [03:37<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 615/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 617/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 618/671 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 619/671 [03:38<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 622/671 [03:38<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 623/671 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 624/671 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 626/671 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  93%|█████████▎| 627/671 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▎| 629/671 [03:39<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 630/671 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 631/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 632/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▍| 635/671 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▍| 636/671 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▌| 639/671 [03:41<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  95%|█████████▌| 640/671 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  96%|█████████▌| 641/671 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▌| 642/671 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▌| 643/671 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▌| 644/671 [03:42<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  96%|█████████▋| 647/671 [03:42<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 648/671 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 649/671 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 651/671 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 652/671 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 653/671 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  97%|█████████▋| 654/671 [03:43<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 655/671 [03:43<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 656/671 [03:44<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 657/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 659/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  98%|█████████▊| 660/671 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▊| 661/671 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 664/671 [03:45<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 665/671 [03:45<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 666/671 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18:  99%|█████████▉| 667/671 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18: 100%|█████████▉| 669/671 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18: 100%|█████████▉| 670/671 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0172, val_loss_epoch=0.0166, train_loss_epoch=0.016]\n",
      "Epoch 18: 100%|██████████| 671/671 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0172, val_loss_epoch=0.0167, train_loss_epoch=0.016]\n",
      "Epoch 19:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  89%|████████▉ | 598/671 [03:34<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  89%|████████▉ | 599/671 [03:34<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|████████▉ | 603/671 [03:35<00:24,  2.80it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 605/671 [03:35<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  90%|█████████ | 607/671 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 610/671 [03:36<00:21,  2.81it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 611/671 [03:36<00:21,  2.82it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  92%|█████████▏| 615/671 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 617/671 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 619/671 [03:38<00:18,  2.84it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 622/671 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 623/671 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 624/671 [03:39<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  93%|█████████▎| 627/671 [03:39<00:15,  2.86it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▎| 629/671 [03:39<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 631/671 [03:40<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 632/671 [03:40<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▍| 635/671 [03:40<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▍| 636/671 [03:41<00:12,  2.88it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  95%|█████████▌| 640/671 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 641/671 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 644/671 [03:42<00:09,  2.90it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  96%|█████████▋| 647/671 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 648/671 [03:43<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 649/671 [03:43<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 652/671 [03:43<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 653/671 [03:43<00:06,  2.92it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  97%|█████████▋| 654/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 657/671 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 659/671 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  98%|█████████▊| 660/671 [03:44<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▊| 661/671 [03:45<00:03,  2.94it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 665/671 [03:45<00:02,  2.95it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 666/671 [03:45<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|█████████▉| 670/671 [03:46<00:00,  2.96it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0154, val_loss_epoch=0.0167, train_loss_epoch=0.0159]\n",
      "Epoch 19: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0154, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  89%|████████▉ | 597/671 [03:34<00:26,  2.79it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  89%|████████▉ | 598/671 [03:34<00:26,  2.79it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  89%|████████▉ | 599/671 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  89%|████████▉ | 600/671 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|████████▉ | 602/671 [03:35<00:24,  2.80it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|████████▉ | 603/671 [03:35<00:24,  2.80it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|█████████ | 605/671 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|█████████ | 606/671 [03:35<00:23,  2.81it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  90%|█████████ | 607/671 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 610/671 [03:36<00:21,  2.82it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 611/671 [03:36<00:21,  2.82it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████ | 612/671 [03:36<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 614/671 [03:37<00:20,  2.83it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 615/671 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 617/671 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 618/671 [03:37<00:18,  2.84it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 619/671 [03:38<00:18,  2.84it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 622/671 [03:38<00:17,  2.85it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 623/671 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 624/671 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 626/671 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  93%|█████████▎| 627/671 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▎| 629/671 [03:39<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 630/671 [03:39<00:14,  2.87it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 631/671 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 632/671 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  94%|█████████▍| 634/671 [03:40<00:12,  2.88it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▍| 635/671 [03:40<00:12,  2.88it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▍| 636/671 [03:40<00:12,  2.88it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▌| 639/671 [03:41<00:11,  2.89it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  95%|█████████▌| 640/671 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 641/671 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 642/671 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 643/671 [03:41<00:09,  2.90it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 644/671 [03:42<00:09,  2.90it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  96%|█████████▋| 647/671 [03:42<00:08,  2.91it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 648/671 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 649/671 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 651/671 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 652/671 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 653/671 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  97%|█████████▋| 654/671 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 655/671 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 656/671 [03:44<00:05,  2.93it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 657/671 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 659/671 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  98%|█████████▊| 660/671 [03:44<00:03,  2.94it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▊| 661/671 [03:44<00:03,  2.94it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 664/671 [03:45<00:02,  2.95it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 665/671 [03:45<00:02,  2.95it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 666/671 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20:  99%|█████████▉| 667/671 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20: 100%|█████████▉| 669/671 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20: 100%|█████████▉| 670/671 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 20: 100%|██████████| 671/671 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.0162, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  89%|████████▉ | 598/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  89%|████████▉ | 599/671 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  90%|████████▉ | 603/671 [03:35<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  90%|█████████ | 607/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  91%|█████████ | 610/671 [03:36<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  91%|█████████ | 611/671 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  92%|█████████▏| 615/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  92%|█████████▏| 617/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  92%|█████████▏| 619/671 [03:38<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  93%|█████████▎| 622/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  93%|█████████▎| 623/671 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  93%|█████████▎| 624/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  94%|█████████▎| 629/671 [03:39<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  94%|█████████▍| 632/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  95%|█████████▍| 635/671 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  95%|█████████▍| 636/671 [03:41<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  95%|█████████▌| 640/671 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  96%|█████████▌| 641/671 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  96%|█████████▌| 644/671 [03:42<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  96%|█████████▋| 647/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  97%|█████████▋| 649/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  97%|█████████▋| 652/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  97%|█████████▋| 653/671 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  97%|█████████▋| 654/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  98%|█████████▊| 657/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  98%|█████████▊| 659/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  99%|█████████▉| 665/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  99%|█████████▉| 666/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21: 100%|█████████▉| 670/671 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 21: 100%|██████████| 671/671 [03:47<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0177, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 598/671 [03:34<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  89%|████████▉ | 599/671 [03:35<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  90%|████████▉ | 603/671 [03:35<00:24,  2.80it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  90%|█████████ | 607/671 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  91%|█████████ | 610/671 [03:36<00:21,  2.81it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  91%|█████████ | 611/671 [03:37<00:21,  2.82it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  92%|█████████▏| 615/671 [03:37<00:19,  2.82it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  93%|█████████▎| 622/671 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  93%|█████████▎| 624/671 [03:39<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  94%|█████████▎| 629/671 [03:40<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  94%|█████████▍| 632/671 [03:40<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  95%|█████████▍| 635/671 [03:40<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  95%|█████████▍| 636/671 [03:41<00:12,  2.88it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  95%|█████████▌| 640/671 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  96%|█████████▌| 641/671 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  96%|█████████▋| 647/671 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  97%|█████████▋| 649/671 [03:43<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  97%|█████████▋| 652/671 [03:43<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  97%|█████████▋| 653/671 [03:43<00:06,  2.92it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  97%|█████████▋| 654/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  98%|█████████▊| 659/671 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  99%|█████████▉| 665/671 [03:45<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  99%|█████████▉| 666/671 [03:46<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22: 100%|█████████▉| 670/671 [03:46<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0162, train_loss_step=0.0129, val_loss_epoch=0.0165, train_loss_epoch=0.0159]\n",
      "Epoch 22: 100%|██████████| 671/671 [03:47<00:00,  2.96it/s, loss=0.015, val_loss_step=0.0164, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 598/671 [03:35<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|████████▉ | 603/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 604/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 610/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 615/671 [03:37<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 616/671 [03:38<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  92%|█████████▏| 620/671 [03:38<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 622/671 [03:39<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 624/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▎| 628/671 [03:40<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▎| 629/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 632/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  95%|█████████▌| 640/671 [03:41<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 641/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 649/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 652/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  97%|█████████▋| 654/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▊| 662/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|█████████▉| 670/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 23: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0256, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 597/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 598/671 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 599/671 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  89%|████████▉ | 600/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|████████▉ | 601/671 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|████████▉ | 602/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|████████▉ | 603/671 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 604/671 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 605/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 606/671 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  90%|█████████ | 607/671 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 608/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 609/671 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 610/671 [03:36<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 611/671 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████ | 612/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  91%|█████████▏| 613/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 614/671 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 615/671 [03:37<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 616/671 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 617/671 [03:38<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 618/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 619/671 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  92%|█████████▏| 620/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 621/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 622/671 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 623/671 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 624/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 625/671 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 626/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  93%|█████████▎| 627/671 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▎| 628/671 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▎| 629/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 630/671 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 631/671 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  94%|█████████▍| 632/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 633/671 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  94%|█████████▍| 634/671 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▍| 635/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▍| 636/671 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▍| 637/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▌| 638/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▌| 639/671 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  95%|█████████▌| 640/671 [03:41<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 641/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 642/671 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 643/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 644/671 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▌| 645/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▋| 646/671 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  96%|█████████▋| 647/671 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 648/671 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 649/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 650/671 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 651/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 652/671 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 653/671 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  97%|█████████▋| 654/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 655/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 656/671 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 657/671 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 658/671 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 659/671 [03:45<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  98%|█████████▊| 660/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▊| 661/671 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▊| 662/671 [03:45<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 663/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 664/671 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 665/671 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 666/671 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24:  99%|█████████▉| 667/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|█████████▉| 668/671 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|█████████▉| 669/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|█████████▉| 670/671 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0164, train_loss_step=0.0192, val_loss_epoch=0.0166, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0166, train_loss_step=0.0192, val_loss_epoch=0.0168, train_loss_epoch=0.0159]\n",
      "Epoch 24: 100%|██████████| 671/671 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0166, train_loss_step=0.0192, val_loss_epoch=0.0168, train_loss_epoch=0.0159]\n",
      "Test iterations: 137\n",
      "Testing: 100%|██████████| 137/137 [00:20<00:00,  6.73it/s]Logits: tensor([[-6.2852, -6.7539, -6.7422,  ..., -6.0742, -6.2188, -6.0234],\n",
      "        [-7.9766, -9.2578, -8.4219,  ..., -7.2930, -8.4375, -6.9805],\n",
      "        [-7.2266, -7.2656, -6.4062,  ..., -6.0898, -6.0391, -5.6523],\n",
      "        ...,\n",
      "        [-6.2070, -6.4727, -6.8867,  ..., -6.4570, -6.1641, -6.6406],\n",
      "        [-6.1758, -6.6016, -6.6562,  ..., -6.0547, -6.0859, -6.0586],\n",
      "        [-6.3750, -6.4609, -6.5469,  ..., -6.2812, -5.9648, -6.2578]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[1.861e-03 1.165e-03 1.179e-03 ... 2.296e-03 1.987e-03 2.415e-03]\n",
      " [3.433e-04 9.537e-05 2.199e-04 ... 6.800e-04 2.166e-04 9.289e-04]\n",
      " [7.267e-04 6.986e-04 1.649e-03 ... 2.260e-03 2.378e-03 3.496e-03]\n",
      " ...\n",
      " [2.010e-03 1.543e-03 1.020e-03 ... 1.567e-03 2.100e-03 1.305e-03]\n",
      " [2.075e-03 1.356e-03 1.285e-03 ... 2.342e-03 2.270e-03 2.333e-03]\n",
      " [1.700e-03 1.561e-03 1.432e-03 ... 1.867e-03 2.562e-03 1.912e-03]]\n",
      "Testing: 100%|██████████| 137/137 [00:20<00:00,  6.58it/s]\n",
      "==================== Fold 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 11 M  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 75\n",
      "Train iterations: 595                                                 \n",
      "Epoch 0:  89%|████████▉ | 595/670 [03:35<00:27,  2.76it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 596/670 [03:35<00:26,  2.76it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  89%|████████▉ | 598/670 [03:36<00:26,  2.77it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  89%|████████▉ | 599/670 [03:36<00:25,  2.77it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  90%|████████▉ | 601/670 [03:36<00:24,  2.77it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  90%|████████▉ | 602/670 [03:36<00:24,  2.78it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  90%|█████████ | 603/670 [03:37<00:24,  2.78it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  90%|█████████ | 606/670 [03:37<00:22,  2.79it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  91%|█████████ | 607/670 [03:37<00:22,  2.79it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  91%|█████████ | 608/670 [03:37<00:22,  2.79it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  91%|█████████ | 610/670 [03:38<00:21,  2.80it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  91%|█████████ | 611/670 [03:38<00:21,  2.80it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  91%|█████████▏| 613/670 [03:38<00:20,  2.80it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  92%|█████████▏| 614/670 [03:38<00:19,  2.81it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  92%|█████████▏| 615/670 [03:39<00:19,  2.81it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  92%|█████████▏| 616/670 [03:39<00:19,  2.81it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  92%|█████████▏| 618/670 [03:39<00:18,  2.82it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  92%|█████████▏| 619/670 [03:39<00:18,  2.82it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  93%|█████████▎| 620/670 [03:39<00:17,  2.82it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  93%|█████████▎| 622/670 [03:40<00:16,  2.82it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  93%|█████████▎| 623/670 [03:40<00:16,  2.83it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  93%|█████████▎| 625/670 [03:40<00:15,  2.83it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  93%|█████████▎| 626/670 [03:40<00:15,  2.83it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  94%|█████████▎| 627/670 [03:41<00:15,  2.84it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  94%|█████████▎| 628/670 [03:41<00:14,  2.84it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  94%|█████████▍| 631/670 [03:41<00:13,  2.85it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  94%|█████████▍| 632/670 [03:41<00:13,  2.85it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  94%|█████████▍| 633/670 [03:42<00:12,  2.85it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  95%|█████████▍| 635/670 [03:42<00:12,  2.86it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  95%|█████████▍| 636/670 [03:42<00:11,  2.86it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  95%|█████████▌| 637/670 [03:42<00:11,  2.86it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  95%|█████████▌| 638/670 [03:42<00:11,  2.86it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  95%|█████████▌| 639/670 [03:43<00:10,  2.87it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  96%|█████████▌| 640/670 [03:43<00:10,  2.87it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  96%|█████████▌| 641/670 [03:43<00:10,  2.87it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  96%|█████████▌| 643/670 [03:43<00:09,  2.87it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  96%|█████████▌| 644/670 [03:43<00:09,  2.88it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  96%|█████████▋| 645/670 [03:44<00:08,  2.88it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  97%|█████████▋| 648/670 [03:44<00:07,  2.89it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  97%|█████████▋| 649/670 [03:44<00:07,  2.89it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  97%|█████████▋| 650/670 [03:44<00:06,  2.89it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  97%|█████████▋| 651/670 [03:44<00:06,  2.89it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  97%|█████████▋| 652/670 [03:45<00:06,  2.90it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  97%|█████████▋| 653/670 [03:45<00:05,  2.90it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  98%|█████████▊| 654/670 [03:45<00:05,  2.90it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  98%|█████████▊| 655/670 [03:45<00:05,  2.90it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  98%|█████████▊| 656/670 [03:45<00:04,  2.90it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  98%|█████████▊| 657/670 [03:45<00:04,  2.91it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  98%|█████████▊| 658/670 [03:46<00:04,  2.91it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  99%|█████████▊| 661/670 [03:46<00:03,  2.92it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  99%|█████████▉| 662/670 [03:46<00:02,  2.92it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  99%|█████████▉| 663/670 [03:46<00:02,  2.92it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|█████████▉| 665/670 [03:47<00:01,  2.93it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0:  99%|█████████▉| 666/670 [03:47<00:01,  2.93it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0: 100%|█████████▉| 667/670 [03:47<00:01,  2.93it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0: 100%|█████████▉| 668/670 [03:47<00:00,  2.93it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0: 100%|█████████▉| 669/670 [03:47<00:00,  2.93it/s, loss=0.021, val_loss_step=0.7, train_loss_step=0.0279]\n",
      "Epoch 0: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.021, val_loss_step=0.023, train_loss_step=0.0279, val_loss_epoch=0.0243]\n",
      "Epoch 1:  89%|████████▉ | 595/670 [03:35<00:27,  2.76it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  89%|████████▉ | 599/670 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  90%|████████▉ | 601/670 [03:36<00:24,  2.77it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  90%|█████████ | 603/670 [03:37<00:24,  2.78it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  90%|█████████ | 606/670 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  91%|█████████ | 607/670 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  91%|█████████ | 608/670 [03:38<00:22,  2.79it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  91%|█████████▏| 613/670 [03:38<00:20,  2.80it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  92%|█████████▏| 614/670 [03:39<00:19,  2.80it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  92%|█████████▏| 616/670 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  92%|█████████▏| 618/670 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  92%|█████████▏| 619/670 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  93%|█████████▎| 620/670 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  93%|█████████▎| 625/670 [03:40<00:15,  2.83it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  94%|█████████▎| 628/670 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  94%|█████████▍| 631/670 [03:41<00:13,  2.84it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  94%|█████████▍| 632/670 [03:42<00:13,  2.85it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  94%|█████████▍| 633/670 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  95%|█████████▍| 636/670 [03:42<00:11,  2.85it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  95%|█████████▌| 637/670 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  96%|█████████▌| 641/670 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  96%|█████████▌| 643/670 [03:43<00:09,  2.87it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  96%|█████████▋| 645/670 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  97%|█████████▋| 648/670 [03:44<00:07,  2.88it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  97%|█████████▋| 649/670 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  97%|█████████▋| 650/670 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  98%|█████████▊| 654/670 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  98%|█████████▊| 655/670 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  98%|█████████▊| 658/670 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  99%|█████████▊| 661/670 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  99%|█████████▉| 662/670 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  99%|█████████▉| 663/670 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1:  99%|█████████▉| 666/670 [03:47<00:01,  2.92it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1: 100%|█████████▉| 667/670 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1: 100%|█████████▉| 668/670 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.023, train_loss_step=0.0167, val_loss_epoch=0.0243, train_loss_epoch=0.0247]\n",
      "Epoch 1: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.101, train_loss_step=0.0167, val_loss_epoch=0.103, train_loss_epoch=0.0247] \n",
      "Epoch 2:  89%|████████▉ | 595/670 [03:35<00:27,  2.76it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 596/670 [03:36<00:26,  2.76it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  89%|████████▉ | 598/670 [03:36<00:26,  2.76it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  89%|████████▉ | 599/670 [03:36<00:25,  2.77it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  90%|████████▉ | 601/670 [03:36<00:24,  2.77it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  90%|████████▉ | 602/670 [03:37<00:24,  2.77it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  90%|█████████ | 603/670 [03:37<00:24,  2.78it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  90%|█████████ | 606/670 [03:37<00:22,  2.78it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  91%|█████████ | 607/670 [03:37<00:22,  2.79it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  91%|█████████ | 608/670 [03:38<00:22,  2.79it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  91%|█████████ | 610/670 [03:38<00:21,  2.79it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  91%|█████████ | 611/670 [03:38<00:21,  2.79it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  91%|█████████▏| 613/670 [03:38<00:20,  2.80it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  92%|█████████▏| 614/670 [03:39<00:19,  2.80it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  92%|█████████▏| 615/670 [03:39<00:19,  2.80it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  92%|█████████▏| 616/670 [03:39<00:19,  2.81it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  92%|█████████▏| 618/670 [03:39<00:18,  2.81it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  92%|█████████▏| 619/670 [03:39<00:18,  2.81it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  93%|█████████▎| 620/670 [03:40<00:17,  2.82it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  93%|█████████▎| 622/670 [03:40<00:17,  2.82it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  93%|█████████▎| 623/670 [03:40<00:16,  2.82it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  93%|█████████▎| 625/670 [03:40<00:15,  2.83it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  93%|█████████▎| 626/670 [03:41<00:15,  2.83it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  94%|█████████▎| 627/670 [03:41<00:15,  2.83it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  94%|█████████▎| 628/670 [03:41<00:14,  2.84it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  94%|█████████▍| 631/670 [03:41<00:13,  2.84it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  94%|█████████▍| 632/670 [03:42<00:13,  2.85it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  94%|█████████▍| 633/670 [03:42<00:12,  2.85it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  95%|█████████▍| 635/670 [03:42<00:12,  2.85it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  95%|█████████▍| 636/670 [03:42<00:11,  2.86it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  95%|█████████▌| 637/670 [03:42<00:11,  2.86it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  95%|█████████▌| 638/670 [03:43<00:11,  2.86it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  95%|█████████▌| 639/670 [03:43<00:10,  2.86it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  96%|█████████▌| 640/670 [03:43<00:10,  2.86it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  96%|█████████▌| 641/670 [03:43<00:10,  2.87it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  96%|█████████▌| 643/670 [03:43<00:09,  2.87it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  96%|█████████▌| 644/670 [03:44<00:09,  2.87it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  96%|█████████▋| 645/670 [03:44<00:08,  2.88it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  97%|█████████▋| 648/670 [03:44<00:07,  2.88it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  97%|█████████▋| 649/670 [03:44<00:07,  2.89it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  97%|█████████▋| 650/670 [03:45<00:06,  2.89it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  97%|█████████▋| 652/670 [03:45<00:06,  2.89it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  97%|█████████▋| 653/670 [03:45<00:05,  2.89it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  98%|█████████▊| 654/670 [03:45<00:05,  2.90it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  98%|█████████▊| 655/670 [03:45<00:05,  2.90it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  98%|█████████▊| 656/670 [03:46<00:04,  2.90it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  98%|█████████▊| 657/670 [03:46<00:04,  2.90it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  98%|█████████▊| 658/670 [03:46<00:04,  2.91it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  99%|█████████▊| 661/670 [03:46<00:03,  2.91it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  99%|█████████▉| 662/670 [03:47<00:02,  2.92it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  99%|█████████▉| 663/670 [03:47<00:02,  2.92it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  99%|█████████▉| 665/670 [03:47<00:01,  2.92it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2:  99%|█████████▉| 666/670 [03:47<00:01,  2.92it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2: 100%|█████████▉| 667/670 [03:47<00:01,  2.93it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2: 100%|█████████▉| 668/670 [03:48<00:00,  2.93it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2: 100%|█████████▉| 669/670 [03:48<00:00,  2.93it/s, loss=0.019, val_loss_step=0.101, train_loss_step=0.0192, val_loss_epoch=0.103, train_loss_epoch=0.0196]\n",
      "Epoch 2: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0192, val_loss_epoch=0.0197, train_loss_epoch=0.0196]\n",
      "Epoch 3:  89%|████████▉ | 595/670 [03:35<00:27,  2.76it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 596/670 [03:35<00:26,  2.76it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  89%|████████▉ | 597/670 [03:35<00:26,  2.77it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  89%|████████▉ | 598/670 [03:35<00:25,  2.77it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  89%|████████▉ | 599/670 [03:36<00:25,  2.77it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  90%|████████▉ | 601/670 [03:36<00:24,  2.78it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  90%|████████▉ | 602/670 [03:36<00:24,  2.78it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  90%|█████████ | 603/670 [03:36<00:24,  2.78it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  90%|█████████ | 604/670 [03:36<00:23,  2.78it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  90%|█████████ | 605/670 [03:37<00:23,  2.79it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  90%|█████████ | 606/670 [03:37<00:22,  2.79it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  91%|█████████ | 607/670 [03:37<00:22,  2.79it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  91%|█████████ | 608/670 [03:37<00:22,  2.79it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  91%|█████████ | 609/670 [03:37<00:21,  2.80it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  91%|█████████ | 610/670 [03:37<00:21,  2.80it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  91%|█████████ | 611/670 [03:38<00:21,  2.80it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  91%|█████████▏| 613/670 [03:38<00:20,  2.81it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  92%|█████████▏| 614/670 [03:38<00:19,  2.81it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  92%|█████████▏| 615/670 [03:38<00:19,  2.81it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  92%|█████████▏| 616/670 [03:38<00:19,  2.81it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  92%|█████████▏| 617/670 [03:39<00:18,  2.82it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  92%|█████████▏| 618/670 [03:39<00:18,  2.82it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  92%|█████████▏| 619/670 [03:39<00:18,  2.82it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  93%|█████████▎| 620/670 [03:39<00:17,  2.82it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  93%|█████████▎| 621/670 [03:39<00:17,  2.83it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  93%|█████████▎| 622/670 [03:39<00:16,  2.83it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  93%|█████████▎| 623/670 [03:40<00:16,  2.83it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  93%|█████████▎| 625/670 [03:40<00:15,  2.84it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  93%|█████████▎| 626/670 [03:40<00:15,  2.84it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  94%|█████████▎| 627/670 [03:40<00:15,  2.84it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  94%|█████████▎| 628/670 [03:40<00:14,  2.84it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  94%|█████████▍| 630/670 [03:41<00:14,  2.85it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  94%|█████████▍| 631/670 [03:41<00:13,  2.85it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  94%|█████████▍| 632/670 [03:41<00:13,  2.85it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  94%|█████████▍| 633/670 [03:41<00:12,  2.85it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  95%|█████████▍| 634/670 [03:41<00:12,  2.86it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  95%|█████████▍| 635/670 [03:42<00:12,  2.86it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  95%|█████████▍| 636/670 [03:42<00:11,  2.86it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  95%|█████████▌| 637/670 [03:42<00:11,  2.86it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  95%|█████████▌| 638/670 [03:42<00:11,  2.87it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  95%|█████████▌| 639/670 [03:42<00:10,  2.87it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  96%|█████████▌| 640/670 [03:42<00:10,  2.87it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  96%|█████████▌| 641/670 [03:43<00:10,  2.87it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  96%|█████████▌| 642/670 [03:43<00:09,  2.88it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  96%|█████████▌| 643/670 [03:43<00:09,  2.88it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  96%|█████████▌| 644/670 [03:43<00:09,  2.88it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  96%|█████████▋| 645/670 [03:43<00:08,  2.88it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  96%|█████████▋| 646/670 [03:43<00:08,  2.89it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  97%|█████████▋| 647/670 [03:44<00:07,  2.89it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  97%|█████████▋| 648/670 [03:44<00:07,  2.89it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  97%|█████████▋| 649/670 [03:44<00:07,  2.89it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  97%|█████████▋| 650/670 [03:44<00:06,  2.89it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  97%|█████████▋| 651/670 [03:44<00:06,  2.90it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  97%|█████████▋| 652/670 [03:44<00:06,  2.90it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  97%|█████████▋| 653/670 [03:45<00:05,  2.90it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  98%|█████████▊| 654/670 [03:45<00:05,  2.90it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  98%|█████████▊| 655/670 [03:45<00:05,  2.91it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  98%|█████████▊| 656/670 [03:45<00:04,  2.91it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  98%|█████████▊| 657/670 [03:45<00:04,  2.91it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  98%|█████████▊| 658/670 [03:45<00:04,  2.91it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  98%|█████████▊| 659/670 [03:46<00:03,  2.92it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  99%|█████████▊| 660/670 [03:46<00:03,  2.92it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  99%|█████████▊| 661/670 [03:46<00:03,  2.92it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  99%|█████████▉| 662/670 [03:46<00:02,  2.92it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  99%|█████████▉| 663/670 [03:46<00:02,  2.92it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  99%|█████████▉| 664/670 [03:46<00:02,  2.93it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  99%|█████████▉| 665/670 [03:47<00:01,  2.93it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3:  99%|█████████▉| 666/670 [03:47<00:01,  2.93it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3: 100%|█████████▉| 667/670 [03:47<00:01,  2.93it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3: 100%|█████████▉| 668/670 [03:47<00:00,  2.94it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3: 100%|█████████▉| 669/670 [03:47<00:00,  2.94it/s, loss=0.019, val_loss_step=0.018, train_loss_step=0.0155, val_loss_epoch=0.0197, train_loss_epoch=0.0191]\n",
      "Epoch 3: 100%|██████████| 670/670 [03:48<00:00,  2.94it/s, loss=0.019, val_loss_step=0.0185, train_loss_step=0.0155, val_loss_epoch=0.0224, train_loss_epoch=0.0191]\n",
      "Epoch 4:  89%|████████▉ | 595/670 [03:35<00:27,  2.76it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 596/670 [03:35<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  89%|████████▉ | 597/670 [03:36<00:26,  2.76it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  89%|████████▉ | 598/670 [03:36<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  89%|████████▉ | 599/670 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  90%|████████▉ | 600/670 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  90%|████████▉ | 601/670 [03:36<00:24,  2.77it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  90%|████████▉ | 602/670 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  90%|█████████ | 603/670 [03:37<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  90%|█████████ | 604/670 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  90%|█████████ | 605/670 [03:37<00:23,  2.78it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  90%|█████████ | 606/670 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  91%|█████████ | 607/670 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  91%|█████████ | 608/670 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  91%|█████████ | 609/670 [03:38<00:21,  2.79it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  91%|█████████ | 610/670 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  91%|█████████ | 611/670 [03:38<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  91%|█████████▏| 612/670 [03:38<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  91%|█████████▏| 613/670 [03:38<00:20,  2.80it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  92%|█████████▏| 614/670 [03:38<00:19,  2.80it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  92%|█████████▏| 615/670 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  92%|█████████▏| 616/670 [03:39<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  92%|█████████▏| 617/670 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  92%|█████████▏| 618/670 [03:39<00:18,  2.81it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  92%|█████████▏| 619/670 [03:39<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  93%|█████████▎| 620/670 [03:39<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  93%|█████████▎| 621/670 [03:40<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  93%|█████████▎| 622/670 [03:40<00:16,  2.82it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  93%|█████████▎| 623/670 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  93%|█████████▎| 625/670 [03:40<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  93%|█████████▎| 626/670 [03:40<00:15,  2.83it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  94%|█████████▎| 627/670 [03:41<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  94%|█████████▎| 628/670 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  94%|█████████▍| 629/670 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  94%|█████████▍| 630/670 [03:41<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  94%|█████████▍| 631/670 [03:41<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  94%|█████████▍| 632/670 [03:41<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  94%|█████████▍| 633/670 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  95%|█████████▍| 634/670 [03:42<00:12,  2.85it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  95%|█████████▍| 635/670 [03:42<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  95%|█████████▍| 636/670 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  95%|█████████▌| 637/670 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  95%|█████████▌| 638/670 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  95%|█████████▌| 639/670 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  96%|█████████▌| 640/670 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  96%|█████████▌| 641/670 [03:43<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  96%|█████████▌| 642/670 [03:43<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  96%|█████████▌| 643/670 [03:43<00:09,  2.87it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  96%|█████████▌| 644/670 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  96%|█████████▋| 645/670 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  96%|█████████▋| 646/670 [03:44<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  97%|█████████▋| 647/670 [03:44<00:07,  2.88it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  97%|█████████▋| 648/670 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  97%|█████████▋| 649/670 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  97%|█████████▋| 650/670 [03:44<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  97%|█████████▋| 651/670 [03:45<00:06,  2.89it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  97%|█████████▋| 652/670 [03:45<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  97%|█████████▋| 653/670 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  98%|█████████▊| 654/670 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  98%|█████████▊| 655/670 [03:45<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  98%|█████████▊| 656/670 [03:45<00:04,  2.90it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  98%|█████████▊| 657/670 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  98%|█████████▊| 658/670 [03:46<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  98%|█████████▊| 659/670 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  99%|█████████▊| 660/670 [03:46<00:03,  2.91it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  99%|█████████▊| 661/670 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  99%|█████████▉| 662/670 [03:46<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  99%|█████████▉| 663/670 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  99%|█████████▉| 664/670 [03:47<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  99%|█████████▉| 665/670 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4:  99%|█████████▉| 666/670 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4: 100%|█████████▉| 667/670 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4: 100%|█████████▉| 668/670 [03:47<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4: 100%|█████████▉| 669/670 [03:47<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0185, train_loss_step=0.0146, val_loss_epoch=0.0224, train_loss_epoch=0.0187]\n",
      "Epoch 4: 100%|██████████| 670/670 [03:48<00:00,  2.93it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0146, val_loss_epoch=0.0202, train_loss_epoch=0.0187]\n",
      "Epoch 5:  89%|████████▉ | 595/670 [03:35<00:27,  2.77it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 596/670 [03:35<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 597/670 [03:35<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 598/670 [03:35<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  89%|████████▉ | 599/670 [03:36<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|████████▉ | 600/670 [03:36<00:25,  2.78it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|████████▉ | 601/670 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|████████▉ | 602/670 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 603/670 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 604/670 [03:36<00:23,  2.79it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 605/670 [03:36<00:23,  2.79it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  90%|█████████ | 606/670 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 607/670 [03:37<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 608/670 [03:37<00:22,  2.80it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 609/670 [03:37<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 610/670 [03:37<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████ | 611/670 [03:37<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████▏| 612/670 [03:38<00:20,  2.81it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  91%|█████████▏| 613/670 [03:38<00:20,  2.81it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 614/670 [03:38<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 615/670 [03:38<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 616/670 [03:38<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 617/670 [03:38<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 618/670 [03:39<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  92%|█████████▏| 619/670 [03:39<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 620/670 [03:39<00:17,  2.82it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 621/670 [03:39<00:17,  2.83it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 622/670 [03:39<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 623/670 [03:39<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 624/670 [03:40<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 625/670 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  93%|█████████▎| 626/670 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▎| 627/670 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▎| 628/670 [03:40<00:14,  2.84it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 629/670 [03:40<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 630/670 [03:41<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  94%|█████████▍| 631/670 [03:41<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 632/670 [03:41<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  94%|█████████▍| 633/670 [03:41<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▍| 634/670 [03:41<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▍| 635/670 [03:41<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▍| 636/670 [03:42<00:11,  2.86it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▌| 637/670 [03:42<00:11,  2.87it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▌| 638/670 [03:42<00:11,  2.87it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  95%|█████████▌| 639/670 [03:42<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 640/670 [03:42<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 641/670 [03:42<00:10,  2.88it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 642/670 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 643/670 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▌| 644/670 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▋| 645/670 [03:43<00:08,  2.88it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  96%|█████████▋| 646/670 [03:43<00:08,  2.89it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 647/670 [03:43<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 648/670 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 649/670 [03:44<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 650/670 [03:44<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 651/670 [03:44<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 652/670 [03:44<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  97%|█████████▋| 653/670 [03:44<00:05,  2.90it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 654/670 [03:45<00:05,  2.91it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 655/670 [03:45<00:05,  2.91it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 656/670 [03:45<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 657/670 [03:45<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 658/670 [03:45<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  98%|█████████▊| 659/670 [03:45<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▊| 660/670 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▊| 661/670 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 662/670 [03:46<00:02,  2.92it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 663/670 [03:46<00:02,  2.93it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 664/670 [03:46<00:02,  2.93it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 665/670 [03:46<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5:  99%|█████████▉| 666/670 [03:47<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|█████████▉| 667/670 [03:47<00:01,  2.94it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|█████████▉| 668/670 [03:47<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|█████████▉| 669/670 [03:47<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0175, val_loss_epoch=0.0202, train_loss_epoch=0.0183]\n",
      "Epoch 5: 100%|██████████| 670/670 [03:48<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0175, val_loss_epoch=0.0195, train_loss_epoch=0.0183]\n",
      "Epoch 6:  89%|████████▉ | 595/670 [03:34<00:27,  2.77it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 596/670 [03:35<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  89%|████████▉ | 597/670 [03:35<00:26,  2.77it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  89%|████████▉ | 598/670 [03:35<00:25,  2.77it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  89%|████████▉ | 599/670 [03:35<00:25,  2.78it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  90%|████████▉ | 600/670 [03:35<00:25,  2.78it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  90%|████████▉ | 601/670 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  90%|████████▉ | 602/670 [03:36<00:24,  2.78it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  90%|█████████ | 603/670 [03:36<00:24,  2.79it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  90%|█████████ | 604/670 [03:36<00:23,  2.79it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  90%|█████████ | 605/670 [03:36<00:23,  2.79it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  90%|█████████ | 606/670 [03:36<00:22,  2.79it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  91%|█████████ | 607/670 [03:37<00:22,  2.80it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  91%|█████████ | 608/670 [03:37<00:22,  2.80it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  91%|█████████ | 609/670 [03:37<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  91%|█████████ | 610/670 [03:37<00:21,  2.80it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  91%|█████████ | 611/670 [03:37<00:21,  2.81it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  91%|█████████▏| 612/670 [03:37<00:20,  2.81it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  91%|█████████▏| 613/670 [03:38<00:20,  2.81it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  92%|█████████▏| 614/670 [03:38<00:19,  2.81it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  92%|█████████▏| 615/670 [03:38<00:19,  2.82it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  92%|█████████▏| 616/670 [03:38<00:19,  2.82it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  92%|█████████▏| 617/670 [03:38<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  92%|█████████▏| 618/670 [03:38<00:18,  2.82it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  92%|█████████▏| 619/670 [03:39<00:18,  2.83it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  93%|█████████▎| 620/670 [03:39<00:17,  2.83it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  93%|█████████▎| 621/670 [03:39<00:17,  2.83it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  93%|█████████▎| 622/670 [03:39<00:16,  2.83it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  93%|█████████▎| 623/670 [03:39<00:16,  2.84it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  93%|█████████▎| 624/670 [03:39<00:16,  2.84it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  93%|█████████▎| 625/670 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  93%|█████████▎| 626/670 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  94%|█████████▎| 627/670 [03:40<00:15,  2.84it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  94%|█████████▎| 628/670 [03:40<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  94%|█████████▍| 629/670 [03:40<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  94%|█████████▍| 630/670 [03:40<00:14,  2.85it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  94%|█████████▍| 631/670 [03:41<00:13,  2.85it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  94%|█████████▍| 632/670 [03:41<00:13,  2.86it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  94%|█████████▍| 633/670 [03:41<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  95%|█████████▍| 634/670 [03:41<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  95%|█████████▍| 635/670 [03:41<00:12,  2.86it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  95%|█████████▍| 636/670 [03:41<00:11,  2.87it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  95%|█████████▌| 637/670 [03:42<00:11,  2.87it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  95%|█████████▌| 638/670 [03:42<00:11,  2.87it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  95%|█████████▌| 639/670 [03:42<00:10,  2.87it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  96%|█████████▌| 640/670 [03:42<00:10,  2.88it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  96%|█████████▌| 641/670 [03:42<00:10,  2.88it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  96%|█████████▌| 642/670 [03:42<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  96%|█████████▌| 643/670 [03:43<00:09,  2.88it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  96%|█████████▌| 644/670 [03:43<00:09,  2.89it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  96%|█████████▋| 645/670 [03:43<00:08,  2.89it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  96%|█████████▋| 646/670 [03:43<00:08,  2.89it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  97%|█████████▋| 647/670 [03:43<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  97%|█████████▋| 648/670 [03:43<00:07,  2.89it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  97%|█████████▋| 649/670 [03:44<00:07,  2.90it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  97%|█████████▋| 650/670 [03:44<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  97%|█████████▋| 651/670 [03:44<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  97%|█████████▋| 652/670 [03:44<00:06,  2.90it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  97%|█████████▋| 653/670 [03:44<00:05,  2.91it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  98%|█████████▊| 654/670 [03:44<00:05,  2.91it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  98%|█████████▊| 655/670 [03:45<00:05,  2.91it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  98%|█████████▊| 656/670 [03:45<00:04,  2.91it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  98%|█████████▊| 657/670 [03:45<00:04,  2.92it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  98%|█████████▊| 658/670 [03:45<00:04,  2.92it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  98%|█████████▊| 659/670 [03:45<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  99%|█████████▊| 660/670 [03:45<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  99%|█████████▊| 661/670 [03:46<00:03,  2.92it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  99%|█████████▉| 662/670 [03:46<00:02,  2.93it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  99%|█████████▉| 663/670 [03:46<00:02,  2.93it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  99%|█████████▉| 664/670 [03:46<00:02,  2.93it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  99%|█████████▉| 665/670 [03:46<00:01,  2.93it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6:  99%|█████████▉| 666/670 [03:46<00:01,  2.94it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6: 100%|█████████▉| 667/670 [03:46<00:01,  2.94it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6: 100%|█████████▉| 668/670 [03:47<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6: 100%|█████████▉| 669/670 [03:47<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0178, train_loss_step=0.0212, val_loss_epoch=0.0195, train_loss_epoch=0.0179]\n",
      "Epoch 6: 100%|██████████| 670/670 [03:47<00:00,  2.94it/s, loss=0.018, val_loss_step=0.0197, train_loss_step=0.0212, val_loss_epoch=0.0203, train_loss_epoch=0.0179]\n",
      "Epoch 7:  89%|████████▉ | 595/670 [03:34<00:27,  2.77it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 596/670 [03:34<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  89%|████████▉ | 597/670 [03:35<00:26,  2.77it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  89%|████████▉ | 598/670 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  89%|████████▉ | 599/670 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|████████▉ | 600/670 [03:35<00:25,  2.78it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|████████▉ | 601/670 [03:35<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|████████▉ | 602/670 [03:35<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|█████████ | 603/670 [03:36<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|█████████ | 604/670 [03:36<00:23,  2.79it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|█████████ | 605/670 [03:36<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  90%|█████████ | 606/670 [03:36<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 607/670 [03:36<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 608/670 [03:36<00:22,  2.80it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 609/670 [03:37<00:21,  2.80it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 610/670 [03:37<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████ | 611/670 [03:37<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████▏| 612/670 [03:37<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  91%|█████████▏| 613/670 [03:37<00:20,  2.81it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 614/670 [03:37<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 615/670 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 616/670 [03:38<00:19,  2.82it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 617/670 [03:38<00:18,  2.82it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 618/670 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  92%|█████████▏| 619/670 [03:38<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 620/670 [03:38<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 621/670 [03:39<00:17,  2.83it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 622/670 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 623/670 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 624/670 [03:39<00:16,  2.84it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  93%|█████████▎| 625/670 [03:39<00:15,  2.84it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  93%|█████████▎| 626/670 [03:39<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▎| 627/670 [03:40<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▎| 628/670 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 629/670 [03:40<00:14,  2.85it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 630/670 [03:40<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 631/670 [03:40<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 632/670 [03:40<00:13,  2.86it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  94%|█████████▍| 633/670 [03:41<00:12,  2.86it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▍| 634/670 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▍| 635/670 [03:41<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▍| 636/670 [03:41<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▌| 637/670 [03:41<00:11,  2.87it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▌| 638/670 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  95%|█████████▌| 639/670 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 640/670 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 641/670 [03:42<00:10,  2.88it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 642/670 [03:42<00:09,  2.88it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 643/670 [03:42<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▌| 644/670 [03:42<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▋| 645/670 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  96%|█████████▋| 646/670 [03:43<00:08,  2.89it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 647/670 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 648/670 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 649/670 [03:43<00:07,  2.90it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 650/670 [03:43<00:06,  2.90it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 651/670 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 652/670 [03:44<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  97%|█████████▋| 653/670 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 654/670 [03:44<00:05,  2.91it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 655/670 [03:44<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 656/670 [03:44<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 657/670 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 658/670 [03:45<00:04,  2.92it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  98%|█████████▊| 659/670 [03:45<00:03,  2.92it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▊| 660/670 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▊| 661/670 [03:45<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 662/670 [03:45<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 663/670 [03:46<00:02,  2.93it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 664/670 [03:46<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 665/670 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7:  99%|█████████▉| 666/670 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7: 100%|█████████▉| 667/670 [03:46<00:01,  2.94it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7: 100%|█████████▉| 668/670 [03:46<00:00,  2.94it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7: 100%|█████████▉| 669/670 [03:46<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0197, train_loss_step=0.0169, val_loss_epoch=0.0203, train_loss_epoch=0.0176]\n",
      "Epoch 7: 100%|██████████| 670/670 [03:47<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0195, train_loss_step=0.0169, val_loss_epoch=0.0215, train_loss_epoch=0.0176]\n",
      "Epoch 8:  89%|████████▉ | 595/670 [03:34<00:27,  2.77it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 596/670 [03:34<00:26,  2.77it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  89%|████████▉ | 597/670 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  89%|████████▉ | 598/670 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  89%|████████▉ | 599/670 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  90%|████████▉ | 600/670 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  90%|████████▉ | 601/670 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  90%|████████▉ | 602/670 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  90%|█████████ | 603/670 [03:35<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  90%|█████████ | 604/670 [03:36<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  90%|█████████ | 605/670 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  90%|█████████ | 606/670 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  91%|█████████ | 607/670 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  91%|█████████ | 608/670 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  91%|█████████ | 609/670 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  91%|█████████ | 610/670 [03:37<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  91%|█████████ | 611/670 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  91%|█████████▏| 612/670 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  91%|█████████▏| 613/670 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  92%|█████████▏| 614/670 [03:37<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  92%|█████████▏| 615/670 [03:37<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  92%|█████████▏| 616/670 [03:38<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  92%|█████████▏| 617/670 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  92%|█████████▏| 618/670 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  92%|█████████▏| 619/670 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  93%|█████████▎| 620/670 [03:38<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  93%|█████████▎| 621/670 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  93%|█████████▎| 622/670 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  93%|█████████▎| 623/670 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  93%|█████████▎| 624/670 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  93%|█████████▎| 625/670 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  93%|█████████▎| 626/670 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  94%|█████████▎| 627/670 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  94%|█████████▎| 628/670 [03:40<00:14,  2.85it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  94%|█████████▍| 629/670 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  94%|█████████▍| 630/670 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  94%|█████████▍| 631/670 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  94%|█████████▍| 632/670 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  94%|█████████▍| 633/670 [03:40<00:12,  2.86it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  95%|█████████▍| 634/670 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  95%|█████████▍| 635/670 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  95%|█████████▍| 636/670 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  95%|█████████▌| 637/670 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  95%|█████████▌| 638/670 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  95%|█████████▌| 639/670 [03:41<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  96%|█████████▌| 640/670 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  96%|█████████▌| 641/670 [03:42<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  96%|█████████▌| 642/670 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  96%|█████████▌| 643/670 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  96%|█████████▌| 644/670 [03:42<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  96%|█████████▋| 645/670 [03:42<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  96%|█████████▋| 646/670 [03:43<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  97%|█████████▋| 647/670 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  97%|█████████▋| 648/670 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  97%|█████████▋| 649/670 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  97%|█████████▋| 650/670 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  97%|█████████▋| 651/670 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  97%|█████████▋| 652/670 [03:44<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  97%|█████████▋| 653/670 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  98%|█████████▊| 654/670 [03:44<00:05,  2.91it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  98%|█████████▊| 655/670 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  98%|█████████▊| 656/670 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  98%|█████████▊| 657/670 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  98%|█████████▊| 658/670 [03:45<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  98%|█████████▊| 659/670 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  99%|█████████▊| 660/670 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  99%|█████████▊| 661/670 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  99%|█████████▉| 662/670 [03:45<00:02,  2.93it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  99%|█████████▉| 663/670 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  99%|█████████▉| 664/670 [03:46<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  99%|█████████▉| 665/670 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8:  99%|█████████▉| 666/670 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8: 100%|█████████▉| 667/670 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8: 100%|█████████▉| 668/670 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8: 100%|█████████▉| 669/670 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0182, val_loss_epoch=0.0215, train_loss_epoch=0.0172]\n",
      "Epoch 8: 100%|██████████| 670/670 [03:47<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0212, train_loss_step=0.0182, val_loss_epoch=0.0208, train_loss_epoch=0.0172]\n",
      "Epoch 9:  89%|████████▉ | 595/670 [03:34<00:26,  2.78it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 596/670 [03:34<00:26,  2.78it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  89%|████████▉ | 597/670 [03:34<00:26,  2.78it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  89%|████████▉ | 598/670 [03:34<00:25,  2.78it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  90%|████████▉ | 600/670 [03:35<00:25,  2.79it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  90%|████████▉ | 601/670 [03:35<00:24,  2.79it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  90%|████████▉ | 602/670 [03:35<00:24,  2.79it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  90%|█████████ | 604/670 [03:35<00:23,  2.80it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  90%|█████████ | 605/670 [03:35<00:23,  2.80it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  90%|█████████ | 606/670 [03:36<00:22,  2.80it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  91%|█████████ | 607/670 [03:36<00:22,  2.81it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  91%|█████████ | 608/670 [03:36<00:22,  2.81it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  91%|█████████ | 609/670 [03:36<00:21,  2.81it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  91%|█████████ | 610/670 [03:36<00:21,  2.81it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  91%|█████████▏| 612/670 [03:37<00:20,  2.82it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  91%|█████████▏| 613/670 [03:37<00:20,  2.82it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  92%|█████████▏| 614/670 [03:37<00:19,  2.82it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  92%|█████████▏| 616/670 [03:37<00:19,  2.83it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  92%|█████████▏| 617/670 [03:37<00:18,  2.83it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  92%|█████████▏| 618/670 [03:38<00:18,  2.83it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  92%|█████████▏| 619/670 [03:38<00:17,  2.84it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  93%|█████████▎| 620/670 [03:38<00:17,  2.84it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  93%|█████████▎| 621/670 [03:38<00:17,  2.84it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  93%|█████████▎| 622/670 [03:38<00:16,  2.84it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  93%|█████████▎| 624/670 [03:39<00:16,  2.85it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  93%|█████████▎| 625/670 [03:39<00:15,  2.85it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  93%|█████████▎| 626/670 [03:39<00:15,  2.85it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  94%|█████████▍| 629/670 [03:39<00:14,  2.86it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  94%|█████████▍| 630/670 [03:40<00:13,  2.86it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  94%|█████████▍| 631/670 [03:40<00:13,  2.87it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  94%|█████████▍| 632/670 [03:40<00:13,  2.87it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  94%|█████████▍| 633/670 [03:40<00:12,  2.87it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  95%|█████████▍| 634/670 [03:40<00:12,  2.87it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  95%|█████████▍| 636/670 [03:41<00:11,  2.88it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  95%|█████████▌| 637/670 [03:41<00:11,  2.88it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  95%|█████████▌| 638/670 [03:41<00:11,  2.88it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  95%|█████████▌| 639/670 [03:41<00:10,  2.88it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  96%|█████████▌| 641/670 [03:41<00:10,  2.89it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  96%|█████████▌| 642/670 [03:42<00:09,  2.89it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  96%|█████████▌| 643/670 [03:42<00:09,  2.89it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  96%|█████████▌| 644/670 [03:42<00:08,  2.90it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  96%|█████████▋| 646/670 [03:42<00:08,  2.90it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  97%|█████████▋| 647/670 [03:42<00:07,  2.90it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  97%|█████████▋| 649/670 [03:43<00:07,  2.91it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  97%|█████████▋| 650/670 [03:43<00:06,  2.91it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  97%|█████████▋| 651/670 [03:43<00:06,  2.91it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  98%|█████████▊| 654/670 [03:43<00:05,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  98%|█████████▊| 655/670 [03:44<00:05,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  98%|█████████▊| 656/670 [03:44<00:04,  2.92it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  98%|█████████▊| 658/670 [03:44<00:04,  2.93it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  98%|█████████▊| 659/670 [03:44<00:03,  2.93it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  99%|█████████▊| 660/670 [03:44<00:03,  2.93it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  99%|█████████▊| 661/670 [03:45<00:03,  2.94it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  99%|█████████▉| 662/670 [03:45<00:02,  2.94it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  99%|█████████▉| 663/670 [03:45<00:02,  2.94it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  99%|█████████▉| 664/670 [03:45<00:02,  2.94it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9: 100%|█████████▉| 667/670 [03:46<00:01,  2.95it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9: 100%|█████████▉| 668/670 [03:46<00:00,  2.95it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n",
      "Epoch 9: 100%|█████████▉| 669/670 [03:46<00:00,  2.95it/s, loss=0.018, val_loss_step=0.0212, train_loss_step=0.0166, val_loss_epoch=0.0208, train_loss_epoch=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 670/670 [03:46<00:00,  2.95it/s, loss=0.018, val_loss_step=0.0239, train_loss_step=0.0166, val_loss_epoch=0.0217, train_loss_epoch=0.017]\n",
      "Epoch 10:  89%|████████▉ | 595/670 [03:33<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 596/670 [03:34<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  89%|████████▉ | 597/670 [03:34<00:26,  2.79it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  90%|████████▉ | 600/670 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  90%|████████▉ | 602/670 [03:35<00:24,  2.80it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  90%|█████████ | 604/670 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  91%|█████████ | 607/670 [03:35<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  91%|█████████ | 608/670 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  91%|█████████ | 609/670 [03:36<00:21,  2.82it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  91%|█████████▏| 612/670 [03:36<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  92%|█████████▏| 614/670 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  92%|█████████▏| 616/670 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  92%|█████████▏| 619/670 [03:37<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  93%|█████████▎| 620/670 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  93%|█████████▎| 621/670 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  93%|█████████▎| 624/670 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  93%|█████████▎| 625/670 [03:38<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  93%|█████████▎| 626/670 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  94%|█████████▍| 629/670 [03:39<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  94%|█████████▍| 632/670 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  94%|█████████▍| 633/670 [03:40<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  95%|█████████▍| 636/670 [03:40<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  95%|█████████▌| 637/670 [03:40<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  95%|█████████▌| 638/670 [03:41<00:11,  2.89it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  95%|█████████▌| 639/670 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  96%|█████████▌| 641/670 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  96%|█████████▌| 644/670 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  96%|█████████▋| 646/670 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  97%|█████████▋| 649/670 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  97%|█████████▋| 650/670 [03:43<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  97%|█████████▋| 651/670 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  98%|█████████▊| 654/670 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  98%|█████████▊| 656/670 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  98%|█████████▊| 658/670 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  98%|█████████▊| 659/670 [03:44<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  99%|█████████▉| 662/670 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  99%|█████████▉| 663/670 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  99%|█████████▉| 664/670 [03:45<00:02,  2.95it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10: 100%|█████████▉| 667/670 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10: 100%|█████████▉| 668/670 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10: 100%|█████████▉| 669/670 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.0239, train_loss_step=0.0233, val_loss_epoch=0.0217, train_loss_epoch=0.0168]\n",
      "Epoch 10: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.0233, val_loss_epoch=0.0249, train_loss_epoch=0.0168] \n",
      "Epoch 11:  89%|████████▉ | 595/670 [03:33<00:26,  2.78it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  89%|████████▉ | 596/670 [03:34<00:26,  2.78it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  89%|████████▉ | 597/670 [03:34<00:26,  2.78it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|████████▉ | 600/670 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|████████▉ | 601/670 [03:35<00:24,  2.79it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|████████▉ | 602/670 [03:35<00:24,  2.80it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|█████████ | 604/670 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|█████████ | 605/670 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 607/670 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 608/670 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 609/670 [03:36<00:21,  2.81it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████▏| 612/670 [03:36<00:20,  2.82it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  91%|█████████▏| 613/670 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 614/670 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  92%|█████████▏| 616/670 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 617/670 [03:37<00:18,  2.83it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  92%|█████████▏| 619/670 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 620/670 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 621/670 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 624/670 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 625/670 [03:39<00:15,  2.85it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  93%|█████████▎| 626/670 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 629/670 [03:39<00:14,  2.86it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 630/670 [03:39<00:13,  2.86it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 631/670 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 632/670 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  94%|█████████▍| 633/670 [03:40<00:12,  2.87it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▍| 634/670 [03:40<00:12,  2.87it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▍| 636/670 [03:40<00:11,  2.88it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▌| 637/670 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▌| 638/670 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  95%|█████████▌| 639/670 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 641/670 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 642/670 [03:41<00:09,  2.89it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 643/670 [03:42<00:09,  2.90it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▌| 644/670 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  96%|█████████▋| 646/670 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 649/670 [03:43<00:07,  2.91it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 650/670 [03:43<00:06,  2.91it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 651/670 [03:43<00:06,  2.91it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 654/670 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 655/670 [03:44<00:05,  2.92it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 656/670 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 658/670 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  98%|█████████▊| 659/670 [03:44<00:03,  2.93it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▊| 661/670 [03:45<00:03,  2.94it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▉| 662/670 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▉| 663/670 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▉| 664/670 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11: 100%|█████████▉| 667/670 [03:46<00:01,  2.95it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11: 100%|█████████▉| 668/670 [03:46<00:00,  2.95it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11: 100%|█████████▉| 669/670 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.027, train_loss_step=0.017, val_loss_epoch=0.0249, train_loss_epoch=0.0167]\n",
      "Epoch 11: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.017, val_loss_epoch=0.0728, train_loss_epoch=0.0167]\n",
      "Epoch 12:  89%|████████▉ | 595/670 [03:33<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 596/670 [03:34<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  89%|████████▉ | 597/670 [03:34<00:26,  2.78it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  90%|████████▉ | 600/670 [03:34<00:25,  2.79it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  90%|████████▉ | 601/670 [03:35<00:24,  2.79it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  90%|████████▉ | 602/670 [03:35<00:24,  2.80it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  90%|█████████ | 604/670 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  90%|█████████ | 605/670 [03:35<00:23,  2.80it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  91%|█████████ | 607/670 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  91%|█████████ | 608/670 [03:36<00:22,  2.81it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  91%|█████████ | 609/670 [03:36<00:21,  2.81it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  91%|█████████▏| 612/670 [03:36<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  91%|█████████▏| 613/670 [03:37<00:20,  2.82it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  92%|█████████▏| 614/670 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  92%|█████████▏| 616/670 [03:37<00:19,  2.83it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  92%|█████████▏| 617/670 [03:37<00:18,  2.83it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  92%|█████████▏| 619/670 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  93%|█████████▎| 620/670 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  93%|█████████▎| 621/670 [03:38<00:17,  2.84it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  93%|█████████▎| 624/670 [03:38<00:16,  2.85it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  93%|█████████▎| 625/670 [03:39<00:15,  2.85it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  93%|█████████▎| 626/670 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  94%|█████████▍| 629/670 [03:39<00:14,  2.86it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  94%|█████████▍| 631/670 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  94%|█████████▍| 632/670 [03:40<00:13,  2.87it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  94%|█████████▍| 633/670 [03:40<00:12,  2.87it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  95%|█████████▍| 636/670 [03:40<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  95%|█████████▌| 637/670 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  95%|█████████▌| 638/670 [03:41<00:11,  2.88it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  95%|█████████▌| 639/670 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  96%|█████████▌| 641/670 [03:41<00:10,  2.89it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  96%|█████████▌| 642/670 [03:41<00:09,  2.89it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  96%|█████████▌| 643/670 [03:42<00:09,  2.90it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  96%|█████████▌| 644/670 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  96%|█████████▋| 646/670 [03:42<00:08,  2.90it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  97%|█████████▋| 649/670 [03:42<00:07,  2.91it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  97%|█████████▋| 650/670 [03:43<00:06,  2.91it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  97%|█████████▋| 651/670 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  98%|█████████▊| 654/670 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  98%|█████████▊| 655/670 [03:43<00:05,  2.92it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  98%|█████████▊| 656/670 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  98%|█████████▊| 658/670 [03:44<00:04,  2.93it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  98%|█████████▊| 659/670 [03:44<00:03,  2.93it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  99%|█████████▉| 662/670 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  99%|█████████▉| 663/670 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  99%|█████████▉| 664/670 [03:45<00:02,  2.94it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12: 100%|█████████▉| 667/670 [03:45<00:01,  2.95it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12: 100%|█████████▉| 668/670 [03:46<00:00,  2.95it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12: 100%|█████████▉| 669/670 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.0658, train_loss_step=0.0129, val_loss_epoch=0.0728, train_loss_epoch=0.0165]\n",
      "Epoch 12: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.017, val_loss_step=0.0543, train_loss_step=0.0129, val_loss_epoch=0.0542, train_loss_epoch=0.0165]\n",
      "Epoch 13:  89%|████████▉ | 595/670 [03:33<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  89%|████████▉ | 596/670 [03:34<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  89%|████████▉ | 597/670 [03:34<00:26,  2.78it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  90%|████████▉ | 600/670 [03:34<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  90%|████████▉ | 601/670 [03:35<00:24,  2.79it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  90%|████████▉ | 602/670 [03:35<00:24,  2.80it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  90%|█████████ | 604/670 [03:35<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  90%|█████████ | 605/670 [03:35<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  91%|█████████ | 607/670 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  91%|█████████ | 608/670 [03:36<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  91%|█████████ | 609/670 [03:36<00:21,  2.81it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  91%|█████████▏| 612/670 [03:36<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  91%|█████████▏| 613/670 [03:37<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  92%|█████████▏| 614/670 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  92%|█████████▏| 616/670 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  92%|█████████▏| 617/670 [03:37<00:18,  2.83it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  92%|█████████▏| 619/670 [03:37<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  93%|█████████▎| 620/670 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  93%|█████████▎| 621/670 [03:38<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  93%|█████████▎| 624/670 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  93%|█████████▎| 625/670 [03:38<00:15,  2.85it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  93%|█████████▎| 626/670 [03:39<00:15,  2.86it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  94%|█████████▍| 629/670 [03:39<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  94%|█████████▍| 632/670 [03:40<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  94%|█████████▍| 633/670 [03:40<00:12,  2.87it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  95%|█████████▍| 636/670 [03:40<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  95%|█████████▌| 637/670 [03:40<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  95%|█████████▌| 638/670 [03:41<00:11,  2.89it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  95%|█████████▌| 639/670 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  96%|█████████▌| 641/670 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  96%|█████████▌| 642/670 [03:41<00:09,  2.89it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  96%|█████████▌| 644/670 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  96%|█████████▋| 646/670 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  97%|█████████▋| 649/670 [03:42<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  97%|█████████▋| 650/670 [03:43<00:06,  2.91it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  97%|█████████▋| 651/670 [03:43<00:06,  2.92it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  98%|█████████▊| 654/670 [03:43<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  98%|█████████▊| 656/670 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  98%|█████████▊| 658/670 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  98%|█████████▊| 659/670 [03:44<00:03,  2.93it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  99%|█████████▉| 662/670 [03:45<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  99%|█████████▉| 663/670 [03:45<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  99%|█████████▉| 664/670 [03:45<00:02,  2.95it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13: 100%|█████████▉| 667/670 [03:45<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13: 100%|█████████▉| 668/670 [03:46<00:00,  2.95it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13: 100%|█████████▉| 669/670 [03:46<00:00,  2.96it/s, loss=0.015, val_loss_step=0.0543, train_loss_step=0.0174, val_loss_epoch=0.0542, train_loss_epoch=0.0164]\n",
      "Epoch 13: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.015, val_loss_step=0.0279, train_loss_step=0.0174, val_loss_epoch=0.0296, train_loss_epoch=0.0164]\n",
      "Epoch 14:  89%|████████▉ | 595/670 [03:34<00:27,  2.78it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  89%|████████▉ | 596/670 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  89%|████████▉ | 597/670 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  89%|████████▉ | 598/670 [03:34<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  89%|████████▉ | 599/670 [03:35<00:25,  2.78it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  90%|████████▉ | 600/670 [03:35<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  90%|████████▉ | 601/670 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  90%|████████▉ | 602/670 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  90%|█████████ | 603/670 [03:35<00:23,  2.79it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  90%|█████████ | 604/670 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  90%|█████████ | 605/670 [03:36<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  90%|█████████ | 606/670 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  91%|█████████ | 607/670 [03:36<00:22,  2.80it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  91%|█████████ | 608/670 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  91%|█████████ | 609/670 [03:36<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  91%|█████████ | 610/670 [03:36<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  91%|█████████ | 611/670 [03:37<00:20,  2.81it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  91%|█████████▏| 612/670 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  91%|█████████▏| 613/670 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  92%|█████████▏| 614/670 [03:37<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  92%|█████████▏| 615/670 [03:37<00:19,  2.82it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  92%|█████████▏| 616/670 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  92%|█████████▏| 617/670 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  92%|█████████▏| 618/670 [03:38<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  92%|█████████▏| 619/670 [03:38<00:17,  2.83it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  93%|█████████▎| 620/670 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  93%|█████████▎| 621/670 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  93%|█████████▎| 622/670 [03:38<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  93%|█████████▎| 623/670 [03:39<00:16,  2.84it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  93%|█████████▎| 624/670 [03:39<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  93%|█████████▎| 625/670 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  93%|█████████▎| 626/670 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  94%|█████████▎| 627/670 [03:39<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  94%|█████████▍| 629/670 [03:40<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  94%|█████████▍| 630/670 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  94%|█████████▍| 631/670 [03:40<00:13,  2.86it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  94%|█████████▍| 632/670 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  94%|█████████▍| 633/670 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  95%|█████████▍| 634/670 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  95%|█████████▍| 635/670 [03:41<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  95%|█████████▍| 636/670 [03:41<00:11,  2.87it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  95%|█████████▌| 637/670 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  95%|█████████▌| 638/670 [03:41<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  95%|█████████▌| 639/670 [03:41<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  96%|█████████▌| 640/670 [03:41<00:10,  2.88it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  96%|█████████▌| 641/670 [03:42<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  96%|█████████▌| 642/670 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  96%|█████████▌| 643/670 [03:42<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  96%|█████████▌| 644/670 [03:42<00:08,  2.89it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  96%|█████████▋| 646/670 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  97%|█████████▋| 647/670 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  97%|█████████▋| 648/670 [03:43<00:07,  2.90it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  97%|█████████▋| 649/670 [03:43<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  97%|█████████▋| 650/670 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  97%|█████████▋| 651/670 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  97%|█████████▋| 652/670 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  97%|█████████▋| 653/670 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  98%|█████████▊| 654/670 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  98%|█████████▊| 655/670 [03:44<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  98%|█████████▊| 656/670 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  98%|█████████▊| 657/670 [03:44<00:04,  2.92it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  98%|█████████▊| 658/670 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  98%|█████████▊| 659/670 [03:44<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  99%|█████████▊| 660/670 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  99%|█████████▊| 661/670 [03:45<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  99%|█████████▉| 662/670 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  99%|█████████▉| 663/670 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  99%|█████████▉| 664/670 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  99%|█████████▉| 665/670 [03:45<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14:  99%|█████████▉| 666/670 [03:46<00:01,  2.94it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14: 100%|█████████▉| 667/670 [03:46<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14: 100%|█████████▉| 668/670 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14: 100%|█████████▉| 669/670 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0279, train_loss_step=0.0175, val_loss_epoch=0.0296, train_loss_epoch=0.0163]\n",
      "Epoch 14: 100%|██████████| 670/670 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.0175, val_loss_epoch=0.0434, train_loss_epoch=0.0163]\n",
      "Epoch 15:  89%|████████▉ | 595/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  89%|████████▉ | 596/670 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  89%|████████▉ | 597/670 [03:34<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|████████▉ | 600/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|████████▉ | 602/670 [03:35<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|█████████ | 604/670 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 607/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 608/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 609/670 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████▏| 612/670 [03:36<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 614/670 [03:36<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 616/670 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  92%|█████████▏| 619/670 [03:37<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 620/670 [03:37<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 621/670 [03:38<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 624/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 625/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  93%|█████████▎| 626/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 629/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 632/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  94%|█████████▍| 633/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▍| 636/670 [03:40<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▌| 637/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▌| 638/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  95%|█████████▌| 639/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 641/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▌| 644/670 [03:41<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  96%|█████████▋| 646/670 [03:42<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 649/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 650/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 651/670 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 654/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 656/670 [03:43<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 658/670 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  98%|█████████▊| 659/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 662/670 [03:44<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 663/670 [03:45<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 664/670 [03:45<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15: 100%|█████████▉| 667/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15: 100%|█████████▉| 668/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15: 100%|█████████▉| 669/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0501, train_loss_step=0.017, val_loss_epoch=0.0434, train_loss_epoch=0.0162]\n",
      "Epoch 15: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.017, val_loss_epoch=0.0255, train_loss_epoch=0.0162] \n",
      "Epoch 16:  89%|████████▉ | 595/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  89%|████████▉ | 596/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  89%|████████▉ | 597/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  89%|████████▉ | 598/670 [03:33<00:25,  2.79it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  89%|████████▉ | 599/670 [03:34<00:25,  2.80it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  90%|████████▉ | 600/670 [03:34<00:25,  2.80it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  90%|████████▉ | 602/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  90%|█████████ | 603/670 [03:34<00:23,  2.81it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  90%|█████████ | 604/670 [03:34<00:23,  2.81it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  91%|█████████ | 607/670 [03:35<00:22,  2.82it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  91%|█████████ | 608/670 [03:35<00:21,  2.82it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  91%|█████████ | 609/670 [03:35<00:21,  2.82it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  91%|█████████ | 610/670 [03:35<00:21,  2.82it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  91%|█████████ | 611/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  91%|█████████▏| 612/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  92%|█████████▏| 614/670 [03:36<00:19,  2.83it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  92%|█████████▏| 615/670 [03:36<00:19,  2.84it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  92%|█████████▏| 616/670 [03:36<00:19,  2.84it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  92%|█████████▏| 619/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  93%|█████████▎| 620/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  93%|█████████▎| 621/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  93%|█████████▎| 622/670 [03:37<00:16,  2.85it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  93%|█████████▎| 623/670 [03:38<00:16,  2.86it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  93%|█████████▎| 624/670 [03:38<00:16,  2.86it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  93%|█████████▎| 625/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  93%|█████████▎| 626/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  94%|█████████▎| 627/670 [03:38<00:15,  2.87it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  94%|█████████▎| 628/670 [03:38<00:14,  2.87it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  94%|█████████▍| 629/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  94%|█████████▍| 631/670 [03:39<00:13,  2.88it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  94%|█████████▍| 632/670 [03:39<00:13,  2.88it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  94%|█████████▍| 633/670 [03:39<00:12,  2.88it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  95%|█████████▍| 634/670 [03:39<00:12,  2.88it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  95%|█████████▍| 635/670 [03:40<00:12,  2.89it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  95%|█████████▍| 636/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  95%|█████████▌| 637/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  95%|█████████▌| 638/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  95%|█████████▌| 639/670 [03:40<00:10,  2.90it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  96%|█████████▌| 640/670 [03:40<00:10,  2.90it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  96%|█████████▌| 641/670 [03:41<00:10,  2.90it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  96%|█████████▌| 644/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  96%|█████████▋| 645/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  96%|█████████▋| 646/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  97%|█████████▋| 648/670 [03:42<00:07,  2.92it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  97%|█████████▋| 649/670 [03:42<00:07,  2.92it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  97%|█████████▋| 650/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  97%|█████████▋| 651/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  97%|█████████▋| 652/670 [03:42<00:06,  2.93it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  97%|█████████▋| 653/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  98%|█████████▊| 654/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  98%|█████████▊| 656/670 [03:43<00:04,  2.94it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  98%|█████████▊| 657/670 [03:43<00:04,  2.94it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  98%|█████████▊| 658/670 [03:43<00:04,  2.94it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  98%|█████████▊| 659/670 [03:43<00:03,  2.94it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  99%|█████████▊| 661/670 [03:44<00:03,  2.95it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  99%|█████████▉| 662/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  99%|█████████▉| 663/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  99%|█████████▉| 664/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  99%|█████████▉| 665/670 [03:44<00:01,  2.96it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16:  99%|█████████▉| 666/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16: 100%|█████████▉| 667/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16: 100%|█████████▉| 668/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16: 100%|█████████▉| 669/670 [03:45<00:00,  2.97it/s, loss=0.016, val_loss_step=0.023, train_loss_step=0.0219, val_loss_epoch=0.0255, train_loss_epoch=0.016]\n",
      "Epoch 16: 100%|██████████| 670/670 [03:45<00:00,  2.97it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0219, val_loss_epoch=0.023, train_loss_epoch=0.016]\n",
      "Epoch 17:  89%|████████▉ | 595/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  89%|████████▉ | 596/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  89%|████████▉ | 597/670 [03:34<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  90%|████████▉ | 600/670 [03:34<00:25,  2.80it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  90%|████████▉ | 602/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  90%|█████████ | 604/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  91%|█████████ | 607/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  91%|█████████ | 608/670 [03:35<00:22,  2.82it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  91%|█████████ | 609/670 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  91%|█████████▏| 612/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  92%|█████████▏| 614/670 [03:36<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  92%|█████████▏| 615/670 [03:36<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  92%|█████████▏| 616/670 [03:37<00:19,  2.84it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  92%|█████████▏| 619/670 [03:37<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  93%|█████████▎| 620/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  93%|█████████▎| 621/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  93%|█████████▎| 624/670 [03:38<00:16,  2.86it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  93%|█████████▎| 625/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  93%|█████████▎| 626/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  94%|█████████▎| 627/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  94%|█████████▎| 628/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  94%|█████████▍| 629/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  94%|█████████▍| 632/670 [03:39<00:13,  2.88it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  94%|█████████▍| 633/670 [03:39<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  95%|█████████▍| 636/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  95%|█████████▌| 637/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  95%|█████████▌| 638/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  95%|█████████▌| 639/670 [03:40<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  96%|█████████▌| 641/670 [03:41<00:10,  2.90it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  96%|█████████▌| 644/670 [03:41<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  96%|█████████▋| 645/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  96%|█████████▋| 646/670 [03:42<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  97%|█████████▋| 649/670 [03:42<00:07,  2.92it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  97%|█████████▋| 650/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  97%|█████████▋| 651/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  98%|█████████▊| 654/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  98%|█████████▊| 656/670 [03:43<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  98%|█████████▊| 657/670 [03:43<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  98%|█████████▊| 658/670 [03:44<00:04,  2.94it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  98%|█████████▊| 659/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  99%|█████████▉| 662/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  99%|█████████▉| 663/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  99%|█████████▉| 664/670 [03:45<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17:  99%|█████████▉| 666/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17: 100%|█████████▉| 667/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17: 100%|█████████▉| 668/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17: 100%|█████████▉| 669/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0224, train_loss_step=0.0172, val_loss_epoch=0.023, train_loss_epoch=0.0159]\n",
      "Epoch 17: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0172, val_loss_epoch=0.017, train_loss_epoch=0.0159]\n",
      "Epoch 18:  89%|████████▉ | 595/670 [03:33<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  89%|████████▉ | 596/670 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  89%|████████▉ | 597/670 [03:34<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  90%|████████▉ | 600/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  90%|████████▉ | 602/670 [03:35<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  90%|█████████ | 604/670 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  91%|█████████ | 607/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  91%|█████████ | 608/670 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  91%|█████████ | 609/670 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  91%|█████████▏| 612/670 [03:36<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  92%|█████████▏| 614/670 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  92%|█████████▏| 616/670 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  92%|█████████▏| 619/670 [03:37<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  93%|█████████▎| 620/670 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  93%|█████████▎| 621/670 [03:38<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  93%|█████████▎| 624/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  93%|█████████▎| 625/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  93%|█████████▎| 626/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  94%|█████████▍| 629/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  94%|█████████▍| 632/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  94%|█████████▍| 633/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  95%|█████████▍| 636/670 [03:40<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  95%|█████████▌| 637/670 [03:40<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  95%|█████████▌| 638/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  95%|█████████▌| 639/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  96%|█████████▌| 641/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  96%|█████████▌| 644/670 [03:41<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  96%|█████████▋| 646/670 [03:42<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  97%|█████████▋| 649/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  97%|█████████▋| 650/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  97%|█████████▋| 651/670 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  98%|█████████▊| 654/670 [03:43<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  98%|█████████▊| 656/670 [03:43<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  98%|█████████▊| 658/670 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  98%|█████████▊| 659/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  99%|█████████▉| 662/670 [03:44<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  99%|█████████▉| 663/670 [03:45<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  99%|█████████▉| 664/670 [03:45<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18: 100%|█████████▉| 667/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18: 100%|█████████▉| 668/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18: 100%|█████████▉| 669/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 18: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0173, train_loss_step=0.0155, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  89%|████████▉ | 595/670 [03:33<00:26,  2.79it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  89%|████████▉ | 596/670 [03:33<00:26,  2.79it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  89%|████████▉ | 597/670 [03:34<00:26,  2.79it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  90%|████████▉ | 600/670 [03:34<00:25,  2.80it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  90%|████████▉ | 602/670 [03:34<00:24,  2.80it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  90%|█████████ | 604/670 [03:35<00:23,  2.81it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  91%|█████████ | 607/670 [03:35<00:22,  2.81it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  91%|█████████ | 608/670 [03:35<00:22,  2.82it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  91%|█████████ | 609/670 [03:36<00:21,  2.82it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  91%|█████████▏| 612/670 [03:36<00:20,  2.83it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  92%|█████████▏| 614/670 [03:36<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  92%|█████████▏| 616/670 [03:37<00:19,  2.84it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  92%|█████████▏| 619/670 [03:37<00:17,  2.84it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  93%|█████████▎| 620/670 [03:37<00:17,  2.85it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  93%|█████████▎| 621/670 [03:38<00:17,  2.85it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  93%|█████████▎| 624/670 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  93%|█████████▎| 625/670 [03:38<00:15,  2.86it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  93%|█████████▎| 626/670 [03:38<00:15,  2.86it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  94%|█████████▍| 629/670 [03:39<00:14,  2.87it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  94%|█████████▍| 632/670 [03:39<00:13,  2.87it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  94%|█████████▍| 633/670 [03:40<00:12,  2.88it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  95%|█████████▍| 636/670 [03:40<00:11,  2.88it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  95%|█████████▌| 637/670 [03:40<00:11,  2.89it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  95%|█████████▌| 638/670 [03:40<00:11,  2.89it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  95%|█████████▌| 639/670 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  96%|█████████▌| 641/670 [03:41<00:10,  2.90it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  96%|█████████▌| 644/670 [03:41<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  96%|█████████▋| 646/670 [03:42<00:08,  2.91it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  97%|█████████▋| 649/670 [03:42<00:07,  2.91it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  97%|█████████▋| 650/670 [03:42<00:06,  2.92it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  97%|█████████▋| 651/670 [03:43<00:06,  2.92it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  98%|█████████▊| 654/670 [03:43<00:05,  2.93it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  98%|█████████▊| 656/670 [03:43<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  98%|█████████▊| 658/670 [03:44<00:04,  2.94it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  98%|█████████▊| 659/670 [03:44<00:03,  2.94it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  99%|█████████▉| 662/670 [03:44<00:02,  2.94it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  99%|█████████▉| 663/670 [03:45<00:02,  2.95it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  99%|█████████▉| 664/670 [03:45<00:02,  2.95it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19: 100%|█████████▉| 667/670 [03:45<00:01,  2.96it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19: 100%|█████████▉| 668/670 [03:45<00:00,  2.96it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19: 100%|█████████▉| 669/670 [03:45<00:00,  2.96it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.017, val_loss_epoch=0.017, train_loss_epoch=0.0158]\n",
      "Epoch 19: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.017, val_loss_epoch=0.0166, train_loss_epoch=0.0158]\n",
      "Epoch 20:  89%|████████▉ | 595/670 [03:33<00:26,  2.79it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  89%|████████▉ | 596/670 [03:33<00:26,  2.79it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  89%|████████▉ | 597/670 [03:34<00:26,  2.79it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  90%|████████▉ | 600/670 [03:34<00:25,  2.80it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  90%|████████▉ | 602/670 [03:34<00:24,  2.80it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  90%|█████████ | 604/670 [03:35<00:23,  2.81it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  91%|█████████ | 607/670 [03:35<00:22,  2.81it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  91%|█████████ | 608/670 [03:35<00:22,  2.82it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  91%|█████████ | 609/670 [03:36<00:21,  2.82it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  91%|█████████▏| 612/670 [03:36<00:20,  2.83it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  92%|█████████▏| 614/670 [03:36<00:19,  2.83it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  92%|█████████▏| 616/670 [03:37<00:19,  2.84it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  92%|█████████▏| 619/670 [03:37<00:17,  2.84it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  93%|█████████▎| 620/670 [03:37<00:17,  2.84it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  93%|█████████▎| 621/670 [03:38<00:17,  2.85it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  93%|█████████▎| 624/670 [03:38<00:16,  2.85it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  93%|█████████▎| 625/670 [03:38<00:15,  2.86it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  93%|█████████▎| 626/670 [03:38<00:15,  2.86it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  94%|█████████▍| 629/670 [03:39<00:14,  2.87it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  94%|█████████▍| 632/670 [03:39<00:13,  2.87it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  94%|█████████▍| 633/670 [03:40<00:12,  2.88it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  95%|█████████▍| 636/670 [03:40<00:11,  2.88it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  95%|█████████▌| 637/670 [03:40<00:11,  2.89it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  95%|█████████▌| 638/670 [03:40<00:11,  2.89it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  95%|█████████▌| 639/670 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  96%|█████████▌| 641/670 [03:41<00:10,  2.90it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  96%|█████████▌| 644/670 [03:41<00:08,  2.90it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  96%|█████████▋| 646/670 [03:42<00:08,  2.91it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  97%|█████████▋| 649/670 [03:42<00:07,  2.91it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  97%|█████████▋| 650/670 [03:42<00:06,  2.92it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  97%|█████████▋| 651/670 [03:43<00:06,  2.92it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  98%|█████████▊| 654/670 [03:43<00:05,  2.93it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  98%|█████████▊| 656/670 [03:43<00:04,  2.93it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  98%|█████████▊| 658/670 [03:44<00:04,  2.94it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  98%|█████████▊| 659/670 [03:44<00:03,  2.94it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  99%|█████████▉| 662/670 [03:44<00:02,  2.94it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  99%|█████████▉| 663/670 [03:45<00:02,  2.95it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  99%|█████████▉| 664/670 [03:45<00:02,  2.95it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|█████████▉| 667/670 [03:45<00:01,  2.96it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20: 100%|█████████▉| 668/670 [03:45<00:00,  2.96it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20: 100%|█████████▉| 669/670 [03:45<00:00,  2.96it/s, loss=0.015, val_loss_step=0.017, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 20: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.015, val_loss_step=0.0169, train_loss_step=0.0129, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  89%|████████▉ | 595/670 [03:33<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  89%|████████▉ | 596/670 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  89%|████████▉ | 597/670 [03:34<00:26,  2.78it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  90%|████████▉ | 600/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  90%|████████▉ | 601/670 [03:35<00:24,  2.79it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  90%|████████▉ | 602/670 [03:35<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  90%|█████████ | 603/670 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  90%|█████████ | 604/670 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  90%|█████████ | 605/670 [03:35<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  91%|█████████ | 607/670 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  91%|█████████ | 608/670 [03:36<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  91%|█████████ | 609/670 [03:36<00:21,  2.81it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  91%|█████████▏| 612/670 [03:36<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  91%|█████████▏| 613/670 [03:37<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  92%|█████████▏| 614/670 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  92%|█████████▏| 615/670 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  92%|█████████▏| 616/670 [03:37<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  92%|█████████▏| 617/670 [03:37<00:18,  2.83it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  92%|█████████▏| 619/670 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  93%|█████████▎| 620/670 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  93%|█████████▎| 621/670 [03:38<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  93%|█████████▎| 624/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  93%|█████████▎| 625/670 [03:38<00:15,  2.85it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  93%|█████████▎| 626/670 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  94%|█████████▎| 627/670 [03:39<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  94%|█████████▎| 628/670 [03:39<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  94%|█████████▍| 629/670 [03:39<00:14,  2.86it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  94%|█████████▍| 632/670 [03:40<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  94%|█████████▍| 633/670 [03:40<00:12,  2.87it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  95%|█████████▍| 636/670 [03:40<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  95%|█████████▌| 637/670 [03:40<00:11,  2.88it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  95%|█████████▌| 638/670 [03:41<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  95%|█████████▌| 639/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  96%|█████████▌| 640/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  96%|█████████▌| 641/670 [03:41<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  96%|█████████▌| 642/670 [03:41<00:09,  2.89it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  96%|█████████▌| 644/670 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  96%|█████████▋| 645/670 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  96%|█████████▋| 646/670 [03:42<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  97%|█████████▋| 649/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  97%|█████████▋| 650/670 [03:43<00:06,  2.91it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  97%|█████████▋| 651/670 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  97%|█████████▋| 653/670 [03:43<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  98%|█████████▊| 654/670 [03:43<00:05,  2.92it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  98%|█████████▊| 656/670 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  98%|█████████▊| 657/670 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  98%|█████████▊| 658/670 [03:44<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  98%|█████████▊| 659/670 [03:44<00:03,  2.93it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  99%|█████████▉| 662/670 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  99%|█████████▉| 663/670 [03:45<00:02,  2.94it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  99%|█████████▉| 664/670 [03:45<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21:  99%|█████████▉| 666/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21: 100%|█████████▉| 667/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21: 100%|█████████▉| 668/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21: 100%|█████████▉| 669/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0169, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 21: 100%|██████████| 670/670 [03:46<00:00,  2.95it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.014, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  89%|████████▉ | 595/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 596/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  89%|████████▉ | 597/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  89%|████████▉ | 599/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  90%|████████▉ | 600/670 [03:34<00:25,  2.80it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  90%|████████▉ | 602/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  90%|█████████ | 603/670 [03:34<00:23,  2.80it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  90%|█████████ | 604/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  91%|█████████ | 607/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  91%|█████████ | 608/670 [03:35<00:22,  2.82it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  91%|█████████ | 609/670 [03:35<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  91%|█████████ | 611/670 [03:36<00:20,  2.82it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  91%|█████████▏| 612/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  92%|█████████▏| 614/670 [03:36<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  92%|█████████▏| 615/670 [03:36<00:19,  2.83it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  92%|█████████▏| 616/670 [03:37<00:19,  2.84it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  92%|█████████▏| 619/670 [03:37<00:17,  2.84it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  93%|█████████▎| 620/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  93%|█████████▎| 621/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  93%|█████████▎| 624/670 [03:38<00:16,  2.86it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  93%|█████████▎| 625/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  93%|█████████▎| 626/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  94%|█████████▎| 627/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  94%|█████████▎| 628/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  94%|█████████▍| 629/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  94%|█████████▍| 632/670 [03:39<00:13,  2.88it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  94%|█████████▍| 633/670 [03:39<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  95%|█████████▍| 636/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  95%|█████████▌| 637/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  95%|█████████▌| 638/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  95%|█████████▌| 639/670 [03:40<00:10,  2.89it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  96%|█████████▌| 640/670 [03:41<00:10,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  96%|█████████▌| 641/670 [03:41<00:10,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  96%|█████████▌| 644/670 [03:41<00:08,  2.90it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  96%|█████████▋| 645/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  96%|█████████▋| 646/670 [03:42<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  97%|█████████▋| 649/670 [03:42<00:07,  2.92it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  97%|█████████▋| 650/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  97%|█████████▋| 651/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  97%|█████████▋| 652/670 [03:43<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  97%|█████████▋| 653/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  98%|█████████▊| 654/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  98%|█████████▊| 656/670 [03:43<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  98%|█████████▊| 657/670 [03:43<00:04,  2.93it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  98%|█████████▊| 658/670 [03:44<00:04,  2.94it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  98%|█████████▊| 659/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  99%|█████████▉| 662/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  99%|█████████▉| 663/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  99%|█████████▉| 664/670 [03:45<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22:  99%|█████████▉| 666/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22: 100%|█████████▉| 667/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22: 100%|█████████▉| 668/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22: 100%|█████████▉| 669/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0168, train_loss_step=0.0123, val_loss_epoch=0.0166, train_loss_epoch=0.0157]\n",
      "Epoch 22: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0123, val_loss_epoch=0.0169, train_loss_epoch=0.0157]\n",
      "Epoch 23:  89%|████████▉ | 595/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 596/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  89%|████████▉ | 597/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  89%|████████▉ | 598/670 [03:33<00:25,  2.80it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  89%|████████▉ | 599/670 [03:34<00:25,  2.80it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  90%|████████▉ | 600/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  90%|████████▉ | 602/670 [03:34<00:24,  2.81it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  90%|█████████ | 603/670 [03:34<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  90%|█████████ | 604/670 [03:34<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  90%|█████████ | 606/670 [03:35<00:22,  2.82it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  91%|█████████ | 607/670 [03:35<00:22,  2.82it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  91%|█████████ | 608/670 [03:35<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  91%|█████████ | 609/670 [03:35<00:21,  2.82it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  91%|█████████ | 610/670 [03:35<00:21,  2.83it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  91%|█████████ | 611/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  91%|█████████▏| 612/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  92%|█████████▏| 614/670 [03:36<00:19,  2.84it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  92%|█████████▏| 615/670 [03:36<00:19,  2.84it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  92%|█████████▏| 616/670 [03:36<00:19,  2.84it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  92%|█████████▏| 618/670 [03:37<00:18,  2.85it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  92%|█████████▏| 619/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  93%|█████████▎| 620/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  93%|█████████▎| 621/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  93%|█████████▎| 622/670 [03:37<00:16,  2.85it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  93%|█████████▎| 623/670 [03:38<00:16,  2.86it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  93%|█████████▎| 624/670 [03:38<00:16,  2.86it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  93%|█████████▎| 625/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  93%|█████████▎| 626/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  94%|█████████▎| 627/670 [03:38<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  94%|█████████▎| 628/670 [03:38<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  94%|█████████▍| 629/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  94%|█████████▍| 631/670 [03:39<00:13,  2.88it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  94%|█████████▍| 632/670 [03:39<00:13,  2.88it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  94%|█████████▍| 633/670 [03:39<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  95%|█████████▍| 634/670 [03:39<00:12,  2.88it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  95%|█████████▍| 635/670 [03:40<00:12,  2.89it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  95%|█████████▍| 636/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  95%|█████████▌| 637/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  95%|█████████▌| 638/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  95%|█████████▌| 639/670 [03:40<00:10,  2.90it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  96%|█████████▌| 640/670 [03:40<00:10,  2.90it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  96%|█████████▌| 641/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  96%|█████████▌| 643/670 [03:41<00:09,  2.91it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  96%|█████████▌| 644/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  96%|█████████▋| 645/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  96%|█████████▋| 646/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  97%|█████████▋| 647/670 [03:41<00:07,  2.91it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  97%|█████████▋| 648/670 [03:42<00:07,  2.92it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  97%|█████████▋| 649/670 [03:42<00:07,  2.92it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  97%|█████████▋| 650/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  97%|█████████▋| 651/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  97%|█████████▋| 652/670 [03:42<00:06,  2.93it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  97%|█████████▋| 653/670 [03:42<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  98%|█████████▊| 654/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  98%|█████████▊| 656/670 [03:43<00:04,  2.94it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  98%|█████████▊| 657/670 [03:43<00:04,  2.94it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  98%|█████████▊| 658/670 [03:43<00:04,  2.94it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  98%|█████████▊| 659/670 [03:43<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  99%|█████████▊| 661/670 [03:44<00:03,  2.95it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  99%|█████████▉| 662/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  99%|█████████▉| 663/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  99%|█████████▉| 664/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  99%|█████████▉| 665/670 [03:44<00:01,  2.96it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23:  99%|█████████▉| 666/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23: 100%|█████████▉| 667/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23: 100%|█████████▉| 668/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23: 100%|█████████▉| 669/670 [03:45<00:00,  2.97it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0182, val_loss_epoch=0.0169, train_loss_epoch=0.0158]\n",
      "Epoch 23: 100%|██████████| 670/670 [03:45<00:00,  2.97it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.0182, val_loss_epoch=0.0184, train_loss_epoch=0.0158] \n",
      "Epoch 24:  89%|████████▉ | 595/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 596/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  89%|████████▉ | 597/670 [03:33<00:26,  2.79it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  89%|████████▉ | 598/670 [03:34<00:25,  2.79it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  89%|████████▉ | 599/670 [03:34<00:25,  2.80it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  90%|████████▉ | 600/670 [03:34<00:25,  2.80it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  90%|████████▉ | 601/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  90%|████████▉ | 602/670 [03:34<00:24,  2.80it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  90%|█████████ | 603/670 [03:34<00:23,  2.81it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  90%|█████████ | 604/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  90%|█████████ | 605/670 [03:35<00:23,  2.81it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  90%|█████████ | 606/670 [03:35<00:22,  2.81it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  91%|█████████ | 607/670 [03:35<00:22,  2.82it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  91%|█████████ | 608/670 [03:35<00:22,  2.82it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  91%|█████████ | 609/670 [03:35<00:21,  2.82it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  91%|█████████ | 610/670 [03:36<00:21,  2.82it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  91%|█████████ | 611/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  91%|█████████▏| 612/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  91%|█████████▏| 613/670 [03:36<00:20,  2.83it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  92%|█████████▏| 614/670 [03:36<00:19,  2.83it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  92%|█████████▏| 615/670 [03:36<00:19,  2.84it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  92%|█████████▏| 616/670 [03:37<00:19,  2.84it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  92%|█████████▏| 617/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  92%|█████████▏| 618/670 [03:37<00:18,  2.84it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  92%|█████████▏| 619/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  93%|█████████▎| 620/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  93%|█████████▎| 621/670 [03:37<00:17,  2.85it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  93%|█████████▎| 622/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  93%|█████████▎| 623/670 [03:38<00:16,  2.85it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  93%|█████████▎| 624/670 [03:38<00:16,  2.86it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  93%|█████████▎| 625/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  93%|█████████▎| 626/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  94%|█████████▎| 627/670 [03:38<00:15,  2.86it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  94%|█████████▎| 628/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  94%|█████████▍| 629/670 [03:39<00:14,  2.87it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  94%|█████████▍| 630/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  94%|█████████▍| 631/670 [03:39<00:13,  2.87it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  94%|█████████▍| 632/670 [03:39<00:13,  2.88it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  94%|█████████▍| 633/670 [03:39<00:12,  2.88it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  95%|█████████▍| 634/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  95%|█████████▍| 635/670 [03:40<00:12,  2.88it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  95%|█████████▍| 636/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  95%|█████████▌| 637/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  95%|█████████▌| 638/670 [03:40<00:11,  2.89it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  95%|█████████▌| 639/670 [03:40<00:10,  2.89it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  96%|█████████▌| 640/670 [03:41<00:10,  2.90it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  96%|█████████▌| 641/670 [03:41<00:10,  2.90it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  96%|█████████▌| 642/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  96%|█████████▌| 643/670 [03:41<00:09,  2.90it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  96%|█████████▌| 644/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  96%|█████████▋| 645/670 [03:41<00:08,  2.91it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  96%|█████████▋| 646/670 [03:42<00:08,  2.91it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  97%|█████████▋| 647/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  97%|█████████▋| 648/670 [03:42<00:07,  2.91it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  97%|█████████▋| 649/670 [03:42<00:07,  2.92it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  97%|█████████▋| 650/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  97%|█████████▋| 651/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  97%|█████████▋| 652/670 [03:42<00:06,  2.92it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  97%|█████████▋| 653/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  98%|█████████▊| 654/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  98%|█████████▊| 655/670 [03:43<00:05,  2.93it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  98%|█████████▊| 656/670 [03:43<00:04,  2.93it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  98%|█████████▊| 657/670 [03:43<00:04,  2.94it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  98%|█████████▊| 658/670 [03:43<00:04,  2.94it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  98%|█████████▊| 659/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  99%|█████████▊| 660/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  99%|█████████▊| 661/670 [03:44<00:03,  2.94it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  99%|█████████▉| 662/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  99%|█████████▉| 663/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  99%|█████████▉| 664/670 [03:44<00:02,  2.95it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  99%|█████████▉| 665/670 [03:45<00:01,  2.95it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24:  99%|█████████▉| 666/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24: 100%|█████████▉| 667/670 [03:45<00:01,  2.96it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24: 100%|█████████▉| 668/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24: 100%|█████████▉| 669/670 [03:45<00:00,  2.96it/s, loss=0.016, val_loss_step=0.019, train_loss_step=0.014, val_loss_epoch=0.0184, train_loss_epoch=0.0158]\n",
      "Epoch 24: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.014, val_loss_epoch=0.0181, train_loss_epoch=0.0158]\n",
      "Epoch 24: 100%|██████████| 670/670 [03:46<00:00,  2.96it/s, loss=0.016, val_loss_step=0.0171, train_loss_step=0.014, val_loss_epoch=0.0181, train_loss_epoch=0.0158]\n",
      "Test iterations: 138\n",
      "Testing: 100%|██████████| 138/138 [00:20<00:00,  6.79it/s]Logits: tensor([[ -5.9414,  -7.1641,  -7.6289,  ...,  -7.3320,  -6.5938,  -6.4961],\n",
      "        [ -6.6172,  -6.9141,  -7.5391,  ...,  -7.9336,  -6.8945,  -7.4727],\n",
      "        [ -9.0000, -10.1172, -10.3516,  ..., -10.3672, -10.9453, -10.9297],\n",
      "        ...,\n",
      "        [ -5.7461,  -6.9453,  -7.7266,  ...,  -7.4570,  -6.6523,  -6.5781],\n",
      "        [ -5.8438,  -7.0625,  -7.5156,  ...,  -7.2344,  -6.4023,  -6.3359],\n",
      "        [ -6.0000,  -7.1602,  -7.5898,  ...,  -7.3711,  -6.5469,  -6.5352]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[2.621e-03 7.734e-04 4.859e-04 ... 6.537e-04 1.367e-03 1.507e-03]\n",
      " [1.335e-03 9.928e-04 5.317e-04 ... 3.583e-04 1.012e-03 5.679e-04]\n",
      " [1.234e-04 4.035e-05 3.195e-05 ... 3.147e-05 1.764e-05 1.794e-05]\n",
      " ...\n",
      " [3.185e-03 9.623e-04 4.408e-04 ... 5.770e-04 1.289e-03 1.389e-03]\n",
      " [2.890e-03 8.559e-04 5.441e-04 ... 7.210e-04 1.655e-03 1.768e-03]\n",
      " [2.472e-03 7.763e-04 5.054e-04 ... 6.289e-04 1.432e-03 1.450e-03]]\n",
      "Testing: 100%|██████████| 138/138 [00:20<00:00,  6.57it/s]\n",
      "CV log_loss:  0.018217229938727666\n",
      "sub.shape(3982, 207)\n",
      "score: 0.018217229938727666\n",
      "CPU times: user 6h 57min 36s, sys: 1h 23min 22s, total: 8h 20min 58s\n",
      "Wall time: 7h 59min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#b3\n",
    "score= Exec(param_space)\n",
    "print(\"score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 42 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 4 M   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 38\n",
      "Train iterations: 149                                                 \n",
      "Epoch 0:  80%|███████▉  | 149/187 [00:59<00:15,  2.50it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Epoch 0:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  11%|█         | 4/38 [00:01<00:11,  3.07it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Epoch 0:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.19it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.53it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.71it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.83it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.86it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.90it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Epoch 0:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.06it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:01,  6.02it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Epoch 0:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.09it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:00,  6.02it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 182/187 [01:06<00:01,  2.76it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Epoch 0:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.07it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.020, val_loss_step=0.688, train_loss_step=0.0206]\n",
      "Epoch 0: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.020, val_loss_step=0.0205, train_loss_step=0.0206, val_loss_epoch=0.0226]\n",
      "Epoch 1:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Epoch 1:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.21it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.19it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Epoch 1:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.28it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Epoch 1:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Epoch 1:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Epoch 1:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.02it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Epoch 1:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.08it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Epoch 1:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:01,  6.11it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.00it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Epoch 1:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:00,  6.04it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.96it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.019, val_loss_step=0.0205, train_loss_step=0.0172, val_loss_epoch=0.0226, train_loss_epoch=0.0373]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.86it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.019, val_loss_step=0.0455, train_loss_step=0.0172, val_loss_epoch=0.0485, train_loss_epoch=0.0373]\n",
      "Epoch 2:  80%|███████▉  | 149/187 [00:59<00:15,  2.48it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:07,  4.26it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.20it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Epoch 2:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.018, val_loss_step=0.0455, train_loss_step=0.0198, val_loss_epoch=0.0485, train_loss_epoch=0.0191]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.16it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.018, val_loss_step=0.0336, train_loss_step=0.0198, val_loss_epoch=0.0354, train_loss_epoch=0.0191]\n",
      "Epoch 3:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.17it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.61it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.03it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.07it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.17it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.017, val_loss_step=0.0336, train_loss_step=0.0192, val_loss_epoch=0.0354, train_loss_epoch=0.018]\n",
      "Epoch 3: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.0192, val_loss_epoch=0.0465, train_loss_epoch=0.018]\n",
      "Epoch 4:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  93%|█████████▎| 174/187 [01:05<00:04,  2.68it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.26it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Epoch 4:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.15it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.017, val_loss_step=0.0436, train_loss_step=0.017, val_loss_epoch=0.0465, train_loss_epoch=0.0172]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.02it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.017, val_loss_step=0.0151, train_loss_step=0.017, val_loss_epoch=0.0184, train_loss_epoch=0.0172]\n",
      "Epoch 5:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Epoch 5:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Epoch 5:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Epoch 5:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Epoch 5:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Epoch 5:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:05,  5.03it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.39it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.59it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.70it/s]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.75it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.72it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.57it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.46it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.38it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.28it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.20it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.13it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.06it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0151, train_loss_step=0.0192, val_loss_epoch=0.0184, train_loss_epoch=0.0169]\n",
      "Epoch 5: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0192, val_loss_epoch=0.105, train_loss_epoch=0.0169] \n",
      "Epoch 6:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.61it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Epoch 6:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.016, val_loss_step=0.0985, train_loss_step=0.0204, val_loss_epoch=0.105, train_loss_epoch=0.0167]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.32it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0204, val_loss_epoch=0.0196, train_loss_epoch=0.0167]\n",
      "Epoch 7:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.41it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.05it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Epoch 7:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.21it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.016, val_loss_step=0.0162, train_loss_step=0.0162, val_loss_epoch=0.0196, train_loss_epoch=0.0163]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.02it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0162, val_loss_epoch=0.0233, train_loss_epoch=0.0163] \n",
      "Epoch 8:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Epoch 8:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.33it/s]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Epoch 8:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Epoch 8:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Epoch 8:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.41it/s]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.64it/s]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 164/187 [01:02<00:08,  2.60it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.73it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Epoch 8:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.89it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.59it/s]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.67it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.67it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.70it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.68it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.016, val_loss_step=0.021, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.69it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0135, val_loss_epoch=0.0233, train_loss_epoch=0.0162]\n",
      "Epoch 9:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.33it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.35it/s]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.08it/s]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.13it/s]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.0215, train_loss_step=0.0158, val_loss_epoch=0.0233, train_loss_epoch=0.0159]\n",
      "Epoch 9: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.016, val_loss_step=0.0301, train_loss_step=0.0158, val_loss_epoch=0.0318, train_loss_epoch=0.0159]\n",
      "Epoch 10:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  80%|████████  | 150/187 [01:01<00:15,  2.45it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  81%|████████▏ | 152/187 [01:01<00:14,  2.47it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  4.68it/s]\u001b[A\n",
      "Epoch 10:  86%|████████▌ | 160/187 [01:02<00:10,  2.54it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.59it/s]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  89%|████████▉ | 166/187 [01:03<00:08,  2.59it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:01,  6.31it/s]\u001b[A\n",
      "Epoch 10:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.23it/s]\u001b[A\n",
      "Epoch 10:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:00,  6.10it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Epoch 10:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.015, val_loss_step=0.0301, train_loss_step=0.0139, val_loss_epoch=0.0318, train_loss_epoch=0.0158]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.14it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0139, val_loss_epoch=0.0191, train_loss_epoch=0.0158]\n",
      "Epoch 11:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  81%|████████▏ | 152/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.18it/s]\u001b[A\n",
      "Epoch 11:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  84%|████████▍ | 158/187 [01:02<00:11,  2.55it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.56it/s]\u001b[A\n",
      "Epoch 11:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.81it/s]\u001b[A\n",
      "Epoch 11:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.77it/s]\u001b[A\n",
      "Epoch 11:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.88it/s]\u001b[A\n",
      "Epoch 11:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.65it/s]\u001b[A\n",
      "Epoch 11:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.92it/s]\u001b[A\n",
      "Epoch 11:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0182, val_loss_epoch=0.0191, train_loss_epoch=0.0156]\n",
      "Epoch 11: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0182, val_loss_epoch=0.0216, train_loss_epoch=0.0156]\n",
      "Epoch 12:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  81%|████████▏ | 152/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.21it/s]\u001b[A\n",
      "Epoch 12:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  84%|████████▍ | 158/187 [01:02<00:11,  2.55it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.31it/s]\u001b[A\n",
      "Epoch 12:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.28it/s]\u001b[A\n",
      "Epoch 12:  96%|█████████▋| 180/187 [01:06<00:02,  2.73it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.25it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0189, train_loss_step=0.0124, val_loss_epoch=0.0216, train_loss_epoch=0.0155]\n",
      "Epoch 12: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.015, val_loss_step=0.0153, train_loss_step=0.0124, val_loss_epoch=0.019, train_loss_epoch=0.0155] \n",
      "Epoch 13:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  80%|████████  | 150/187 [01:01<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:13,  2.64it/s]\u001b[A\n",
      "Epoch 13:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.43it/s]\u001b[A\n",
      "Epoch 13:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.61it/s]\u001b[A\n",
      "Epoch 13:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  92%|█████████▏| 172/187 [01:05<00:05,  2.65it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Epoch 13:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.18it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0153, train_loss_step=0.0138, val_loss_epoch=0.019, train_loss_epoch=0.0152]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.17it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0159, train_loss_step=0.0138, val_loss_epoch=0.0181, train_loss_epoch=0.0152]\n",
      "Epoch 14:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.21it/s]\u001b[A\n",
      "Epoch 14:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.01it/s]\u001b[A\n",
      "Epoch 14:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.36it/s]\u001b[A\n",
      "Epoch 14:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.27it/s]\u001b[A\n",
      "Epoch 14:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0159, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 14: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.0199, val_loss_epoch=0.0181, train_loss_epoch=0.015]\n",
      "Epoch 15:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.81it/s]\u001b[A\n",
      "Epoch 15:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  93%|█████████▎| 174/187 [01:05<00:04,  2.68it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0155, train_loss_step=0.017, val_loss_epoch=0.0181, train_loss_epoch=0.0148]\n",
      "Epoch 15: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.017, val_loss_epoch=0.0184, train_loss_epoch=0.0148]\n",
      "Epoch 16:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:07,  4.25it/s]\u001b[A\n",
      "Epoch 16:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.00it/s]\u001b[A\n",
      "Epoch 16:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.12it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.92it/s]\u001b[A\n",
      "Epoch 16:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.21it/s]\u001b[A\n",
      "Epoch 16:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Epoch 16:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0148, train_loss_step=0.0124, val_loss_epoch=0.0184, train_loss_epoch=0.0146]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.25it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0124, val_loss_epoch=0.0324, train_loss_epoch=0.0146]\n",
      "Epoch 17:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:13,  2.63it/s]\u001b[A\n",
      "Epoch 17:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.10it/s]\u001b[A\n",
      "Epoch 17:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.98it/s]\u001b[A\n",
      "Epoch 17:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  93%|█████████▎| 174/187 [01:05<00:04,  2.68it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Epoch 17:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0307, train_loss_step=0.0129, val_loss_epoch=0.0324, train_loss_epoch=0.0144]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.33it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.015, val_loss_step=0.0131, train_loss_step=0.0129, val_loss_epoch=0.0167, train_loss_epoch=0.0144]\n",
      "Epoch 18:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 18:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 18:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 18:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 18:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 18:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 18:  87%|████████▋ | 162/187 [01:02<00:09,  2.57it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.19it/s]\u001b[A\n",
      "Epoch 18:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 18:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.56it/s]\u001b[A\n",
      "Epoch 18:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating:  53%|█████▎    | 20/38 [00:04<00:03,  5.73it/s]\u001b[A\n",
      "Epoch 18:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.77it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.84it/s]\u001b[A\n",
      "Epoch 18:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.86it/s]\u001b[A\n",
      "Epoch 18:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 18:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.90it/s]\u001b[A\n",
      "Epoch 18:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.63it/s]\u001b[A\n",
      "Epoch 18:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.53it/s]\u001b[A\n",
      "Epoch 18:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0131, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 18: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0142] \n",
      "Epoch 19:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.11it/s]\u001b[A\n",
      "Epoch 19:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:00,  6.14it/s]\u001b[A\n",
      "Epoch 19:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.83it/s]\u001b[A\n",
      "Epoch 19:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.91it/s]\u001b[A\n",
      "Epoch 19:  99%|█████████▉| 186/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0127, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 20:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.20it/s]\u001b[A\n",
      "Epoch 20:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 20:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 20:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0136, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.04it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0136, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  81%|████████▏ | 152/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.22it/s]\u001b[A\n",
      "Epoch 21:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.22it/s]\u001b[A\n",
      "Epoch 21:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  84%|████████▍ | 158/187 [01:02<00:11,  2.55it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.32it/s]\u001b[A\n",
      "Epoch 21:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.86it/s]\u001b[A\n",
      "Epoch 21:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.18it/s]\u001b[A\n",
      "Epoch 21:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.91it/s]\u001b[A\n",
      "Epoch 21:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 21:  96%|█████████▋| 180/187 [01:06<00:02,  2.73it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:00,  6.13it/s]\u001b[A\n",
      "Epoch 21:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0128, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.07it/s]\u001b[A\n",
      "Epoch 21: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0107, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 22:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 22:  81%|████████▏ | 152/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.20it/s]\u001b[A\n",
      "Epoch 22:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.19it/s]\u001b[A\n",
      "Epoch 22:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.92it/s]\u001b[A\n",
      "Epoch 22:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 22:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 22:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 22:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.87it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.87it/s]\u001b[A\n",
      "Epoch 22:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.83it/s]\u001b[A\n",
      "Epoch 22:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.82it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.83it/s]\u001b[A\n",
      "Epoch 22:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.83it/s]\u001b[A\n",
      "Epoch 22:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.73it/s]\u001b[A\n",
      "Epoch 22:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Epoch 22:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 22:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.79it/s]\u001b[A\n",
      "Epoch 22:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0166, train_loss_epoch=0.0139]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.70it/s]\u001b[A\n",
      "Epoch 22: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0141, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  80%|████████  | 150/187 [01:00<00:15,  2.47it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  87%|████████▋ | 162/187 [01:02<00:09,  2.57it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.99it/s]\u001b[A\n",
      "Epoch 23:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.07it/s]\u001b[A\n",
      "Epoch 23:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.01it/s]\u001b[A\n",
      "Epoch 23:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.71it/s]\u001b[A\n",
      "Epoch 23:  98%|█████████▊| 184/187 [01:07<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  99%|█████████▉| 186/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0129, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139]\n",
      "Epoch 23: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0108, val_loss_epoch=0.0167, train_loss_epoch=0.0139] \n",
      "Epoch 24:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 24:  81%|████████▏ | 152/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 24:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 24:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.39it/s]\u001b[A\n",
      "Epoch 24:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 24:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:05,  5.13it/s]\u001b[A\n",
      "Epoch 24:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.42it/s]\u001b[A\n",
      "Epoch 24:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.58it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.68it/s]\u001b[A\n",
      "Epoch 24:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.66it/s]\u001b[A\n",
      "Epoch 24:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.65it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.59it/s]\u001b[A\n",
      "Epoch 24:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.68it/s]\u001b[A\n",
      "Epoch 24:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.70it/s]\u001b[A\n",
      "Epoch 24:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.71it/s]\u001b[A\n",
      "Epoch 24:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.74it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.74it/s]\u001b[A\n",
      "Epoch 24:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.013, train_loss_step=0.0157, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.68it/s]\u001b[A\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0157, val_loss_epoch=0.0173, train_loss_epoch=0.014]\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0157, val_loss_epoch=0.0173, train_loss_epoch=0.014]\n",
      "Test iterations: 69\n",
      "Testing: 100%|██████████| 69/69 [00:12<00:00,  6.10it/s]Logits: tensor([[-12.1484,  -9.1562,  -7.4141,  ...,  -9.4375, -10.9219, -10.1562],\n",
      "        [ -7.5664,  -6.6367,  -6.6836,  ...,  -6.8594,  -6.2812,  -7.6602],\n",
      "        [-22.0781, -19.8281, -11.1562,  ...,  -9.8828,  -7.6992,  -8.7031],\n",
      "        ...,\n",
      "        [ -7.0938,  -6.5703,  -5.7930,  ...,  -5.6680,  -6.2266,  -5.5859],\n",
      "        [ -6.9609,  -7.1445,  -6.6758,  ...,  -5.9648,  -6.3320,  -6.1367],\n",
      "        [ -7.7422,  -7.0000,  -6.2266,  ...,  -6.6445,  -7.5312,  -6.8203]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[5.3048e-06 1.0556e-04 6.0225e-04 ... 7.9691e-05 1.8060e-05 3.8803e-05]\n",
      " [5.1737e-04 1.3094e-03 1.2493e-03 ... 1.0481e-03 1.8673e-03 4.7112e-04]\n",
      " [0.0000e+00 0.0000e+00 1.4305e-05 ... 5.1022e-05 4.5300e-04 1.6606e-04]\n",
      " ...\n",
      " [8.2970e-04 1.3990e-03 3.0403e-03 ... 3.4428e-03 1.9722e-03 3.7365e-03]\n",
      " [9.4748e-04 7.8869e-04 1.2598e-03 ... 2.5616e-03 1.7748e-03 2.1572e-03]\n",
      " [4.3392e-04 9.1124e-04 1.9722e-03 ... 1.2999e-03 5.3596e-04 1.0900e-03]]\n",
      "Testing: 100%|██████████| 69/69 [00:12<00:00,  5.37it/s]\n",
      "==================== Fold 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 4 M   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 38\n",
      "Train iterations: 149                                                 \n",
      "Epoch 0:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Validating:  26%|██▋       | 10/38 [00:01<00:05,  4.98it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Epoch 0:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:01,  6.11it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.06it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.99it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.98it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.97it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0214]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.91it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0214, val_loss_epoch=0.0206]\n",
      "Epoch 1:  80%|███████▉  | 149/187 [00:59<00:15,  2.48it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:13,  2.62it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Epoch 1:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.31it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:05,  5.01it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.45it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Epoch 1:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Epoch 1:  88%|████████▊ | 164/187 [01:02<00:08,  2.60it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Epoch 1:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.15it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.93it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Epoch 1:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.92it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Epoch 1:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.03it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.93it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.96it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.020, val_loss_step=0.0191, train_loss_step=0.0166, val_loss_epoch=0.0206, train_loss_epoch=0.0415]\n",
      "Epoch 1: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.020, val_loss_step=0.0276, train_loss_step=0.0166, val_loss_epoch=0.0307, train_loss_epoch=0.0415]\n",
      "Epoch 2:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:13,  2.71it/s]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Epoch 2:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Epoch 2:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Epoch 2:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Epoch 2:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:03,  6.05it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Epoch 2:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.25it/s]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Epoch 2:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.30it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.84it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Epoch 2:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.23it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Epoch 2:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:00,  6.25it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Epoch 2:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.018, val_loss_step=0.0276, train_loss_step=0.0165, val_loss_epoch=0.0307, train_loss_epoch=0.0194]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.40it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.018, val_loss_step=0.036, train_loss_step=0.0165, val_loss_epoch=0.0386, train_loss_epoch=0.0194] \n",
      "Epoch 3:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  81%|████████▏ | 152/187 [01:00<00:14,  2.49it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Validating:  26%|██▋       | 10/38 [00:01<00:05,  4.83it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.38it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.33it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:00,  6.29it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.017, val_loss_step=0.036, train_loss_step=0.0164, val_loss_epoch=0.0386, train_loss_epoch=0.0184]\n",
      "Epoch 3: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0164, val_loss_epoch=0.0789, train_loss_epoch=0.0184]\n",
      "Epoch 4:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Epoch 4:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Epoch 4:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Epoch 4:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.43it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Epoch 4:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.41it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Epoch 4:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  6.04it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Epoch 4:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Epoch 4:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.00it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:01,  6.02it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.01it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.98it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.98it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.99it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.93it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.017, val_loss_step=0.079, train_loss_step=0.0166, val_loss_epoch=0.0789, train_loss_epoch=0.0176]\n",
      "Epoch 4: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0166, val_loss_epoch=0.0393, train_loss_epoch=0.0176]\n",
      "Epoch 5:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.16it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.70it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  6.07it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.08it/s]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.017, val_loss_step=0.0389, train_loss_step=0.0146, val_loss_epoch=0.0393, train_loss_epoch=0.0171]\n",
      "Epoch 5: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.017, val_loss_step=0.0418, train_loss_step=0.0146, val_loss_epoch=0.0435, train_loss_epoch=0.0171]\n",
      "Epoch 6:  80%|███████▉  | 149/187 [00:59<00:15,  2.48it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.49it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  97%|█████████▋| 182/187 [01:06<00:01,  2.76it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.016, val_loss_step=0.0418, train_loss_step=0.0193, val_loss_epoch=0.0435, train_loss_epoch=0.0167]\n",
      "Epoch 6: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0193, val_loss_epoch=0.0534, train_loss_epoch=0.0167]\n",
      "Epoch 7:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Epoch 7:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Epoch 7:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Epoch 7:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Epoch 7:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  26%|██▋       | 10/38 [00:01<00:05,  4.95it/s]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.25it/s]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.60it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.79it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.88it/s]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.92it/s]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.97it/s]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.96it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.96it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.93it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.016, val_loss_step=0.0531, train_loss_step=0.0178, val_loss_epoch=0.0534, train_loss_epoch=0.0165]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.86it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.0178, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Epoch 8:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.46it/s]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.32it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Epoch 8:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.016, val_loss_epoch=0.0254, train_loss_epoch=0.0163]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.53it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.016, val_loss_epoch=0.0194, train_loss_epoch=0.0163]\n",
      "Epoch 9:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.20it/s]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.76it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.28it/s]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  97%|█████████▋| 182/187 [01:06<00:01,  2.76it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.016, val_loss_step=0.0177, train_loss_step=0.0148, val_loss_epoch=0.0194, train_loss_epoch=0.0161]\n",
      "Epoch 9: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.016, val_loss_step=0.0149, train_loss_step=0.0148, val_loss_epoch=0.0181, train_loss_epoch=0.0161]\n",
      "Epoch 10:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.36it/s]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Validating:  26%|██▋       | 10/38 [00:01<00:05,  5.13it/s]\u001b[A\n",
      "Epoch 10:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.88it/s]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.13it/s]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  91%|█████████ | 170/187 [01:04<00:06,  2.66it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.07it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.18it/s]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:00,  6.40it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Epoch 10:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0147, val_loss_epoch=0.0181, train_loss_epoch=0.0159]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.27it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0147, val_loss_epoch=0.0191, train_loss_epoch=0.0159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  80%|███████▉  | 149/187 [01:00<00:15,  2.48it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.43it/s]\u001b[A\n",
      "Epoch 11:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.24it/s]\u001b[A\n",
      "Epoch 11:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0173, train_loss_step=0.0158, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 11: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0158, val_loss_epoch=0.0197, train_loss_epoch=0.0157]\n",
      "Epoch 12:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Epoch 12:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Epoch 12:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.79it/s]\u001b[A\n",
      "Epoch 12:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.73it/s]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  26%|██▋       | 10/38 [00:01<00:05,  5.36it/s]\u001b[A\n",
      "Epoch 12:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.75it/s]\u001b[A\n",
      "Epoch 12:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.95it/s]\u001b[A\n",
      "Epoch 12:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Epoch 12:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.16it/s]\u001b[A\n",
      "Epoch 12:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Epoch 12:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Epoch 12:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.32it/s]\u001b[A\n",
      "Epoch 12:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:01,  6.20it/s]\u001b[A\n",
      "Epoch 12:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Epoch 12:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Epoch 12:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:00,  6.35it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.23it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.015, val_loss_step=0.0149, train_loss_step=0.0164, val_loss_epoch=0.0197, train_loss_epoch=0.0155]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.15it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0164, val_loss_epoch=0.0172, train_loss_epoch=0.0155]\n",
      "Epoch 13:  80%|███████▉  | 149/187 [00:59<00:15,  2.50it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Epoch 13:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.94it/s]\u001b[A\n",
      "Epoch 13:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Epoch 13:  84%|████████▍ | 158/187 [01:01<00:11,  2.57it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  26%|██▋       | 10/38 [00:01<00:05,  5.16it/s]\u001b[A\n",
      "Epoch 13:  86%|████████▌ | 160/187 [01:01<00:10,  2.58it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.69it/s]\u001b[A\n",
      "Epoch 13:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Epoch 13:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  6.02it/s]\u001b[A\n",
      "Epoch 13:  89%|████████▉ | 166/187 [01:02<00:07,  2.64it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Epoch 13:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Epoch 13:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.36it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 172/187 [01:04<00:05,  2.69it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Epoch 13:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Epoch 13:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.38it/s]\u001b[A\n",
      "Epoch 13:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 13:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.96it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 182/187 [01:05<00:01,  2.77it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.99it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.015, val_loss_step=0.0141, train_loss_step=0.0175, val_loss_epoch=0.0172, train_loss_epoch=0.0153]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0175, val_loss_epoch=0.017, train_loss_epoch=0.0153] \n",
      "Epoch 14:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Epoch 14:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.17it/s]\u001b[A\n",
      "Epoch 14:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.21it/s]\u001b[A\n",
      "Epoch 14:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Epoch 14:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.43it/s]\u001b[A\n",
      "Epoch 14:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.97it/s]\u001b[A\n",
      "Epoch 14:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Epoch 14:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  6.05it/s]\u001b[A\n",
      "Epoch 14:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.13it/s]\u001b[A\n",
      "Epoch 14:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Epoch 14:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.87it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.78it/s]\u001b[A\n",
      "Epoch 14:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 14:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.92it/s]\u001b[A\n",
      "Epoch 14:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.92it/s]\u001b[A\n",
      "Epoch 14:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.93it/s]\u001b[A\n",
      "Epoch 14:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.91it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.015, val_loss_step=0.0127, train_loss_step=0.0134, val_loss_epoch=0.017, train_loss_epoch=0.0151]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.93it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0134, val_loss_epoch=0.0198, train_loss_epoch=0.0151]\n",
      "Epoch 15:  80%|███████▉  | 149/187 [00:59<00:15,  2.48it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.37it/s]\u001b[A\n",
      "Epoch 15:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Epoch 15:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Epoch 15:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Epoch 15:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Epoch 15:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Epoch 15:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Epoch 15:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.87it/s]\u001b[A\n",
      "Epoch 15:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 15:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.97it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.98it/s]\u001b[A\n",
      "Epoch 15:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.99it/s]\u001b[A\n",
      "Epoch 15:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.84it/s]\u001b[A\n",
      "Epoch 15:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.00it/s]\u001b[A\n",
      "Epoch 15:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.98it/s]\u001b[A\n",
      "Epoch 15:  97%|█████████▋| 182/187 [01:06<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.99it/s]\u001b[A\n",
      "Epoch 15:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.015, val_loss_step=0.0147, train_loss_step=0.0149, val_loss_epoch=0.0198, train_loss_epoch=0.0149]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.98it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0149, val_loss_epoch=0.0182, train_loss_epoch=0.0149]\n",
      "Epoch 16:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Epoch 16:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Epoch 16:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Epoch 16:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Epoch 16:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Epoch 16:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Epoch 16:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Epoch 16:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.53it/s]\u001b[A\n",
      "Epoch 16:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.74it/s]\u001b[A\n",
      "Epoch 16:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.87it/s]\u001b[A\n",
      "Epoch 16:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.90it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 16:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 16:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 16:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.93it/s]\u001b[A\n",
      "Epoch 16:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.97it/s]\u001b[A\n",
      "Epoch 16:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.96it/s]\u001b[A\n",
      "Epoch 16:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.015, val_loss_step=0.0136, train_loss_step=0.0162, val_loss_epoch=0.0182, train_loss_epoch=0.0146]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.95it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0162, val_loss_epoch=0.0167, train_loss_epoch=0.0146]\n",
      "Epoch 17:  80%|███████▉  | 149/187 [00:59<00:15,  2.50it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  80%|████████  | 150/187 [01:00<00:14,  2.50it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Epoch 17:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Epoch 17:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Epoch 17:  84%|████████▍ | 158/187 [01:01<00:11,  2.57it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Epoch 17:  86%|████████▌ | 160/187 [01:01<00:10,  2.59it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Epoch 17:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Epoch 17:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Epoch 17:  89%|████████▉ | 166/187 [01:02<00:07,  2.64it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Epoch 17:  90%|████████▉ | 168/187 [01:03<00:07,  2.66it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Epoch 17:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.95it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 172/187 [01:03<00:05,  2.69it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.92it/s]\u001b[A\n",
      "Epoch 17:  93%|█████████▎| 174/187 [01:04<00:04,  2.71it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 17:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 17:  95%|█████████▌| 178/187 [01:05<00:03,  2.74it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 17:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.96it/s]\u001b[A\n",
      "Epoch 17:  97%|█████████▋| 182/187 [01:05<00:01,  2.77it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.96it/s]\u001b[A\n",
      "Epoch 17:  98%|█████████▊| 184/187 [01:06<00:01,  2.79it/s, loss=0.015, val_loss_step=0.0118, train_loss_step=0.0159, val_loss_epoch=0.0167, train_loss_epoch=0.0145]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.93it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 187/187 [01:06<00:00,  2.81it/s, loss=0.015, val_loss_step=0.0115, train_loss_step=0.0159, val_loss_epoch=0.0163, train_loss_epoch=0.0145]\n",
      "Epoch 18:  80%|███████▉  | 149/187 [00:59<00:15,  2.48it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Epoch 18:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Epoch 18:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Epoch 18:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Epoch 18:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  26%|██▋       | 10/38 [00:01<00:05,  4.93it/s]\u001b[A\n",
      "Epoch 18:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Epoch 18:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Epoch 18:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Epoch 18:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Epoch 18:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.91it/s]\u001b[A\n",
      "Epoch 18:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.96it/s]\u001b[A\n",
      "Epoch 18:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.98it/s]\u001b[A\n",
      "Epoch 18:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.97it/s]\u001b[A\n",
      "Epoch 18:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 18:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.96it/s]\u001b[A\n",
      "Epoch 18:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.98it/s]\u001b[A\n",
      "Epoch 18:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0163, train_loss_epoch=0.0143]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.96it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.017, val_loss_epoch=0.0162, train_loss_epoch=0.0143]\n",
      "Epoch 19:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:01,  6.37it/s]\u001b[A\n",
      "Epoch 19:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  97%|█████████▋| 182/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 19:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.0115, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.41it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0144, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 20:  80%|███████▉  | 149/187 [00:59<00:15,  2.48it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.21it/s]\u001b[A\n",
      "Epoch 20:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.48it/s]\u001b[A\n",
      "Epoch 20:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.81it/s]\u001b[A\n",
      "Epoch 20:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  6.14it/s]\u001b[A\n",
      "Epoch 20:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.23it/s]\u001b[A\n",
      "Epoch 20:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.20it/s]\u001b[A\n",
      "Epoch 20:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.19it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:01,  6.31it/s]\u001b[A\n",
      "Epoch 20:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.13it/s]\u001b[A\n",
      "Epoch 20:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.35it/s]\u001b[A\n",
      "Epoch 20:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0138, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.19it/s]\u001b[A\n",
      "Epoch 21:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.23it/s]\u001b[A\n",
      "Epoch 21:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.68it/s]\u001b[A\n",
      "Epoch 21:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.95it/s]\u001b[A\n",
      "Epoch 21:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.40it/s]\u001b[A\n",
      "Epoch 21:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.39it/s]\u001b[A\n",
      "Epoch 21:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  97%|█████████▋| 182/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Epoch 21:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0161, train_loss_epoch=0.014]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.38it/s]\u001b[A\n",
      "Epoch 21: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0121, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 22:  80%|███████▉  | 149/187 [00:59<00:15,  2.48it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 22:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 22:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 22:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.45it/s]\u001b[A\n",
      "Epoch 22:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  26%|██▋       | 10/38 [00:01<00:05,  5.17it/s]\u001b[A\n",
      "Epoch 22:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.51it/s]\u001b[A\n",
      "Epoch 22:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.85it/s]\u001b[A\n",
      "Epoch 22:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  6.00it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 22:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.15it/s]\u001b[A\n",
      "Epoch 22:  91%|█████████ | 170/187 [01:04<00:06,  2.66it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 22:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.92it/s]\u001b[A\n",
      "Epoch 22:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.93it/s]\u001b[A\n",
      "Epoch 22:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 22:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.93it/s]\u001b[A\n",
      "Epoch 22:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.90it/s]\u001b[A\n",
      "Epoch 22:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.92it/s]\u001b[A\n",
      "Epoch 22:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.0116, train_loss_step=0.0114, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.88it/s]\u001b[A\n",
      "Epoch 22: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0114, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  80%|███████▉  | 149/187 [00:59<00:15,  2.49it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.76it/s]\u001b[A\n",
      "Epoch 23:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.11it/s]\u001b[A\n",
      "Epoch 23:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.59it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  97%|█████████▋| 182/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.0117, train_loss_step=0.0135, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 23: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0135, val_loss_epoch=0.0164, train_loss_epoch=0.014]\n",
      "Epoch 24:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 24:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.27it/s]\u001b[A\n",
      "Epoch 24:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 24:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 24:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 24:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 24:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 24:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 24:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 24:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.14it/s]\u001b[A\n",
      "Epoch 24:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.89it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.91it/s]\u001b[A\n",
      "Epoch 24:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.93it/s]\u001b[A\n",
      "Epoch 24:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.93it/s]\u001b[A\n",
      "Epoch 24:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.93it/s]\u001b[A\n",
      "Epoch 24:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  84%|████████▍ | 32/38 [00:05<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.94it/s]\u001b[A\n",
      "Epoch 24:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0118, train_loss_step=0.0122, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.92it/s]\u001b[A\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0119, train_loss_step=0.0122, val_loss_epoch=0.0165, train_loss_epoch=0.0141]\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0119, train_loss_step=0.0122, val_loss_epoch=0.0165, train_loss_epoch=0.0141]\n",
      "Test iterations: 69\n",
      "Testing: 100%|██████████| 69/69 [00:11<00:00,  7.11it/s]Logits: tensor([[-6.1406, -5.9492, -5.8125,  ..., -6.2852, -7.4883, -7.2344],\n",
      "        [-5.8789, -6.2305, -7.0469,  ..., -6.2070, -7.0586, -5.8047],\n",
      "        [-6.1797, -6.5547, -7.0586,  ..., -6.6719, -8.8281, -7.3047],\n",
      "        ...,\n",
      "        [-5.8867, -5.9453, -6.5977,  ..., -6.2148, -7.5078, -6.4062],\n",
      "        [-5.9141, -6.4766, -6.5859,  ..., -6.1445, -6.4844, -5.8438],\n",
      "        [-6.5859, -6.7891, -7.1758,  ..., -6.4492, -7.1055, -6.2070]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[0.00215   0.002602  0.002981  ... 0.001861  0.0005593 0.000721 ]\n",
      " [0.00279   0.001965  0.0008693 ... 0.00201   0.0008593 0.003004 ]\n",
      " [0.002068  0.001421  0.0008593 ... 0.001265  0.0001465 0.000672 ]\n",
      " ...\n",
      " [0.002768  0.002611  0.001362  ... 0.001995  0.0005484 0.001649 ]\n",
      " [0.002693  0.001536  0.001378  ... 0.00214   0.001525  0.00289  ]\n",
      " [0.001378  0.001124  0.0007644 ... 0.001579  0.00082   0.00201  ]]\n",
      "Testing: 100%|██████████| 69/69 [00:11<00:00,  5.75it/s]\n",
      "==================== Fold 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 4 M   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 37\n",
      "Train iterations: 150                                                 \n",
      "Epoch 0:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 151/187 [01:00<00:14,  2.48it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  82%|████████▏ | 153/187 [01:01<00:13,  2.50it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Validating:  11%|█         | 4/37 [00:00<00:10,  3.20it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 155/187 [01:01<00:12,  2.52it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  84%|████████▍ | 157/187 [01:01<00:11,  2.53it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  85%|████████▌ | 159/187 [01:02<00:10,  2.55it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  86%|████████▌ | 161/187 [01:02<00:10,  2.57it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  87%|████████▋ | 163/187 [01:02<00:09,  2.59it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  88%|████████▊ | 165/187 [01:03<00:08,  2.60it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  89%|████████▉ | 167/187 [01:03<00:07,  2.62it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Validating:  49%|████▊     | 18/37 [00:03<00:03,  6.12it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 169/187 [01:04<00:06,  2.64it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  91%|█████████▏| 171/187 [01:04<00:06,  2.65it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Validating:  59%|█████▉    | 22/37 [00:04<00:02,  6.21it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 173/187 [01:04<00:05,  2.67it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  94%|█████████▎| 175/187 [01:05<00:04,  2.69it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  95%|█████████▍| 177/187 [01:05<00:03,  2.70it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  96%|█████████▌| 179/187 [01:05<00:02,  2.72it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  97%|█████████▋| 181/187 [01:06<00:02,  2.73it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0:  98%|█████████▊| 183/187 [01:06<00:01,  2.75it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Validating:  92%|█████████▏| 34/37 [00:06<00:00,  6.43it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 185/187 [01:06<00:00,  2.77it/s, loss=0.020, val_loss_step=0.69, train_loss_step=0.0241]\n",
      "Epoch 0: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.020, val_loss_step=0.0198, train_loss_step=0.0241, val_loss_epoch=0.0208]\n",
      "Epoch 1:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:08,  3.56it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  88%|████████▊ | 164/187 [01:02<00:08,  2.60it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  5.14it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.65it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.018, val_loss_step=0.0198, train_loss_step=0.0215, val_loss_epoch=0.0208, train_loss_epoch=0.0372]\n",
      "Epoch 1: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0215, val_loss_epoch=0.0243, train_loss_epoch=0.0372]\n",
      "Epoch 2:  80%|████████  | 150/187 [01:00<00:14,  2.50it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.018, val_loss_step=0.0236, train_loss_step=0.0147, val_loss_epoch=0.0243, train_loss_epoch=0.019]\n",
      "Epoch 2: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.018, val_loss_step=0.0407, train_loss_step=0.0147, val_loss_epoch=0.0417, train_loss_epoch=0.019]\n",
      "Epoch 3:  80%|████████  | 150/187 [01:00<00:14,  2.50it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:08,  3.45it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:05,  4.79it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.27it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.31it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.017, val_loss_step=0.0407, train_loss_step=0.0186, val_loss_epoch=0.0417, train_loss_epoch=0.0181]\n",
      "Epoch 3: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0186, val_loss_epoch=0.047, train_loss_epoch=0.0181] \n",
      "Epoch 4:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:10,  2.92it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.81it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  96%|█████████▋| 180/187 [01:06<00:02,  2.73it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.50it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 186/187 [01:07<00:00,  2.77it/s, loss=0.017, val_loss_step=0.0472, train_loss_step=0.0157, val_loss_epoch=0.047, train_loss_epoch=0.0175]\n",
      "Epoch 4: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0157, val_loss_epoch=0.0536, train_loss_epoch=0.0175]\n",
      "Epoch 5:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:10,  3.02it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.18it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.65it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.86it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.13it/s]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  91%|█████████ | 170/187 [01:04<00:06,  2.66it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.62it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.017, val_loss_step=0.0535, train_loss_step=0.0196, val_loss_epoch=0.0536, train_loss_epoch=0.017]\n",
      "Epoch 5: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0196, val_loss_epoch=0.033, train_loss_epoch=0.017] \n",
      "Epoch 6:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:05,  4.62it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  4.90it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.19it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 170/187 [01:04<00:06,  2.66it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.46it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.30it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.017, val_loss_step=0.0333, train_loss_step=0.0186, val_loss_epoch=0.033, train_loss_epoch=0.0167]\n",
      "Epoch 6: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.017, val_loss_step=0.0243, train_loss_step=0.0186, val_loss_epoch=0.0254, train_loss_epoch=0.0167]\n",
      "Epoch 7:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Epoch 7:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Epoch 7:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Epoch 7:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Epoch 7:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.91it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 164/187 [01:02<00:08,  2.60it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  5.05it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.15it/s]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Epoch 7:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Epoch 7:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.43it/s]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.43it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.43it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.43it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.43it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.41it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.40it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0243, train_loss_step=0.0171, val_loss_epoch=0.0254, train_loss_epoch=0.0165]\n",
      "Epoch 7: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.0171, val_loss_epoch=0.0712, train_loss_epoch=0.0165]\n",
      "Epoch 8:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:08,  3.55it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.85it/s]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.17it/s]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.19it/s]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0689, train_loss_step=0.013, val_loss_epoch=0.0712, train_loss_epoch=0.0162]\n",
      "Epoch 8: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.013, val_loss_epoch=0.058, train_loss_epoch=0.0162] \n",
      "Epoch 9:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:07,  3.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.50it/s]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  91%|█████████ | 170/187 [01:04<00:06,  2.66it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0545, train_loss_step=0.016, val_loss_epoch=0.058, train_loss_epoch=0.016]\n",
      "Epoch 9: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.016, val_loss_epoch=0.0256, train_loss_epoch=0.016]\n",
      "Epoch 10:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  88%|████████▊ | 164/187 [01:02<00:08,  2.60it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  91%|█████████ | 170/187 [01:04<00:06,  2.66it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.55it/s]\u001b[A\n",
      "Epoch 10:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0241, train_loss_step=0.019, val_loss_epoch=0.0256, train_loss_epoch=0.0158]\n",
      "Epoch 10: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.019, val_loss_epoch=0.0259, train_loss_epoch=0.0158]\n",
      "Epoch 11:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/37 [00:00<00:17,  2.09it/s]\u001b[A\n",
      "Epoch 11:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.33it/s]\u001b[A\n",
      "Epoch 11:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.52it/s]\u001b[A\n",
      "Epoch 11:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.41it/s]\u001b[A\n",
      "Epoch 11:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.41it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.36it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.36it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 186/187 [01:07<00:00,  2.77it/s, loss=0.016, val_loss_step=0.0252, train_loss_step=0.0127, val_loss_epoch=0.0259, train_loss_epoch=0.0157]\n",
      "Epoch 11: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.016, val_loss_step=0.0179, train_loss_step=0.0127, val_loss_epoch=0.0191, train_loss_epoch=0.0157]\n",
      "Epoch 12:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.36it/s]\u001b[A\n",
      "Epoch 12:  87%|████████▋ | 162/187 [01:02<00:09,  2.57it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.27it/s]\u001b[A\n",
      "Epoch 12:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.05it/s]\u001b[A\n",
      "Epoch 12:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.22it/s]\u001b[A\n",
      "Epoch 12:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.19it/s]\u001b[A\n",
      "Epoch 12:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.20it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12:  99%|█████████▉| 186/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0179, train_loss_step=0.00973, val_loss_epoch=0.0191, train_loss_epoch=0.0155]\n",
      "Epoch 12: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0163, train_loss_step=0.00973, val_loss_epoch=0.0175, train_loss_epoch=0.0155]\n",
      "Epoch 13:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 13:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:05,  4.75it/s]\u001b[A\n",
      "Epoch 13:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Validating:  57%|█████▋    | 21/37 [00:04<00:02,  5.35it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.25it/s]\u001b[A\n",
      "Epoch 13:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.015, val_loss_step=0.0163, train_loss_step=0.0143, val_loss_epoch=0.0175, train_loss_epoch=0.0152]\n",
      "Epoch 13: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0143, val_loss_epoch=0.0321, train_loss_epoch=0.0152] \n",
      "Epoch 14:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  81%|████████▏ | 152/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:10,  2.94it/s]\u001b[A\n",
      "Epoch 14:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  84%|████████▍ | 158/187 [01:02<00:11,  2.55it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.29it/s]\u001b[A\n",
      "Epoch 14:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.34it/s]\u001b[A\n",
      "Epoch 14:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14:  99%|█████████▉| 186/187 [01:07<00:00,  2.77it/s, loss=0.015, val_loss_step=0.031, train_loss_step=0.0116, val_loss_epoch=0.0321, train_loss_epoch=0.015]\n",
      "Epoch 14: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0116, val_loss_epoch=0.0275, train_loss_epoch=0.015]\n",
      "Epoch 15:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Validating:  41%|████      | 15/37 [00:03<00:04,  4.85it/s]\u001b[A\n",
      "Epoch 15:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.18it/s]\u001b[A\n",
      "Epoch 15:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Validating:  57%|█████▋    | 21/37 [00:04<00:03,  5.18it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.25it/s]\u001b[A\n",
      "Epoch 15:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.18it/s]\u001b[A\n",
      "Epoch 15:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.14it/s]\u001b[A\n",
      "Epoch 15:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.015, val_loss_step=0.0231, train_loss_step=0.0186, val_loss_epoch=0.0275, train_loss_epoch=0.0148]\n",
      "Epoch 15: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.015, val_loss_step=0.0558, train_loss_step=0.0186, val_loss_epoch=0.0601, train_loss_epoch=0.0148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:10,  3.02it/s]\u001b[A\n",
      "Epoch 16:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  84%|████████▍ | 158/187 [01:02<00:11,  2.55it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.23it/s]\u001b[A\n",
      "Epoch 16:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.56it/s]\u001b[A\n",
      "Epoch 16:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0558, train_loss_step=0.0165, val_loss_epoch=0.0601, train_loss_epoch=0.0146]\n",
      "Epoch 16: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.0165, val_loss_epoch=0.0206, train_loss_epoch=0.0146]\n",
      "Epoch 17:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.49it/s]\u001b[A\n",
      "Epoch 17:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:09,  3.40it/s]\u001b[A\n",
      "Epoch 17:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:07,  4.11it/s]\u001b[A\n",
      "Epoch 17:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.61it/s]\u001b[A\n",
      "Epoch 17:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Epoch 17:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  5.06it/s]\u001b[A\n",
      "Epoch 17:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:  41%|████      | 15/37 [00:03<00:04,  5.13it/s]\u001b[A\n",
      "Epoch 17:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Epoch 17:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Epoch 17:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:  57%|█████▋    | 21/37 [00:04<00:03,  5.27it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Epoch 17:  93%|█████████▎| 174/187 [01:05<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.33it/s]\u001b[A\n",
      "Epoch 17:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Epoch 17:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.62it/s]\u001b[A\n",
      "Epoch 17:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.41it/s]\u001b[A\n",
      "Epoch 17:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Epoch 17:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Epoch 17:  99%|█████████▉| 186/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0202, train_loss_step=0.012, val_loss_epoch=0.0206, train_loss_epoch=0.0144]\n",
      "Epoch 17: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.012, val_loss_epoch=0.0171, train_loss_epoch=0.0144]\n",
      "Epoch 18:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.59it/s]\u001b[A\n",
      "Epoch 18:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:07,  3.93it/s]\u001b[A\n",
      "Epoch 18:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.51it/s]\u001b[A\n",
      "Epoch 18:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Epoch 18:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Epoch 18:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  5.24it/s]\u001b[A\n",
      "Epoch 18:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.35it/s]\u001b[A\n",
      "Epoch 18:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.38it/s]\u001b[A\n",
      "Epoch 18:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  57%|█████▋    | 21/37 [00:04<00:02,  5.40it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.42it/s]\u001b[A\n",
      "Epoch 18:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.43it/s]\u001b[A\n",
      "Epoch 18:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.42it/s]\u001b[A\n",
      "Epoch 18:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.42it/s]\u001b[A\n",
      "Epoch 18:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.43it/s]\u001b[A\n",
      "Epoch 18:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.43it/s]\u001b[A\n",
      "Epoch 18:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.44it/s]\u001b[A\n",
      "Epoch 18:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0168, train_loss_step=0.0145, val_loss_epoch=0.0171, train_loss_epoch=0.0142]\n",
      "Epoch 18: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0161, train_loss_step=0.0145, val_loss_epoch=0.0167, train_loss_epoch=0.0142]\n",
      "Epoch 19:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:05,  4.64it/s]\u001b[A\n",
      "Epoch 19:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  91%|█████████ | 170/187 [01:04<00:06,  2.66it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.40it/s]\u001b[A\n",
      "Epoch 19:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.42it/s]\u001b[A\n",
      "Epoch 19:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.013, val_loss_step=0.0161, train_loss_step=0.0121, val_loss_epoch=0.0167, train_loss_epoch=0.014]\n",
      "Epoch 19: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0121, val_loss_epoch=0.0164, train_loss_epoch=0.014]\n",
      "Epoch 20:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.53it/s]\u001b[A\n",
      "Epoch 20:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.48it/s]\u001b[A\n",
      "Epoch 20:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.52it/s]\u001b[A\n",
      "Epoch 20:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.013, val_loss_step=0.0157, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 20: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.013, val_loss_step=0.0158, train_loss_step=0.0103, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  87%|████████▋ | 162/187 [01:02<00:09,  2.57it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  93%|█████████▎| 174/187 [01:05<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21:  99%|█████████▉| 186/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 21: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0174, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 22:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 22:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 22:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 22:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:07,  3.99it/s]\u001b[A\n",
      "Epoch 22:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.54it/s]\u001b[A\n",
      "Epoch 22:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.95it/s]\u001b[A\n",
      "Epoch 22:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  5.17it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.28it/s]\u001b[A\n",
      "Epoch 22:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.34it/s]\u001b[A\n",
      "Epoch 22:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  57%|█████▋    | 21/37 [00:04<00:02,  5.34it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.37it/s]\u001b[A\n",
      "Epoch 22:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.38it/s]\u001b[A\n",
      "Epoch 22:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.37it/s]\u001b[A\n",
      "Epoch 22:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.41it/s]\u001b[A\n",
      "Epoch 22:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.38it/s]\u001b[A\n",
      "Epoch 22:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.37it/s]\u001b[A\n",
      "Epoch 22:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.40it/s]\u001b[A\n",
      "Epoch 22:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0158, train_loss_step=0.0185, val_loss_epoch=0.0164, train_loss_epoch=0.0139]\n",
      "Epoch 22: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.0185, val_loss_epoch=0.0165, train_loss_epoch=0.0139] \n",
      "Epoch 23:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  87%|████████▋ | 162/187 [01:02<00:09,  2.57it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23:  99%|█████████▉| 186/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.016, train_loss_step=0.013, val_loss_epoch=0.0165, train_loss_epoch=0.014]\n",
      "Epoch 23: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.013, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0167, val_loss_epoch=0.018, train_loss_epoch=0.014]\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.014, val_loss_step=0.0181, train_loss_step=0.0167, val_loss_epoch=0.0192, train_loss_epoch=0.014]\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.014, val_loss_step=0.0181, train_loss_step=0.0167, val_loss_epoch=0.0192, train_loss_epoch=0.014]\n",
      "Test iterations: 68\n",
      "Testing:  99%|█████████▊| 67/68 [00:12<00:00,  5.67it/s]Logits: tensor([[ -9.4688,  -9.4062,  -8.6719,  ...,  -8.1719,  -7.3828,  -6.9297],\n",
      "        [-10.9062, -12.0000,  -7.9648,  ...,  -7.3789,  -4.8438,  -6.8711],\n",
      "        [-17.2344, -15.0156, -11.6719,  ..., -14.2422, -11.7812, -12.5703],\n",
      "        ...,\n",
      "        [ -7.4570,  -7.0781,  -8.9922,  ...,  -8.0234,  -7.2227,  -6.2188],\n",
      "        [ -8.5781,  -8.9766,  -7.8281,  ...,  -7.4375,  -7.0312,  -6.4609],\n",
      "        [ -7.4766,  -6.9531,  -7.9805,  ...,  -7.3906,  -8.1250,  -6.7266]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[7.725e-05 8.219e-05 1.713e-04 ... 2.825e-04 6.213e-04 9.775e-04]\n",
      " [1.836e-05 6.139e-06 3.474e-04 ... 6.237e-04 7.812e-03 1.037e-03]\n",
      " [5.960e-08 2.980e-07 8.523e-06 ... 6.557e-07 7.629e-06 3.457e-06]\n",
      " ...\n",
      " [5.770e-04 8.426e-04 1.243e-04 ... 3.276e-04 7.296e-04 1.987e-03]\n",
      " [1.881e-04 1.264e-04 3.982e-04 ... 5.884e-04 8.831e-04 1.561e-03]\n",
      " [5.660e-04 9.546e-04 3.419e-04 ... 6.166e-04 2.959e-04 1.197e-03]]\n",
      "Testing: 100%|██████████| 68/68 [00:12<00:00,  5.51it/s]\n",
      "==================== Fold 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 4 M   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 37\n",
      "Train iterations: 150                                                 \n",
      "Epoch 0:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 151/187 [01:00<00:14,  2.49it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  82%|████████▏ | 153/187 [01:01<00:13,  2.51it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  83%|████████▎ | 155/187 [01:01<00:12,  2.53it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Validating:  16%|█▌        | 6/37 [00:01<00:08,  3.77it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 157/187 [01:01<00:11,  2.54it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  85%|████████▌ | 159/187 [01:02<00:10,  2.56it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  86%|████████▌ | 161/187 [01:02<00:10,  2.58it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Validating:  32%|███▏      | 12/37 [00:02<00:04,  5.51it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 163/187 [01:02<00:09,  2.60it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  88%|████████▊ | 165/187 [01:03<00:08,  2.61it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  89%|████████▉ | 167/187 [01:03<00:07,  2.63it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  90%|█████████ | 169/187 [01:03<00:06,  2.65it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  91%|█████████▏| 171/187 [01:04<00:06,  2.67it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  93%|█████████▎| 173/187 [01:04<00:05,  2.68it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  94%|█████████▎| 175/187 [01:04<00:04,  2.70it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  95%|█████████▍| 177/187 [01:05<00:03,  2.71it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  96%|█████████▌| 179/187 [01:05<00:02,  2.73it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  97%|█████████▋| 181/187 [01:05<00:02,  2.75it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  98%|█████████▊| 183/187 [01:06<00:01,  2.76it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0:  99%|█████████▉| 185/187 [01:06<00:00,  2.78it/s, loss=0.020, val_loss_step=0.691, train_loss_step=0.0204]\n",
      "Epoch 0: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0204, val_loss_epoch=0.0215]\n",
      "Epoch 1:  80%|████████  | 150/187 [00:59<00:14,  2.50it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  86%|████████▌ | 160/187 [01:01<00:10,  2.58it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.12it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.020, val_loss_step=0.0202, train_loss_step=0.0115, val_loss_epoch=0.0215, train_loss_epoch=0.0374]\n",
      "Epoch 1: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.020, val_loss_step=0.0196, train_loss_step=0.0115, val_loss_epoch=0.0212, train_loss_epoch=0.0374]\n",
      "Epoch 2:  80%|████████  | 150/187 [01:00<00:14,  2.50it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.40it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.26it/s]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.69it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2:  99%|█████████▉| 186/187 [01:06<00:00,  2.80it/s, loss=0.018, val_loss_step=0.0196, train_loss_step=0.0165, val_loss_epoch=0.0212, train_loss_epoch=0.0193]\n",
      "Epoch 2: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0165, val_loss_epoch=0.0358, train_loss_epoch=0.0193] \n",
      "Epoch 3:  80%|████████  | 150/187 [00:59<00:14,  2.51it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 152/187 [01:00<00:13,  2.52it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  82%|████████▏ | 154/187 [01:00<00:13,  2.54it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  84%|████████▍ | 158/187 [01:01<00:11,  2.57it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.06it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 160/187 [01:01<00:10,  2.59it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  87%|████████▋ | 162/187 [01:02<00:09,  2.61it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  89%|████████▉ | 166/187 [01:02<00:07,  2.64it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.31it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 168/187 [01:03<00:07,  2.66it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  91%|█████████ | 170/187 [01:03<00:06,  2.68it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  92%|█████████▏| 172/187 [01:03<00:05,  2.69it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  93%|█████████▎| 174/187 [01:04<00:04,  2.71it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  94%|█████████▍| 176/187 [01:04<00:04,  2.73it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  95%|█████████▌| 178/187 [01:04<00:03,  2.74it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  96%|█████████▋| 180/187 [01:05<00:02,  2.76it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  97%|█████████▋| 182/187 [01:05<00:01,  2.77it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  98%|█████████▊| 184/187 [01:05<00:01,  2.79it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3:  99%|█████████▉| 186/187 [01:06<00:00,  2.80it/s, loss=0.018, val_loss_step=0.034, train_loss_step=0.0233, val_loss_epoch=0.0358, train_loss_epoch=0.0184]\n",
      "Epoch 3: 100%|██████████| 187/187 [01:06<00:00,  2.81it/s, loss=0.018, val_loss_step=0.355, train_loss_step=0.0233, val_loss_epoch=0.373, train_loss_epoch=0.0184] \n",
      "Epoch 4:  80%|████████  | 150/187 [00:59<00:14,  2.50it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  84%|████████▍ | 158/187 [01:01<00:11,  2.57it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  86%|████████▌ | 160/187 [01:01<00:10,  2.58it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  89%|████████▉ | 166/187 [01:02<00:07,  2.64it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.14it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.13it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  92%|█████████▏| 172/187 [01:04<00:05,  2.69it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.42it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.30it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.39it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  99%|█████████▉| 186/187 [01:06<00:00,  2.80it/s, loss=0.017, val_loss_step=0.355, train_loss_step=0.0156, val_loss_epoch=0.373, train_loss_epoch=0.0179]\n",
      "Epoch 4: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0156, val_loss_epoch=0.11, train_loss_epoch=0.0179] \n",
      "Epoch 5:  80%|████████  | 150/187 [01:00<00:14,  2.50it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:10,  3.03it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  86%|████████▌ | 160/187 [01:01<00:10,  2.58it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  89%|████████▉ | 166/187 [01:02<00:07,  2.64it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.36it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.60it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.46it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5:  99%|█████████▉| 186/187 [01:06<00:00,  2.80it/s, loss=0.017, val_loss_step=0.106, train_loss_step=0.0196, val_loss_epoch=0.11, train_loss_epoch=0.0174]\n",
      "Epoch 5: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0196, val_loss_epoch=0.134, train_loss_epoch=0.0174]\n",
      "Epoch 6:  80%|████████  | 150/187 [00:59<00:14,  2.51it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  81%|████████▏ | 152/187 [01:00<00:13,  2.52it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  82%|████████▏ | 154/187 [01:00<00:13,  2.54it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  84%|████████▍ | 158/187 [01:01<00:11,  2.57it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  86%|████████▌ | 160/187 [01:01<00:10,  2.59it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  87%|████████▋ | 162/187 [01:02<00:09,  2.61it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  89%|████████▉ | 166/187 [01:02<00:07,  2.64it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  90%|████████▉ | 168/187 [01:03<00:07,  2.66it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.33it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 170/187 [01:03<00:06,  2.68it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Validating:  57%|█████▋    | 21/37 [00:03<00:02,  5.36it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 172/187 [01:03<00:05,  2.69it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  93%|█████████▎| 174/187 [01:04<00:04,  2.71it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.45it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 176/187 [01:04<00:04,  2.73it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.42it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 178/187 [01:04<00:03,  2.74it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  96%|█████████▋| 180/187 [01:05<00:02,  2.76it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.50it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 182/187 [01:05<00:01,  2.77it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  98%|█████████▊| 184/187 [01:05<00:01,  2.79it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6:  99%|█████████▉| 186/187 [01:06<00:00,  2.81it/s, loss=0.017, val_loss_step=0.128, train_loss_step=0.0193, val_loss_epoch=0.134, train_loss_epoch=0.0171]\n",
      "Epoch 6: 100%|██████████| 187/187 [01:06<00:00,  2.81it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0193, val_loss_epoch=0.0498, train_loss_epoch=0.0171]\n",
      "Epoch 7:  80%|████████  | 150/187 [01:00<00:14,  2.50it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:10,  2.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.27it/s]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.94it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  5.08it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.28it/s]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.36it/s]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.30it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.017, val_loss_step=0.0477, train_loss_step=0.0163, val_loss_epoch=0.0498, train_loss_epoch=0.0168]\n",
      "Epoch 7: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0163, val_loss_epoch=0.0521, train_loss_epoch=0.0168]\n",
      "Epoch 8:  80%|████████  | 150/187 [00:59<00:14,  2.51it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.49it/s]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:09,  3.41it/s]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:07,  4.16it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 158/187 [01:01<00:11,  2.57it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:05,  4.69it/s]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 160/187 [01:01<00:10,  2.59it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.94it/s]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Epoch 8:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  5.21it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 166/187 [01:02<00:07,  2.64it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Epoch 8:  90%|████████▉ | 168/187 [01:03<00:07,  2.66it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.34it/s]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Epoch 8:  92%|█████████▏| 172/187 [01:03<00:05,  2.69it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.39it/s]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Epoch 8:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.41it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 178/187 [01:05<00:03,  2.74it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.29it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.26it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 182/187 [01:05<00:01,  2.77it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.26it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.23it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 186/187 [01:06<00:00,  2.80it/s, loss=0.017, val_loss_step=0.0491, train_loss_step=0.0231, val_loss_epoch=0.0521, train_loss_epoch=0.0164]\n",
      "Epoch 8: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.017, val_loss_step=0.0854, train_loss_step=0.0231, val_loss_epoch=0.091, train_loss_epoch=0.0164] \n",
      "Epoch 9:  80%|████████  | 150/187 [00:59<00:14,  2.51it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.56it/s]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:09,  3.46it/s]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  84%|████████▍ | 158/187 [01:01<00:11,  2.57it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  86%|████████▌ | 160/187 [01:01<00:10,  2.59it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.81it/s]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  5.18it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 166/187 [01:02<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  92%|█████████▏| 172/187 [01:04<00:05,  2.69it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.45it/s]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  97%|█████████▋| 182/187 [01:05<00:01,  2.77it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.56it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9:  99%|█████████▉| 186/187 [01:06<00:00,  2.80it/s, loss=0.016, val_loss_step=0.0854, train_loss_step=0.0162, val_loss_epoch=0.091, train_loss_epoch=0.0163]\n",
      "Epoch 9: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.0162, val_loss_epoch=0.018, train_loss_epoch=0.0163]\n",
      "Epoch 10:  80%|████████  | 150/187 [00:59<00:14,  2.50it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/37 [00:00<00:18,  1.98it/s]\u001b[A\n",
      "Epoch 10:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  86%|████████▌ | 160/187 [01:01<00:10,  2.58it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.94it/s]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.30it/s]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Validating:  57%|█████▋    | 21/37 [00:03<00:02,  5.37it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.32it/s]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.40it/s]\u001b[A\n",
      "Epoch 10:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.31it/s]\u001b[A\n",
      "Epoch 10:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.28it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.016, val_loss_step=0.0163, train_loss_step=0.019, val_loss_epoch=0.018, train_loss_epoch=0.016]\n",
      "Epoch 10: 100%|██████████| 187/187 [01:06<00:00,  2.79it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.019, val_loss_epoch=0.0243, train_loss_epoch=0.016]\n",
      "Epoch 11:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Epoch 11:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Epoch 11:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Epoch 11:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Epoch 11:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Epoch 11:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Epoch 11:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Epoch 11:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.38it/s]\u001b[A\n",
      "Epoch 11:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Validating:  57%|█████▋    | 21/37 [00:03<00:02,  5.50it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.52it/s]\u001b[A\n",
      "Epoch 11:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.52it/s]\u001b[A\n",
      "Epoch 11:  94%|█████████▍| 176/187 [01:05<00:04,  2.71it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Validating:  73%|███████▎  | 27/37 [00:04<00:01,  5.53it/s]\u001b[A\n",
      "Epoch 11:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.52it/s]\u001b[A\n",
      "Epoch 11:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.52it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.53it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.51it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.016, val_loss_step=0.0217, train_loss_step=0.025, val_loss_epoch=0.0243, train_loss_epoch=0.0157]\n",
      "Epoch 11: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.016, val_loss_step=0.0238, train_loss_step=0.025, val_loss_epoch=0.0264, train_loss_epoch=0.0157]\n",
      "Epoch 12:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:07,  3.92it/s]\u001b[A\n",
      "Epoch 12:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  5.07it/s]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12:  99%|█████████▉| 186/187 [01:07<00:00,  2.77it/s, loss=0.015, val_loss_step=0.0238, train_loss_step=0.00779, val_loss_epoch=0.0264, train_loss_epoch=0.0156]\n",
      "Epoch 12: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.00779, val_loss_epoch=0.0203, train_loss_epoch=0.0156]\n",
      "Epoch 13:  80%|████████  | 150/187 [00:59<00:14,  2.50it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Epoch 13:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Epoch 13:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Epoch 13:  84%|████████▍ | 158/187 [01:01<00:11,  2.57it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Epoch 13:  86%|████████▌ | 160/187 [01:01<00:10,  2.58it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Epoch 13:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:05,  4.76it/s]\u001b[A\n",
      "Epoch 13:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  5.10it/s]\u001b[A\n",
      "Epoch 13:  89%|████████▉ | 166/187 [01:02<00:07,  2.64it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.29it/s]\u001b[A\n",
      "Epoch 13:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.36it/s]\u001b[A\n",
      "Epoch 13:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  57%|█████▋    | 21/37 [00:03<00:02,  5.40it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 172/187 [01:04<00:05,  2.69it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.42it/s]\u001b[A\n",
      "Epoch 13:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.44it/s]\u001b[A\n",
      "Epoch 13:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.37it/s]\u001b[A\n",
      "Epoch 13:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.43it/s]\u001b[A\n",
      "Epoch 13:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.46it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 182/187 [01:05<00:01,  2.77it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.47it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.46it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 186/187 [01:06<00:00,  2.80it/s, loss=0.015, val_loss_step=0.0179, train_loss_step=0.0174, val_loss_epoch=0.0203, train_loss_epoch=0.0153]\n",
      "Epoch 13: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0174, val_loss_epoch=0.0193, train_loss_epoch=0.0153]\n",
      "Epoch 14:  80%|████████  | 150/187 [01:01<00:15,  2.44it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  81%|████████▏ | 152/187 [01:01<00:14,  2.45it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  82%|████████▏ | 154/187 [01:02<00:13,  2.47it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  83%|████████▎ | 156/187 [01:02<00:12,  2.49it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  84%|████████▍ | 158/187 [01:03<00:11,  2.51it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  86%|████████▌ | 160/187 [01:03<00:10,  2.52it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  87%|████████▋ | 162/187 [01:03<00:09,  2.54it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:05,  4.52it/s]\u001b[A\n",
      "Epoch 14:  88%|████████▊ | 164/187 [01:04<00:08,  2.56it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Validating:  41%|████      | 15/37 [00:03<00:04,  4.75it/s]\u001b[A\n",
      "Epoch 14:  89%|████████▉ | 166/187 [01:04<00:08,  2.57it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:04,  4.83it/s]\u001b[A\n",
      "Epoch 14:  90%|████████▉ | 168/187 [01:04<00:07,  2.59it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  91%|█████████ | 170/187 [01:05<00:06,  2.60it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  92%|█████████▏| 172/187 [01:05<00:05,  2.62it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.20it/s]\u001b[A\n",
      "Epoch 14:  93%|█████████▎| 174/187 [01:06<00:04,  2.64it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  94%|█████████▍| 176/187 [01:06<00:04,  2.65it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.28it/s]\u001b[A\n",
      "Epoch 14:  95%|█████████▌| 178/187 [01:06<00:03,  2.67it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  96%|█████████▋| 180/187 [01:07<00:02,  2.68it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  97%|█████████▋| 182/187 [01:07<00:01,  2.70it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14:  98%|█████████▊| 184/187 [01:07<00:01,  2.71it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.49it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▉| 186/187 [01:08<00:00,  2.73it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0163, val_loss_epoch=0.0193, train_loss_epoch=0.0151]\n",
      "Epoch 14: 100%|██████████| 187/187 [01:08<00:00,  2.73it/s, loss=0.015, val_loss_step=0.015, train_loss_step=0.0163, val_loss_epoch=0.0177, train_loss_epoch=0.0151] \n",
      "Epoch 15:  80%|████████  | 150/187 [01:01<00:15,  2.44it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  81%|████████▏ | 152/187 [01:02<00:14,  2.45it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:14,  2.39it/s]\u001b[A\n",
      "Epoch 15:  82%|████████▏ | 154/187 [01:02<00:13,  2.46it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:09,  3.29it/s]\u001b[A\n",
      "Epoch 15:  83%|████████▎ | 156/187 [01:02<00:12,  2.48it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:07,  3.97it/s]\u001b[A\n",
      "Epoch 15:  84%|████████▍ | 158/187 [01:03<00:11,  2.50it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.53it/s]\u001b[A\n",
      "Epoch 15:  86%|████████▌ | 160/187 [01:03<00:10,  2.51it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.91it/s]\u001b[A\n",
      "Epoch 15:  87%|████████▋ | 162/187 [01:03<00:09,  2.53it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  5.15it/s]\u001b[A\n",
      "Epoch 15:  88%|████████▊ | 164/187 [01:04<00:09,  2.55it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  41%|████      | 15/37 [00:03<00:04,  5.16it/s]\u001b[A\n",
      "Epoch 15:  89%|████████▉ | 166/187 [01:04<00:08,  2.57it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.26it/s]\u001b[A\n",
      "Epoch 15:  90%|████████▉ | 168/187 [01:05<00:07,  2.58it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.31it/s]\u001b[A\n",
      "Epoch 15:  91%|█████████ | 170/187 [01:05<00:06,  2.60it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  57%|█████▋    | 21/37 [00:04<00:03,  5.28it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 172/187 [01:05<00:05,  2.61it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.24it/s]\u001b[A\n",
      "Epoch 15:  93%|█████████▎| 174/187 [01:06<00:04,  2.63it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.37it/s]\u001b[A\n",
      "Epoch 15:  94%|█████████▍| 176/187 [01:06<00:04,  2.65it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.29it/s]\u001b[A\n",
      "Epoch 15:  95%|█████████▌| 178/187 [01:06<00:03,  2.66it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.41it/s]\u001b[A\n",
      "Epoch 15:  96%|█████████▋| 180/187 [01:07<00:02,  2.68it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.43it/s]\u001b[A\n",
      "Epoch 15:  97%|█████████▋| 182/187 [01:07<00:01,  2.69it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.44it/s]\u001b[A\n",
      "Epoch 15:  98%|█████████▊| 184/187 [01:07<00:01,  2.71it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.46it/s]\u001b[A\n",
      "Epoch 15:  99%|█████████▉| 186/187 [01:08<00:00,  2.72it/s, loss=0.016, val_loss_step=0.015, train_loss_step=0.0338, val_loss_epoch=0.0177, train_loss_epoch=0.0149]\n",
      "Epoch 15: 100%|██████████| 187/187 [01:08<00:00,  2.73it/s, loss=0.016, val_loss_step=0.0165, train_loss_step=0.0338, val_loss_epoch=0.0194, train_loss_epoch=0.0149]\n",
      "Epoch 16:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:07,  3.97it/s]\u001b[A\n",
      "Epoch 16:  86%|████████▌ | 160/187 [01:02<00:10,  2.58it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.35it/s]\u001b[A\n",
      "Epoch 16:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Validating:  57%|█████▋    | 21/37 [00:03<00:02,  5.54it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.45it/s]\u001b[A\n",
      "Epoch 16:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.36it/s]\u001b[A\n",
      "Epoch 16:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.50it/s]\u001b[A\n",
      "Epoch 16:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.63it/s]\u001b[A\n",
      "Epoch 16:  99%|█████████▉| 186/187 [01:06<00:00,  2.79it/s, loss=0.015, val_loss_step=0.0165, train_loss_step=0.0171, val_loss_epoch=0.0194, train_loss_epoch=0.0148]\n",
      "Epoch 16: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.015, val_loss_step=0.014, train_loss_step=0.0171, val_loss_epoch=0.0165, train_loss_epoch=0.0148] \n",
      "Epoch 17:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  81%|████████▏ | 152/187 [01:00<00:14,  2.50it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.46it/s]\u001b[A\n",
      "Epoch 17:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:09,  3.39it/s]\u001b[A\n",
      "Epoch 17:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:07,  4.15it/s]\u001b[A\n",
      "Epoch 17:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 17:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Epoch 17:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  5.06it/s]\u001b[A\n",
      "Epoch 17:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Epoch 17:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.24it/s]\u001b[A\n",
      "Epoch 17:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Epoch 17:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Epoch 17:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Epoch 17:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Epoch 17:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.51it/s]\u001b[A\n",
      "Epoch 17:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.32it/s]\u001b[A\n",
      "Epoch 17:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.24it/s]\u001b[A\n",
      "Epoch 17:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Epoch 17:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0153, val_loss_epoch=0.0165, train_loss_epoch=0.0145]\n",
      "Epoch 17: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0153, val_loss_epoch=0.0163, train_loss_epoch=0.0145]\n",
      "Epoch 18:  80%|████████  | 150/187 [00:59<00:14,  2.50it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  81%|████████▏ | 152/187 [01:00<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18:  82%|████████▏ | 154/187 [01:00<00:13,  2.53it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:10,  3.12it/s]\u001b[A\n",
      "Epoch 18:  83%|████████▎ | 156/187 [01:01<00:12,  2.55it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.34it/s]\u001b[A\n",
      "Epoch 18:  86%|████████▌ | 160/187 [01:01<00:10,  2.58it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18:  87%|████████▋ | 162/187 [01:02<00:09,  2.60it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.99it/s]\u001b[A\n",
      "Epoch 18:  88%|████████▊ | 164/187 [01:02<00:08,  2.62it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Validating:  41%|████      | 15/37 [00:02<00:04,  4.83it/s]\u001b[A\n",
      "Epoch 18:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18:  90%|████████▉ | 168/187 [01:03<00:07,  2.65it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18:  91%|█████████ | 170/187 [01:03<00:06,  2.67it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Validating:  57%|█████▋    | 21/37 [00:03<00:02,  5.54it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18:  93%|█████████▎| 174/187 [01:04<00:04,  2.70it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18:  94%|█████████▍| 176/187 [01:04<00:04,  2.72it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.56it/s]\u001b[A\n",
      "Epoch 18:  95%|█████████▌| 178/187 [01:05<00:03,  2.73it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.40it/s]\u001b[A\n",
      "Epoch 18:  96%|█████████▋| 180/187 [01:05<00:02,  2.75it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18:  97%|█████████▋| 182/187 [01:05<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.47it/s]\u001b[A\n",
      "Epoch 18:  98%|█████████▊| 184/187 [01:06<00:01,  2.78it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18:  99%|█████████▉| 186/187 [01:06<00:00,  2.80it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00916, val_loss_epoch=0.0163, train_loss_epoch=0.0142]\n",
      "Epoch 18: 100%|██████████| 187/187 [01:06<00:00,  2.80it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.00916, val_loss_epoch=0.0164, train_loss_epoch=0.0142]\n",
      "Epoch 19:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  81%|████████▏ | 152/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  83%|████████▎ | 156/187 [01:01<00:12,  2.53it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  84%|████████▍ | 158/187 [01:02<00:11,  2.55it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:07,  3.94it/s]\u001b[A\n",
      "Epoch 19:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.48it/s]\u001b[A\n",
      "Epoch 19:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.81it/s]\u001b[A\n",
      "Epoch 19:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.25it/s]\u001b[A\n",
      "Epoch 19:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.40it/s]\u001b[A\n",
      "Epoch 19:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19:  99%|█████████▉| 186/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0141, train_loss_step=0.0172, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 19: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0172, val_loss_epoch=0.0162, train_loss_epoch=0.0141]\n",
      "Epoch 20:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.61it/s]\u001b[A\n",
      "Epoch 20:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:07,  3.97it/s]\u001b[A\n",
      "Epoch 20:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 20:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.88it/s]\u001b[A\n",
      "Epoch 20:  87%|████████▋ | 162/187 [01:02<00:09,  2.57it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  4.98it/s]\u001b[A\n",
      "Epoch 20:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.18it/s]\u001b[A\n",
      "Epoch 20:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  57%|█████▋    | 21/37 [00:04<00:03,  5.13it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.17it/s]\u001b[A\n",
      "Epoch 20:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.31it/s]\u001b[A\n",
      "Epoch 20:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.24it/s]\u001b[A\n",
      "Epoch 20:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.24it/s]\u001b[A\n",
      "Epoch 20:  99%|█████████▉| 186/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0162, train_loss_epoch=0.014]\n",
      "Epoch 20: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.00965, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.45it/s]\u001b[A\n",
      "Epoch 21:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:09,  3.31it/s]\u001b[A\n",
      "Epoch 21:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:07,  3.97it/s]\u001b[A\n",
      "Epoch 21:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.82it/s]\u001b[A\n",
      "Epoch 21:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  5.02it/s]\u001b[A\n",
      "Epoch 21:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  41%|████      | 15/37 [00:03<00:04,  5.08it/s]\u001b[A\n",
      "Epoch 21:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.48it/s]\u001b[A\n",
      "Epoch 21:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21:  99%|█████████▉| 186/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0139, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 21: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0115, val_loss_epoch=0.0163, train_loss_epoch=0.014] \n",
      "Epoch 22:  80%|████████  | 150/187 [01:00<00:14,  2.49it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.46it/s]\u001b[A\n",
      "Epoch 22:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:09,  3.38it/s]\u001b[A\n",
      "Epoch 22:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 22:  84%|████████▍ | 158/187 [01:01<00:11,  2.55it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:06,  4.41it/s]\u001b[A\n",
      "Epoch 22:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.76it/s]\u001b[A\n",
      "Epoch 22:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 22:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  41%|████      | 15/37 [00:03<00:04,  5.15it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 166/187 [01:03<00:08,  2.62it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 22:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 22:  91%|█████████ | 170/187 [01:04<00:06,  2.66it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  57%|█████▋    | 21/37 [00:04<00:02,  5.39it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 172/187 [01:04<00:05,  2.67it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.27it/s]\u001b[A\n",
      "Epoch 22:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.22it/s]\u001b[A\n",
      "Epoch 22:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.22it/s]\u001b[A\n",
      "Epoch 22:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.18it/s]\u001b[A\n",
      "Epoch 22:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.18it/s]\u001b[A\n",
      "Epoch 22:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.17it/s]\u001b[A\n",
      "Epoch 22:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 22:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.014, val_loss_step=0.014, train_loss_step=0.0201, val_loss_epoch=0.0163, train_loss_epoch=0.014]\n",
      "Epoch 22: 100%|██████████| 187/187 [01:07<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0142, train_loss_step=0.0201, val_loss_epoch=0.0164, train_loss_epoch=0.014]\n",
      "Epoch 23:  80%|████████  | 150/187 [01:00<00:14,  2.48it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:13,  2.57it/s]\u001b[A\n",
      "Epoch 23:  82%|████████▏ | 154/187 [01:01<00:13,  2.51it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  19%|█▉        | 7/37 [00:01<00:07,  3.97it/s]\u001b[A\n",
      "Epoch 23:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  24%|██▍       | 9/37 [00:01<00:05,  4.76it/s]\u001b[A\n",
      "Epoch 23:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  87%|████████▋ | 162/187 [01:02<00:09,  2.58it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  5.23it/s]\u001b[A\n",
      "Epoch 23:  88%|████████▊ | 164/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  90%|████████▉ | 168/187 [01:03<00:07,  2.63it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  91%|█████████ | 170/187 [01:04<00:06,  2.65it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  92%|█████████▏| 172/187 [01:04<00:05,  2.66it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  93%|█████████▎| 174/187 [01:04<00:04,  2.68it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.62it/s]\u001b[A\n",
      "Epoch 23:  94%|█████████▍| 176/187 [01:05<00:04,  2.70it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.44it/s]\u001b[A\n",
      "Epoch 23:  95%|█████████▌| 178/187 [01:05<00:03,  2.71it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  96%|█████████▋| 180/187 [01:05<00:02,  2.73it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  97%|█████████▋| 182/187 [01:06<00:01,  2.74it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23:  98%|█████████▊| 184/187 [01:06<00:01,  2.76it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  99%|█████████▉| 186/187 [01:07<00:00,  2.77it/s, loss=0.015, val_loss_step=0.0142, train_loss_step=0.0229, val_loss_epoch=0.0164, train_loss_epoch=0.0141]\n",
      "Epoch 23: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.015, val_loss_step=0.0174, train_loss_step=0.0229, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Epoch 24:  80%|████████  | 150/187 [01:00<00:14,  2.50it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  81%|████████▏ | 152/187 [01:00<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:   8%|▊         | 3/37 [00:00<00:14,  2.33it/s]\u001b[A\n",
      "Epoch 24:  82%|████████▏ | 154/187 [01:01<00:13,  2.52it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  14%|█▎        | 5/37 [00:01<00:09,  3.25it/s]\u001b[A\n",
      "Epoch 24:  83%|████████▎ | 156/187 [01:01<00:12,  2.54it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Epoch 24:  84%|████████▍ | 158/187 [01:01<00:11,  2.56it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Epoch 24:  86%|████████▌ | 160/187 [01:02<00:10,  2.57it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  30%|██▉       | 11/37 [00:02<00:05,  4.73it/s]\u001b[A\n",
      "Epoch 24:  87%|████████▋ | 162/187 [01:02<00:09,  2.59it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  35%|███▌      | 13/37 [00:02<00:04,  5.09it/s]\u001b[A\n",
      "Epoch 24:  88%|████████▊ | 164/187 [01:02<00:08,  2.61it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  41%|████      | 15/37 [00:03<00:04,  5.25it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 166/187 [01:03<00:07,  2.63it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  46%|████▌     | 17/37 [00:03<00:03,  5.35it/s]\u001b[A\n",
      "Epoch 24:  90%|████████▉ | 168/187 [01:03<00:07,  2.64it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  51%|█████▏    | 19/37 [00:03<00:03,  5.38it/s]\u001b[A\n",
      "Epoch 24:  91%|█████████ | 170/187 [01:03<00:06,  2.66it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  57%|█████▋    | 21/37 [00:04<00:02,  5.42it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 172/187 [01:04<00:05,  2.68it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  62%|██████▏   | 23/37 [00:04<00:02,  5.43it/s]\u001b[A\n",
      "Epoch 24:  93%|█████████▎| 174/187 [01:04<00:04,  2.69it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  68%|██████▊   | 25/37 [00:04<00:02,  5.43it/s]\u001b[A\n",
      "Epoch 24:  94%|█████████▍| 176/187 [01:04<00:04,  2.71it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  73%|███████▎  | 27/37 [00:05<00:01,  5.45it/s]\u001b[A\n",
      "Epoch 24:  95%|█████████▌| 178/187 [01:05<00:03,  2.72it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  78%|███████▊  | 29/37 [00:05<00:01,  5.47it/s]\u001b[A\n",
      "Epoch 24:  96%|█████████▋| 180/187 [01:05<00:02,  2.74it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  84%|████████▍ | 31/37 [00:05<00:01,  5.49it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 182/187 [01:06<00:01,  2.75it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  89%|████████▉ | 33/37 [00:06<00:00,  5.55it/s]\u001b[A\n",
      "Epoch 24:  98%|█████████▊| 184/187 [01:06<00:01,  2.77it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Validating:  95%|█████████▍| 35/37 [00:06<00:00,  5.58it/s]\u001b[A\n",
      "Epoch 24:  99%|█████████▉| 186/187 [01:06<00:00,  2.78it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0131, val_loss_epoch=0.0204, train_loss_epoch=0.0141]\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.014, val_loss_step=0.0152, train_loss_step=0.0131, val_loss_epoch=0.0179, train_loss_epoch=0.0141]\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.79it/s, loss=0.014, val_loss_step=0.0152, train_loss_step=0.0131, val_loss_epoch=0.0179, train_loss_epoch=0.0141]\n",
      "Test iterations: 69\n",
      "Testing:  99%|█████████▊| 68/69 [00:12<00:00,  6.02it/s]Logits: tensor([[ -6.9141,  -7.2266,  -7.2266,  ...,  -6.2383,  -7.4102,  -6.3516],\n",
      "        [ -7.3945,  -7.8477,  -6.7539,  ...,  -7.1211,  -7.6055,  -7.5039],\n",
      "        [-11.0312, -10.8516,  -6.6719,  ...,  -6.1211,  -5.9414,  -5.4219],\n",
      "        ...,\n",
      "        [ -6.8672,  -7.5625,  -6.8984,  ...,  -6.1172,  -7.7930,  -6.3867],\n",
      "        [ -7.2656,  -8.0938,  -7.2266,  ...,  -5.7695,  -8.6094,  -6.4219],\n",
      "        [ -6.6328,  -7.1328,  -6.5938,  ...,  -5.9414,  -7.8008,  -6.5742]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[9.928e-04 7.267e-04 7.267e-04 ... 1.949e-03 6.046e-04 1.741e-03]\n",
      " [6.142e-04 3.905e-04 1.165e-03 ... 8.073e-04 4.973e-04 5.507e-04]\n",
      " [1.621e-05 1.937e-05 1.265e-03 ... 2.192e-03 2.621e-03 4.398e-03]\n",
      " ...\n",
      " [1.040e-03 5.193e-04 1.008e-03 ... 2.199e-03 4.125e-04 1.681e-03]\n",
      " [6.986e-04 3.054e-04 7.267e-04 ... 3.111e-03 1.824e-04 1.623e-03]\n",
      " [1.315e-03 7.977e-04 1.367e-03 ... 2.621e-03 4.094e-04 1.394e-03]]\n",
      "Testing: 100%|██████████| 69/69 [00:12<00:00,  5.68it/s]\n",
      "==================== Fold 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | backbone | GenEfficientNet | 4 M   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: 0.001000\n",
      "Validate iterations: 38\n",
      "Train iterations: 149                                                 \n",
      "Epoch 0:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Epoch 0:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.35it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.29it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.97it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Epoch 0:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.37it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.55it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.65it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.72it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.72it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.71it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 172/187 [01:05<00:05,  2.65it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.58it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.65it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.70it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.70it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.73it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.75it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.71it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 186/187 [01:07<00:00,  2.75it/s, loss=0.019, val_loss_step=0.69, train_loss_step=0.0198]\n",
      "Epoch 0: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0198, val_loss_epoch=0.0218]\n",
      "Epoch 1:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 150/187 [01:00<00:14,  2.47it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.31it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.09it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.65it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  6.00it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:01,  6.06it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.96it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 1:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.10it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.019, val_loss_step=0.0209, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.98it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.019, val_loss_step=0.0211, train_loss_step=0.0187, val_loss_epoch=0.0218, train_loss_epoch=0.0378]\n",
      "Epoch 2:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.68it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.57it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.07it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.92it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.99it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 176/187 [01:05<00:04,  2.67it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.92it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:00,  6.14it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.018, val_loss_step=0.0211, train_loss_step=0.0171, val_loss_epoch=0.0218, train_loss_epoch=0.0192]\n",
      "Epoch 2: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0171, val_loss_epoch=0.103, train_loss_epoch=0.0192]  \n",
      "Epoch 3:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 150/187 [01:01<00:15,  2.46it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Epoch 3:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.31it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.25it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.97it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Epoch 3:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.36it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.54it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.64it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.68it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.71it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.70it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.73it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.75it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.76it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.71it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.69it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.64it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.61it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 186/187 [01:07<00:00,  2.75it/s, loss=0.018, val_loss_step=0.105, train_loss_step=0.0185, val_loss_epoch=0.103, train_loss_epoch=0.0184]\n",
      "Epoch 3: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.018, val_loss_step=0.0305, train_loss_step=0.0185, val_loss_epoch=0.0304, train_loss_epoch=0.0184]\n",
      "Epoch 4:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Epoch 4:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.71it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Epoch 4:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Epoch 4:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.32it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.62it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.72it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.73it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.92it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.93it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 172/187 [01:05<00:05,  2.65it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.90it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Epoch 4:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.88it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.01it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.97it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Epoch 4:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.98it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 186/187 [01:07<00:00,  2.75it/s, loss=0.017, val_loss_step=0.0305, train_loss_step=0.0151, val_loss_epoch=0.0304, train_loss_epoch=0.0176]\n",
      "Epoch 4: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0151, val_loss_epoch=0.0993, train_loss_epoch=0.0176] \n",
      "Epoch 5:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Epoch 5:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.30it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Epoch 5:  83%|████████▎ | 156/187 [01:02<00:12,  2.52it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Epoch 5:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Epoch 5:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Epoch 5:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.62it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Epoch 5:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Epoch 5:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.97it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.55it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.63it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.65it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.68it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.68it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.67it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.70it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.017, val_loss_step=0.105, train_loss_step=0.0196, val_loss_epoch=0.0993, train_loss_epoch=0.017]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.66it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.017, val_loss_step=0.0376, train_loss_step=0.0196, val_loss_epoch=0.0355, train_loss_epoch=0.017]\n",
      "Epoch 6:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:13,  2.76it/s]\u001b[A\n",
      "Epoch 6:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Epoch 6:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Epoch 6:  83%|████████▎ | 156/187 [01:02<00:12,  2.52it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.80it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.31it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.60it/s]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.77it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:04,  5.46it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.67it/s]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.71it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.73it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.75it/s]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.76it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.73it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 178/187 [01:06<00:03,  2.70it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.76it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.72it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.73it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.73it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 186/187 [01:07<00:00,  2.76it/s, loss=0.016, val_loss_step=0.0376, train_loss_step=0.0162, val_loss_epoch=0.0355, train_loss_epoch=0.0167]\n",
      "Epoch 6: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0162, val_loss_epoch=0.0393, train_loss_epoch=0.0167]\n",
      "Epoch 7:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Epoch 7:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.19it/s]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Epoch 7:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.65it/s]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.25it/s]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.55it/s]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Epoch 7:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.94it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.92it/s]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Epoch 7:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.04it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.97it/s]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.93it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.92it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.93it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.03it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 186/187 [01:07<00:00,  2.76it/s, loss=0.016, val_loss_step=0.0416, train_loss_step=0.0132, val_loss_epoch=0.0393, train_loss_epoch=0.0164]\n",
      "Epoch 7: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0164]\n",
      "Epoch 8:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.70it/s]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.93it/s]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.98it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  94%|█████████▍| 176/187 [01:05<00:04,  2.67it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.07it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.93it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▋| 180/187 [01:06<00:02,  2.70it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8:  98%|█████████▊| 184/187 [01:07<00:01,  2.73it/s, loss=0.016, val_loss_step=0.0195, train_loss_step=0.0132, val_loss_epoch=0.0199, train_loss_epoch=0.0162]\n",
      "Epoch 8: 100%|██████████| 187/187 [01:07<00:00,  2.75it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0132, val_loss_epoch=0.0189, train_loss_epoch=0.0162]\n",
      "Epoch 9:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  80%|████████  | 150/187 [01:01<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Epoch 9:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.13it/s]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.13it/s]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.81it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.27it/s]\u001b[A\n",
      "Epoch 9:  86%|████████▌ | 160/187 [01:02<00:10,  2.54it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Epoch 9:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.61it/s]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Epoch 9:  89%|████████▉ | 166/187 [01:04<00:08,  2.59it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.88it/s]\u001b[A\n",
      "Epoch 9:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.77it/s]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 170/187 [01:04<00:06,  2.62it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.71it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.66it/s]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 174/187 [01:05<00:04,  2.65it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.68it/s]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 176/187 [01:05<00:04,  2.67it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.69it/s]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 178/187 [01:06<00:03,  2.68it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Epoch 9:  96%|█████████▋| 180/187 [01:06<00:02,  2.70it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  6.00it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 182/187 [01:07<00:01,  2.71it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n",
      "Epoch 9:  98%|█████████▊| 184/187 [01:07<00:01,  2.73it/s, loss=0.016, val_loss_step=0.0188, train_loss_step=0.0154, val_loss_epoch=0.0189, train_loss_epoch=0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.08it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 187/187 [01:07<00:00,  2.75it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0154, val_loss_epoch=0.0892, train_loss_epoch=0.016]\n",
      "Epoch 10:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:13,  2.71it/s]\u001b[A\n",
      "Epoch 10:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Epoch 10:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.29it/s]\u001b[A\n",
      "Epoch 10:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.97it/s]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.39it/s]\u001b[A\n",
      "Epoch 10:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.60it/s]\u001b[A\n",
      "Epoch 10:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.68it/s]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.81it/s]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.53it/s]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.63it/s]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.66it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 172/187 [01:05<00:05,  2.65it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.66it/s]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.71it/s]\u001b[A\n",
      "Epoch 10:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.69it/s]\u001b[A\n",
      "Epoch 10:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.67it/s]\u001b[A\n",
      "Epoch 10:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.70it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.66it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.016, val_loss_step=0.0864, train_loss_step=0.0164, val_loss_epoch=0.0892, train_loss_epoch=0.0158]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.69it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0164, val_loss_epoch=0.0643, train_loss_epoch=0.0158] \n",
      "Epoch 11:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  80%|████████  | 150/187 [01:00<00:15,  2.47it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:14,  2.54it/s]\u001b[A\n",
      "Epoch 11:  81%|████████▏ | 152/187 [01:01<00:14,  2.49it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Epoch 11:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Epoch 11:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.72it/s]\u001b[A\n",
      "Epoch 11:  84%|████████▍ | 158/187 [01:02<00:11,  2.54it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Epoch 11:  86%|████████▌ | 160/187 [01:02<00:10,  2.56it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.54it/s]\u001b[A\n",
      "Epoch 11:  87%|████████▋ | 162/187 [01:02<00:09,  2.57it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.44it/s]\u001b[A\n",
      "Epoch 11:  88%|████████▊ | 164/187 [01:03<00:08,  2.59it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.60it/s]\u001b[A\n",
      "Epoch 11:  89%|████████▉ | 166/187 [01:03<00:08,  2.61it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.68it/s]\u001b[A\n",
      "Epoch 11:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.70it/s]\u001b[A\n",
      "Epoch 11:  91%|█████████ | 170/187 [01:04<00:06,  2.64it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.64it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.75it/s]\u001b[A\n",
      "Epoch 11:  93%|█████████▎| 174/187 [01:05<00:04,  2.67it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.74it/s]\u001b[A\n",
      "Epoch 11:  94%|█████████▍| 176/187 [01:05<00:04,  2.69it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.76it/s]\u001b[A\n",
      "Epoch 11:  95%|█████████▌| 178/187 [01:05<00:03,  2.70it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  96%|█████████▋| 180/187 [01:06<00:02,  2.72it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.73it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.69it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 184/187 [01:06<00:01,  2.75it/s, loss=0.016, val_loss_step=0.061, train_loss_step=0.0147, val_loss_epoch=0.0643, train_loss_epoch=0.0156]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.65it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 187/187 [01:07<00:00,  2.77it/s, loss=0.016, val_loss_step=0.0431, train_loss_step=0.0147, val_loss_epoch=0.0441, train_loss_epoch=0.0156]\n",
      "Epoch 12:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  80%|████████  | 150/187 [01:01<00:15,  2.45it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  81%|████████▏ | 152/187 [01:01<00:14,  2.47it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.15it/s]\u001b[A\n",
      "Epoch 12:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.61it/s]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 158/187 [01:02<00:11,  2.52it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  86%|████████▌ | 160/187 [01:02<00:10,  2.54it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.43it/s]\u001b[A\n",
      "Epoch 12:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  88%|████████▊ | 164/187 [01:03<00:08,  2.57it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.78it/s]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 166/187 [01:04<00:08,  2.59it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  91%|█████████ | 170/187 [01:04<00:06,  2.62it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  6.02it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  93%|█████████▎| 174/187 [01:05<00:04,  2.65it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:01,  6.04it/s]\u001b[A\n",
      "Epoch 12:  94%|█████████▍| 176/187 [01:05<00:04,  2.67it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  95%|█████████▌| 178/187 [01:06<00:03,  2.68it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  96%|█████████▋| 180/187 [01:06<00:02,  2.70it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  97%|█████████▋| 182/187 [01:07<00:01,  2.71it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Epoch 12:  98%|█████████▊| 184/187 [01:07<00:01,  2.73it/s, loss=0.015, val_loss_step=0.0431, train_loss_step=0.0112, val_loss_epoch=0.0441, train_loss_epoch=0.0154]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  6.20it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 187/187 [01:07<00:00,  2.75it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0112, val_loss_epoch=0.0329, train_loss_epoch=0.0154] \n",
      "Epoch 13:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.25it/s]\u001b[A\n",
      "Epoch 13:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.03it/s]\u001b[A\n",
      "Epoch 13:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.46it/s]\u001b[A\n",
      "Epoch 13:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.67it/s]\u001b[A\n",
      "Epoch 13:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.04it/s]\u001b[A\n",
      "Epoch 13:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.04it/s]\u001b[A\n",
      "Epoch 13:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.05it/s]\u001b[A\n",
      "Epoch 13:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.78it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 186/187 [01:07<00:00,  2.75it/s, loss=0.015, val_loss_step=0.032, train_loss_step=0.0158, val_loss_epoch=0.0329, train_loss_epoch=0.0151]\n",
      "Epoch 13: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0158, val_loss_epoch=0.0174, train_loss_epoch=0.0151]\n",
      "Epoch 14:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Epoch 14:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Epoch 14:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.74it/s]\u001b[A\n",
      "Epoch 14:  83%|████████▎ | 156/187 [01:02<00:12,  2.52it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.41it/s]\u001b[A\n",
      "Epoch 14:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.00it/s]\u001b[A\n",
      "Epoch 14:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.35it/s]\u001b[A\n",
      "Epoch 14:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.53it/s]\u001b[A\n",
      "Epoch 14:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.61it/s]\u001b[A\n",
      "Epoch 14:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.68it/s]\u001b[A\n",
      "Epoch 14:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.69it/s]\u001b[A\n",
      "Epoch 14:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.73it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.73it/s]\u001b[A\n",
      "Epoch 14:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.73it/s]\u001b[A\n",
      "Epoch 14:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.75it/s]\u001b[A\n",
      "Epoch 14:  95%|█████████▌| 178/187 [01:06<00:03,  2.70it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.74it/s]\u001b[A\n",
      "Epoch 14:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.72it/s]\u001b[A\n",
      "Epoch 14:  97%|█████████▋| 182/187 [01:06<00:01,  2.73it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.69it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.015, val_loss_step=0.0192, train_loss_step=0.0145, val_loss_epoch=0.0174, train_loss_epoch=0.015]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.65it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.015, val_loss_step=0.0187, train_loss_step=0.0145, val_loss_epoch=0.021, train_loss_epoch=0.015] \n",
      "Epoch 15:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:13,  2.73it/s]\u001b[A\n",
      "Epoch 15:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Epoch 15:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Epoch 15:  83%|████████▎ | 156/187 [01:02<00:12,  2.52it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Epoch 15:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Epoch 15:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Epoch 15:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Epoch 15:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.67it/s]\u001b[A\n",
      "Epoch 15:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.81it/s]\u001b[A\n",
      "Epoch 15:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.72it/s]\u001b[A\n",
      "Epoch 15:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.67it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Epoch 15:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Epoch 15:  94%|█████████▍| 176/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.90it/s]\u001b[A\n",
      "Epoch 15:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.76it/s]\u001b[A\n",
      "Epoch 15:  96%|█████████▋| 180/187 [01:06<00:02,  2.70it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.78it/s]\u001b[A\n",
      "Epoch 15:  98%|█████████▊| 184/187 [01:07<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0187, train_loss_step=0.015, val_loss_epoch=0.021, train_loss_epoch=0.0147]\n",
      "Epoch 15: 100%|██████████| 187/187 [01:07<00:00,  2.75it/s, loss=0.014, val_loss_step=0.0239, train_loss_step=0.015, val_loss_epoch=0.0254, train_loss_epoch=0.0147]\n",
      "Epoch 16:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  80%|████████  | 150/187 [01:01<00:15,  2.45it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Epoch 16:  81%|████████▏ | 152/187 [01:01<00:14,  2.47it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Epoch 16:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.83it/s]\u001b[A\n",
      "Epoch 16:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.63it/s]\u001b[A\n",
      "Epoch 16:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Epoch 16:  86%|████████▌ | 160/187 [01:02<00:10,  2.54it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.25it/s]\u001b[A\n",
      "Epoch 16:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.51it/s]\u001b[A\n",
      "Epoch 16:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.62it/s]\u001b[A\n",
      "Epoch 16:  89%|████████▉ | 166/187 [01:04<00:08,  2.59it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.71it/s]\u001b[A\n",
      "Epoch 16:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.74it/s]\u001b[A\n",
      "Epoch 16:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.74it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.75it/s]\u001b[A\n",
      "Epoch 16:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.76it/s]\u001b[A\n",
      "Epoch 16:  94%|█████████▍| 176/187 [01:05<00:04,  2.67it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.73it/s]\u001b[A\n",
      "Epoch 16:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.74it/s]\u001b[A\n",
      "Epoch 16:  96%|█████████▋| 180/187 [01:06<00:02,  2.70it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.74it/s]\u001b[A\n",
      "Epoch 16:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.75it/s]\u001b[A\n",
      "Epoch 16:  98%|█████████▊| 184/187 [01:07<00:01,  2.73it/s, loss=0.015, val_loss_step=0.0239, train_loss_step=0.0167, val_loss_epoch=0.0254, train_loss_epoch=0.0144]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.71it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 187/187 [01:07<00:00,  2.75it/s, loss=0.015, val_loss_step=0.0178, train_loss_step=0.0167, val_loss_epoch=0.0173, train_loss_epoch=0.0144]\n",
      "Epoch 17:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:13,  2.60it/s]\u001b[A\n",
      "Epoch 17:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:09,  3.65it/s]\u001b[A\n",
      "Epoch 17:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 17:  83%|████████▎ | 156/187 [01:02<00:12,  2.52it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:05,  5.13it/s]\u001b[A\n",
      "Epoch 17:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Epoch 17:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.72it/s]\u001b[A\n",
      "Epoch 17:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.80it/s]\u001b[A\n",
      "Epoch 17:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Epoch 17:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Epoch 17:  90%|████████▉ | 168/187 [01:04<00:07,  2.62it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.02it/s]\u001b[A\n",
      "Epoch 17:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.94it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 172/187 [01:04<00:05,  2.65it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.89it/s]\u001b[A\n",
      "Epoch 17:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Epoch 17:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Epoch 17:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  6.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.95it/s]\u001b[A\n",
      "Epoch 17:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.88it/s]\u001b[A\n",
      "Epoch 17:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0178, train_loss_step=0.0178, val_loss_epoch=0.0173, train_loss_epoch=0.0142]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.86it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0178, val_loss_epoch=0.0168, train_loss_epoch=0.0142]\n",
      "Epoch 18:  80%|███████▉  | 149/187 [01:01<00:15,  2.43it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  80%|████████  | 150/187 [01:01<00:15,  2.42it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18:  81%|████████▏ | 152/187 [01:02<00:14,  2.44it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18:  82%|████████▏ | 154/187 [01:02<00:13,  2.46it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.72it/s]\u001b[A\n",
      "Epoch 18:  83%|████████▎ | 156/187 [01:03<00:12,  2.48it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 18:  84%|████████▍ | 158/187 [01:03<00:11,  2.49it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.18it/s]\u001b[A\n",
      "Epoch 18:  86%|████████▌ | 160/187 [01:03<00:10,  2.51it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18:  87%|████████▋ | 162/187 [01:04<00:09,  2.53it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18:  88%|████████▊ | 164/187 [01:04<00:09,  2.54it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18:  89%|████████▉ | 166/187 [01:04<00:08,  2.56it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18:  90%|████████▉ | 168/187 [01:05<00:07,  2.58it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.09it/s]\u001b[A\n",
      "Epoch 18:  91%|█████████ | 170/187 [01:05<00:06,  2.59it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18:  92%|█████████▏| 172/187 [01:05<00:05,  2.61it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  6.05it/s]\u001b[A\n",
      "Epoch 18:  93%|█████████▎| 174/187 [01:06<00:04,  2.62it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:01,  6.02it/s]\u001b[A\n",
      "Epoch 18:  94%|█████████▍| 176/187 [01:06<00:04,  2.64it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18:  95%|█████████▌| 178/187 [01:07<00:03,  2.65it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18:  96%|█████████▋| 180/187 [01:07<00:02,  2.67it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:00,  6.18it/s]\u001b[A\n",
      "Epoch 18:  97%|█████████▋| 182/187 [01:07<00:01,  2.69it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.05it/s]\u001b[A\n",
      "Epoch 18:  98%|█████████▊| 184/187 [01:08<00:01,  2.70it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.92it/s]\u001b[A\n",
      "Epoch 18:  99%|█████████▉| 186/187 [01:08<00:00,  2.72it/s, loss=0.014, val_loss_step=0.0171, train_loss_step=0.0147, val_loss_epoch=0.0168, train_loss_epoch=0.014]\n",
      "Epoch 18: 100%|██████████| 187/187 [01:08<00:00,  2.72it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0147, val_loss_epoch=0.0166, train_loss_epoch=0.014]\n",
      "Epoch 19:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  80%|████████  | 150/187 [01:01<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:   5%|▌         | 2/38 [00:00<00:13,  2.73it/s]\u001b[A\n",
      "Epoch 19:  81%|████████▏ | 152/187 [01:01<00:14,  2.47it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:09,  3.76it/s]\u001b[A\n",
      "Epoch 19:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:06,  4.61it/s]\u001b[A\n",
      "Epoch 19:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:05,  5.16it/s]\u001b[A\n",
      "Epoch 19:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.49it/s]\u001b[A\n",
      "Epoch 19:  86%|████████▌ | 160/187 [01:02<00:10,  2.54it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.66it/s]\u001b[A\n",
      "Epoch 19:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.72it/s]\u001b[A\n",
      "Epoch 19:  88%|████████▊ | 164/187 [01:03<00:08,  2.57it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.67it/s]\u001b[A\n",
      "Epoch 19:  89%|████████▉ | 166/187 [01:04<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.84it/s]\u001b[A\n",
      "Epoch 19:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.84it/s]\u001b[A\n",
      "Epoch 19:  91%|█████████ | 170/187 [01:04<00:06,  2.62it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.50it/s]\u001b[A\n",
      "Epoch 19:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.57it/s]\u001b[A\n",
      "Epoch 19:  93%|█████████▎| 174/187 [01:05<00:04,  2.65it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  94%|█████████▍| 176/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.63it/s]\u001b[A\n",
      "Epoch 19:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.67it/s]\u001b[A\n",
      "Epoch 19:  96%|█████████▋| 180/187 [01:06<00:02,  2.70it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.65it/s]\u001b[A\n",
      "Epoch 19:  97%|█████████▋| 182/187 [01:07<00:01,  2.71it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.68it/s]\u001b[A\n",
      "Epoch 19:  98%|█████████▊| 184/187 [01:07<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0174, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.68it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 187/187 [01:07<00:00,  2.75it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0115, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Epoch 20:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  80%|████████  | 150/187 [01:01<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  81%|████████▏ | 152/187 [01:01<00:14,  2.47it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.14it/s]\u001b[A\n",
      "Epoch 20:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.02it/s]\u001b[A\n",
      "Epoch 20:  86%|████████▌ | 160/187 [01:02<00:10,  2.54it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.79it/s]\u001b[A\n",
      "Epoch 20:  89%|████████▉ | 166/187 [01:04<00:08,  2.59it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.73it/s]\u001b[A\n",
      "Epoch 20:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  94%|█████████▍| 176/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.16it/s]\u001b[A\n",
      "Epoch 20:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.98it/s]\u001b[A\n",
      "Epoch 20:  96%|█████████▋| 180/187 [01:06<00:02,  2.70it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.90it/s]\u001b[A\n",
      "Epoch 20:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 20:  98%|█████████▊| 184/187 [01:07<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.95it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 187/187 [01:07<00:00,  2.75it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0183, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 21:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  80%|████████  | 150/187 [01:00<00:15,  2.46it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 21:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 21:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.86it/s]\u001b[A\n",
      "Epoch 21:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.68it/s]\u001b[A\n",
      "Epoch 21:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.26it/s]\u001b[A\n",
      "Epoch 21:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  32%|███▏      | 12/38 [00:02<00:04,  5.59it/s]\u001b[A\n",
      "Epoch 21:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.75it/s]\u001b[A\n",
      "Epoch 21:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.86it/s]\u001b[A\n",
      "Epoch 21:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.89it/s]\u001b[A\n",
      "Epoch 21:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.89it/s]\u001b[A\n",
      "Epoch 21:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.93it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 172/187 [01:05<00:05,  2.65it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.91it/s]\u001b[A\n",
      "Epoch 21:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  68%|██████▊   | 26/38 [00:04<00:02,  5.91it/s]\u001b[A\n",
      "Epoch 21:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.83it/s]\u001b[A\n",
      "Epoch 21:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.94it/s]\u001b[A\n",
      "Epoch 21:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 21:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.05it/s]\u001b[A\n",
      "Epoch 21:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.90it/s]\u001b[A\n",
      "Epoch 21:  99%|█████████▉| 186/187 [01:07<00:00,  2.75it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 21: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.013, val_loss_step=0.0175, train_loss_step=0.0127, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 22:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  80%|████████  | 150/187 [01:01<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 22:  81%|████████▏ | 152/187 [01:01<00:14,  2.47it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.14it/s]\u001b[A\n",
      "Epoch 22:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:07,  4.09it/s]\u001b[A\n",
      "Epoch 22:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 22:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 22:  86%|████████▌ | 160/187 [01:02<00:10,  2.54it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 22:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.65it/s]\u001b[A\n",
      "Epoch 22:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.90it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  6.17it/s]\u001b[A\n",
      "Epoch 22:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:02,  6.03it/s]\u001b[A\n",
      "Epoch 22:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 22:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 22:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  68%|██████▊   | 26/38 [00:04<00:01,  6.18it/s]\u001b[A\n",
      "Epoch 22:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  6.08it/s]\u001b[A\n",
      "Epoch 22:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 22:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:00,  6.11it/s]\u001b[A\n",
      "Epoch 22:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  6.01it/s]\u001b[A\n",
      "Epoch 22:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.97it/s]\u001b[A\n",
      "Epoch 22:  99%|█████████▉| 186/187 [01:07<00:00,  2.75it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 22: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0145, val_loss_epoch=0.0166, train_loss_epoch=0.0137]\n",
      "Epoch 23:  80%|███████▉  | 149/187 [01:00<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  80%|████████  | 150/187 [01:01<00:15,  2.46it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Epoch 23:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  11%|█         | 4/38 [00:00<00:10,  3.34it/s]\u001b[A\n",
      "Epoch 23:  82%|████████▏ | 154/187 [01:01<00:13,  2.49it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Epoch 23:  83%|████████▎ | 156/187 [01:02<00:12,  2.51it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.73it/s]\u001b[A\n",
      "Epoch 23:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Epoch 23:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Epoch 23:  87%|████████▋ | 162/187 [01:03<00:09,  2.56it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.47it/s]\u001b[A\n",
      "Epoch 23:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:03,  5.60it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.66it/s]\u001b[A\n",
      "Epoch 23:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  53%|█████▎    | 20/38 [00:03<00:03,  5.51it/s]\u001b[A\n",
      "Epoch 23:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.71it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.74it/s]\u001b[A\n",
      "Epoch 23:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.72it/s]\u001b[A\n",
      "Epoch 23:  94%|█████████▍| 176/187 [01:05<00:04,  2.68it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.73it/s]\u001b[A\n",
      "Epoch 23:  95%|█████████▌| 178/187 [01:06<00:03,  2.69it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  79%|███████▉  | 30/38 [00:05<00:01,  5.76it/s]\u001b[A\n",
      "Epoch 23:  96%|█████████▋| 180/187 [01:06<00:02,  2.71it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.72it/s]\u001b[A\n",
      "Epoch 23:  97%|█████████▋| 182/187 [01:06<00:01,  2.72it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.73it/s]\u001b[A\n",
      "Epoch 23:  98%|█████████▊| 184/187 [01:07<00:01,  2.74it/s, loss=0.014, val_loss_step=0.0175, train_loss_step=0.0159, val_loss_epoch=0.0166, train_loss_epoch=0.0138]\n",
      "Validating:  95%|█████████▍| 36/38 [00:06<00:00,  5.69it/s]\u001b[A\n",
      "Epoch 23: 100%|██████████| 187/187 [01:07<00:00,  2.76it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0159, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Epoch 24:  80%|███████▉  | 149/187 [01:00<00:15,  2.47it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  80%|████████  | 150/187 [01:00<00:15,  2.47it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Epoch 24:  81%|████████▏ | 152/187 [01:01<00:14,  2.48it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Epoch 24:  82%|████████▏ | 154/187 [01:01<00:13,  2.50it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  16%|█▌        | 6/38 [00:01<00:08,  3.70it/s]\u001b[A\n",
      "Epoch 24:  83%|████████▎ | 156/187 [01:01<00:12,  2.52it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  21%|██        | 8/38 [00:01<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 24:  84%|████████▍ | 158/187 [01:02<00:11,  2.53it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  26%|██▋       | 10/38 [00:02<00:05,  5.00it/s]\u001b[A\n",
      "Epoch 24:  86%|████████▌ | 160/187 [01:02<00:10,  2.55it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Epoch 24:  87%|████████▋ | 162/187 [01:03<00:09,  2.57it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  37%|███▋      | 14/38 [00:02<00:04,  5.35it/s]\u001b[A\n",
      "Epoch 24:  88%|████████▊ | 164/187 [01:03<00:08,  2.58it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  42%|████▏     | 16/38 [00:03<00:04,  5.41it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 166/187 [01:03<00:08,  2.60it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  47%|████▋     | 18/38 [00:03<00:03,  5.41it/s]\u001b[A\n",
      "Epoch 24:  90%|████████▉ | 168/187 [01:04<00:07,  2.61it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  53%|█████▎    | 20/38 [00:04<00:03,  5.52it/s]\u001b[A\n",
      "Epoch 24:  91%|█████████ | 170/187 [01:04<00:06,  2.63it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  58%|█████▊    | 22/38 [00:04<00:02,  5.56it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 172/187 [01:05<00:05,  2.64it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  63%|██████▎   | 24/38 [00:04<00:02,  5.58it/s]\u001b[A\n",
      "Epoch 24:  93%|█████████▎| 174/187 [01:05<00:04,  2.66it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  68%|██████▊   | 26/38 [00:05<00:02,  5.60it/s]\u001b[A\n",
      "Epoch 24:  94%|█████████▍| 176/187 [01:05<00:04,  2.67it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  74%|███████▎  | 28/38 [00:05<00:01,  5.58it/s]\u001b[A\n",
      "Epoch 24:  95%|█████████▌| 178/187 [01:06<00:03,  2.68it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  79%|███████▉  | 30/38 [00:06<00:01,  5.61it/s]\u001b[A\n",
      "Epoch 24:  96%|█████████▋| 180/187 [01:06<00:02,  2.70it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  84%|████████▍ | 32/38 [00:06<00:01,  5.68it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 182/187 [01:07<00:01,  2.71it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  89%|████████▉ | 34/38 [00:06<00:00,  5.77it/s]\u001b[A\n",
      "Epoch 24:  98%|█████████▊| 184/187 [01:07<00:01,  2.73it/s, loss=0.014, val_loss_step=0.0176, train_loss_step=0.0136, val_loss_epoch=0.0168, train_loss_epoch=0.0138]\n",
      "Validating:  95%|█████████▍| 36/38 [00:07<00:00,  5.81it/s]\u001b[A\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.75it/s, loss=0.014, val_loss_step=0.0172, train_loss_step=0.0136, val_loss_epoch=0.0172, train_loss_epoch=0.0138]\n",
      "Epoch 24: 100%|██████████| 187/187 [01:07<00:00,  2.75it/s, loss=0.014, val_loss_step=0.0172, train_loss_step=0.0136, val_loss_epoch=0.0172, train_loss_epoch=0.0138]\n",
      "Test iterations: 69\n",
      "Testing:  99%|█████████▊| 68/69 [00:12<00:00,  5.46it/s]Logits: tensor([[ -4.3711,  -5.8125,  -8.4453,  ...,  -8.4688,  -8.5078,  -6.4492],\n",
      "        [ -5.9961,  -5.0234,  -9.3672,  ...,  -9.7500, -10.7344,  -7.6406],\n",
      "        [-12.4062, -12.9062,  -9.2500,  ..., -11.6641, -12.6953, -11.7109],\n",
      "        ...,\n",
      "        [ -5.1094,  -6.1406,  -8.0391,  ...,  -8.0859,  -7.9961,  -6.4688],\n",
      "        [ -5.3867,  -5.7227,  -8.0156,  ...,  -7.8906,  -8.6797,  -6.1289],\n",
      "        [ -6.0820,  -6.9961,  -7.1680,  ...,  -7.5625,  -7.1562,  -6.4375]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[1.248e-02 2.981e-03 2.148e-04 ... 2.099e-04 2.018e-04 1.579e-03]\n",
      " [2.481e-03 6.538e-03 8.547e-05 ... 5.829e-05 2.176e-05 4.804e-04]\n",
      " [4.113e-06 2.503e-06 9.608e-05 ... 8.583e-06 3.040e-06 8.225e-06]\n",
      " ...\n",
      " [6.004e-03 2.150e-03 3.226e-04 ... 3.078e-04 3.366e-04 1.549e-03]\n",
      " [4.555e-03 3.260e-03 3.302e-04 ... 3.741e-04 1.700e-04 2.174e-03]\n",
      " [2.279e-03 9.146e-04 7.701e-04 ... 5.193e-04 7.792e-04 1.597e-03]]\n",
      "Testing: 100%|██████████| 69/69 [00:12<00:00,  5.40it/s]\n",
      "CV log_loss:  0.01752536571439289\n",
      "sub.shape(3982, 207)\n",
      "score: 0.01752536571439289\n",
      "CPU times: user 2h 2min 26s, sys: 24min 36s, total: 2h 27min 2s\n",
      "Wall time: 2h 22min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#b0\n",
    "score= Exec(param_space)\n",
    "print(\"score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(confFitting, param, test, target, fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    x_test = test[confFitting[\"feature_cols\"]]\n",
    "    \n",
    "    #データセットをイメージ化するトランスフォーマー。\n",
    "    #ここでLogScaleも実施。\n",
    "    all_scaler, all_it, test = PreprocessingLoadTransform(param, x_test, fold, seed)\n",
    "    x_test = x_test.values\n",
    "    \n",
    "    #model class 定義\n",
    "    model = MoAEfficientNet.load_from_checkpoint(\n",
    "        checkpoint_path=f\"{SAVEMODEL}/model{model_type}_SEED{seed}_FOLD{fold}.ckpt\",\n",
    "        training_set=(None, None),  # tuple\n",
    "        valid_set=(None, None),  # tuple\n",
    "        test_set=x_test, #予測用のデータセット\n",
    "        transformer=all_it,\n",
    "        drop_rate=drop_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        fc_size=fc_size,\n",
    "        weight_init='goog')\n",
    "    \n",
    "    model.freeze()\n",
    "    model.eval()\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        gpus=gpus,\n",
    "        distributed_backend=\"dp\",  # multiple-gpus, 1 machine\n",
    "        precision=16,\n",
    "        benchmark=False,\n",
    "        deterministic=True)\n",
    "    \n",
    "    output = trainer.test(model, verbose=False)[0]\n",
    "    predictions = output[\"pred_probs\"]\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed):\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        pred_ = run_predict(confFitting, param, test, target, fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitPredict(confFitting, predictions, test, prefix):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}{prefix}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds_drug_id(train, trainTargetScored)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, trainTargetScored, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = SEED = [42]\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        predictions_ = run_k_fold_predict(confFitting, test, trainTargetScored, param, Tester, NFOLDS, seed)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    # 課題提出\n",
    "    prefix = \"Pytorch\"\n",
    "    SubmitPredict(confFitting, predictions, test, prefix)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test iterations: 63\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.53it/s]Logits: tensor([[-15.7344, -14.8359, -17.3281,  ..., -17.9219, -16.1562, -17.4219],\n",
      "        [-13.6797, -14.5938, -14.9922,  ..., -16.1250, -14.4922, -15.0312],\n",
      "        [-19.3125, -18.2188, -20.1562,  ..., -20.3750, -19.9531, -20.2188],\n",
      "        ...,\n",
      "        [-10.2500, -10.4062, -11.2578,  ..., -10.8906, -11.4766, -10.8203],\n",
      "        [-18.6250, -18.5312, -18.2500,  ..., -21.0781, -16.8750, -19.2812],\n",
      "        [-16.1562, -15.8750, -17.6250,  ..., -19.2969, -16.0000, -18.0781]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[1.192e-07 3.576e-07 5.960e-08 ... 0.000e+00 1.192e-07 0.000e+00]\n",
      " [1.132e-06 4.768e-07 2.980e-07 ... 1.192e-07 5.364e-07 2.980e-07]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [3.535e-05 3.022e-05 1.293e-05 ... 1.866e-05 1.037e-05 1.997e-05]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 5.960e-08 0.000e+00]\n",
      " [1.192e-07 1.192e-07 0.000e+00 ... 0.000e+00 1.192e-07 0.000e+00]]\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test iterations: 63\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.53it/s]Logits: tensor([[-15.0547, -15.7578, -12.0859,  ..., -12.2188, -12.5859, -13.0078],\n",
      "        [-16.0938, -16.1562, -13.0469,  ..., -13.8203, -15.1719, -14.5391],\n",
      "        [-14.6484, -15.2109, -11.4062,  ..., -10.8281, -12.4844, -11.7656],\n",
      "        ...,\n",
      "        [-13.9922, -14.5781, -11.5078,  ..., -11.1797, -12.4609, -12.1250],\n",
      "        [-13.8984, -13.3203, -13.1875,  ..., -12.8906, -15.9922, -13.2656],\n",
      "        [-15.4766, -15.9297, -12.3594,  ..., -12.0078, -14.1016, -13.1016]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[2.980e-07 1.192e-07 5.662e-06 ... 4.947e-06 3.397e-06 2.265e-06]\n",
      " [1.192e-07 1.192e-07 2.146e-06 ... 1.013e-06 2.384e-07 4.768e-07]\n",
      " [4.172e-07 2.384e-07 1.115e-05 ... 1.985e-05 3.815e-06 7.749e-06]\n",
      " ...\n",
      " [8.345e-07 4.768e-07 1.007e-05 ... 1.395e-05 3.874e-06 5.424e-06]\n",
      " [8.941e-07 1.669e-06 1.848e-06 ... 2.503e-06 1.192e-07 1.729e-06]\n",
      " [1.788e-07 1.192e-07 4.292e-06 ... 6.080e-06 7.749e-07 2.027e-06]]\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test iterations: 63\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.54it/s]Logits: tensor([[-20.0781, -16.0938, -16.1875,  ..., -18.3906, -16.3906, -18.0938],\n",
      "        [-15.5547, -12.6484, -11.4375,  ..., -13.7656, -10.3750, -13.2656],\n",
      "        [-16.9531, -14.4688, -13.7422,  ..., -14.7734, -12.9453, -14.3359],\n",
      "        ...,\n",
      "        [-14.9297, -11.9688, -11.4219,  ..., -13.3125, -10.9688, -13.0234],\n",
      "        [-11.8516,  -9.5391,  -9.6797,  ..., -10.5391,  -9.6250, -10.4219],\n",
      "        [-19.9844, -15.2500, -17.4062,  ..., -18.9375, -19.5469, -19.1250]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[0.000e+00 1.192e-07 1.192e-07 ... 0.000e+00 5.960e-08 0.000e+00]\n",
      " [1.788e-07 3.219e-06 1.079e-05 ... 1.073e-06 3.117e-05 1.729e-06]\n",
      " [5.960e-08 5.364e-07 1.073e-06 ... 3.576e-07 2.384e-06 5.960e-07]\n",
      " ...\n",
      " [3.576e-07 6.318e-06 1.097e-05 ... 1.669e-06 1.723e-05 2.205e-06]\n",
      " [7.153e-06 7.200e-05 6.253e-05 ... 2.646e-05 6.604e-05 2.980e-05]\n",
      " [0.000e+00 2.384e-07 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]]\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test iterations: 63\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.52it/s]Logits: tensor([[ -9.9531, -12.0391, -13.5547,  ..., -11.9766, -11.8594, -13.6875],\n",
      "        [-10.7891, -13.7422, -13.2031,  ..., -10.6484, -12.3984, -11.2891],\n",
      "        [-10.8203, -12.4297, -13.8281,  ..., -13.0156, -12.8672, -14.2734],\n",
      "        ...,\n",
      "        [ -9.9297, -12.1641, -12.8594,  ..., -11.1875, -11.3906, -12.6250],\n",
      "        [-10.4141, -12.7031, -15.2344,  ..., -13.5391, -13.1641, -15.8125],\n",
      "        [ -8.3359, -10.4219, -12.0859,  ..., -10.4141, -10.7656, -11.8125]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[4.756e-05 5.901e-06 1.311e-06 ... 6.318e-06 7.093e-06 1.132e-06]\n",
      " [2.062e-05 1.073e-06 1.848e-06 ... 2.372e-05 4.113e-06 1.252e-05]\n",
      " [1.997e-05 3.994e-06 1.013e-06 ... 2.205e-06 2.563e-06 6.557e-07]\n",
      " ...\n",
      " [4.870e-05 5.186e-06 2.623e-06 ... 1.383e-05 1.132e-05 3.278e-06]\n",
      " [2.998e-05 3.040e-06 2.384e-07 ... 1.311e-06 1.907e-06 1.192e-07]\n",
      " [2.397e-04 2.980e-05 5.662e-06 ... 2.998e-05 2.110e-05 7.391e-06]]\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test iterations: 63\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.51it/s]Logits: tensor([[-17.2969, -17.7812, -20.1719,  ..., -21.8438, -20.0469, -20.7969],\n",
      "        [ -9.7500, -10.5938, -12.7891,  ..., -13.1094, -12.6484, -12.6484],\n",
      "        [-14.9062, -15.6172, -18.0156,  ..., -19.3594, -17.8906, -18.5156],\n",
      "        ...,\n",
      "        [-13.8359, -14.7422, -17.0469,  ..., -17.4062, -17.0781, -16.6562],\n",
      "        [-10.4531, -11.5859, -13.3828,  ..., -13.5703, -13.5781, -13.4922],\n",
      "        [ -9.9766, -11.4062, -13.8906,  ..., -13.4531, -13.4219, -12.5000]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "Predictions:  [[5.960e-08 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [5.829e-05 2.509e-05 2.801e-06 ... 2.027e-06 3.219e-06 3.219e-06]\n",
      " [3.576e-07 1.788e-07 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [9.537e-07 4.172e-07 5.960e-08 ... 0.000e+00 5.960e-08 5.960e-08]\n",
      " [2.885e-05 9.298e-06 1.550e-06 ... 1.252e-06 1.252e-06 1.371e-06]\n",
      " [4.649e-05 1.115e-05 9.537e-07 ... 1.431e-06 1.490e-06 3.755e-06]]\n",
      "Testing: 100%|██████████| 63/63 [00:10<00:00,  6.18it/s]\n",
      "sub.shape(3982, 207)\n",
      "CPU times: user 46.8 s, sys: 22.7 s, total: 1min 9s\n",
      "Wall time: 56.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Predict(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperopt\n",
    "from hyperopt import fmin, tpe, hp, rand, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOptExec(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    #Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:                                          \n",
      "0.014981391207012364                                  \n",
      "CV log_loss:                                                                         \n",
      "0.01504250432043703                                                                  \n",
      "CV log_loss:                                                                         \n",
      "0.015004835293169368                                                                 \n",
      "CV log_loss:                                                                         \n",
      "0.015002514832957038                                                                 \n",
      "CV log_loss:                                                                         \n",
      "0.015008986227264749                                                                 \n",
      "CV log_loss:                                                                         \n",
      "0.014993115273980633                                                                   \n",
      "CV log_loss:                                                                           \n",
      "0.015004305432533609                                                                   \n",
      "CV log_loss:                                                                           \n",
      "0.015005235605759781                                                                   \n",
      "CV log_loss:                                                                           \n",
      "0.01505112173070906                                                                    \n",
      "CV log_loss:                                                                           \n",
      "0.014989767496596161                                                                   \n",
      "CV log_loss:                                                                           \n",
      "0.015010978983541678                                                                  \n",
      "CV log_loss:                                                                          \n",
      "0.015006924959817869                                                                  \n",
      "CV log_loss:                                                                          \n",
      "0.01498752231737257                                                                   \n",
      " 87%|████████▋ | 13/15 [2:14:54<20:46, 623.49s/trial, best loss: 0.014981391207012364]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_space = {'hidden_size1': 512, \n",
    "               'hidden_size2': 512, \n",
    "               'dropOutRate1': 0.20393004966355735, \n",
    "               'dropOutRate2': 0.39170486751620137,\n",
    "               'rankGauss_n_quantiles': 488.0393350201078,\n",
    "               'leakyReluSlope': hp.uniform('leakyReluSlope', 1e-3, 1e-1),\n",
    "              }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "hopt = fmin(fn = HOptExec, \n",
    "            space = param_space, \n",
    "            algo = tpe.suggest, \n",
    "            max_evals = 15, \n",
    "            #timeout = 8.9 * 60 * 60, \n",
    "            trials = trials, \n",
    "           )\n",
    "\n",
    "print(hopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
