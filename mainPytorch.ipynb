{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#desktopで動かす。\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tidalUtl.PrpUtl as prp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/tidalryoku/new-baseline-pytorch-moa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ver1__<br>\n",
    "baseline：CV:0.01465 LB:0.01874<br>\n",
    "__ver2__<br>\n",
    "Hyperopt, 2Layer：CV:0.01460 LB:0.01869<br>\n",
    "__ver3__<br>\n",
    "3Layer：CV:0.01464 LB:LB:0.01868<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT = \"/home/tidal/ML_Data/MoA/lish-moa\"\n",
    "#OUTPUT = \"/home/tidal/ML_Data/MoA/output\"\n",
    "INPUT = \"/Users/hfuis/ML_Data/MoA/lish-moa\"\n",
    "OUTPUT = \"/Users/hfuis/ML_Data/MoA/output\"\n",
    "\n",
    "SUBMIT = OUTPUT + \"/submittion/\"\n",
    "SAVEMODEL = OUTPUT + \"/modelPyTorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading\n",
    "trainFeature = pd.read_csv(INPUT + '/train_features.csv')\n",
    "testFeature = pd.read_csv(INPUT + '/test_features.csv')\n",
    "trainTargetScored = pd.read_csv(INPUT + '/train_targets_scored.csv')\n",
    "sample_submission = pd.read_csv(INPUT + '/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in trainFeature.columns if col.startswith('g-')] #gから始まる列名のセット\n",
    "CELLS = [col for col in trainFeature.columns if col.startswith('c-')] #cから始まる列名のセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed固定\n",
    "def seed_everything(seed=42):\n",
    "    #data取得についてのランダム性固定\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #cudnnによる演算の安定化(評価値の安定)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: In & Out Type is DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA features add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_features_add(trainFeature, testFeature):\n",
    "    # GENES\n",
    "    n_comp = 50\n",
    "    \n",
    "    inTrain = trainFeature[GENES]\n",
    "    inTest = testFeature[GENES]\n",
    "    \n",
    "    #PCA実行＆変換後のデータ作成\n",
    "    pca_train, pca_test, _ = prp.tidalPCA(inTrain, inTest, Dim=n_comp, random_state=42)\n",
    "    \n",
    "    #columの名前付け\n",
    "    trainTmp = pd.DataFrame(pca_train, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "    testTmp = pd.DataFrame(pca_test, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "    \n",
    "    #データに付け足し\n",
    "    trainFeature = pd.concat((trainFeature, trainTmp), axis=1)\n",
    "    testFeature = pd.concat((testFeature, testTmp), axis=1)\n",
    "    \n",
    "    \n",
    "    # CELLS\n",
    "    # CELLSもGENESと同様。\n",
    "    n_comp = 15\n",
    "    \n",
    "    inTrain = trainFeature[CELLS]\n",
    "    inTest = testFeature[CELLS]\n",
    "    \n",
    "    pca_train, pca_test, _ = prp.tidalPCA(inTrain, inTest, Dim=n_comp, random_state=42)\n",
    "    \n",
    "    trainTmp = pd.DataFrame(pca_train, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "    testTmp = pd.DataFrame(pca_test, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "    \n",
    "    trainFeature = pd.concat((trainFeature, trainTmp), axis=1)\n",
    "    testFeature = pd.concat((testFeature, testTmp), axis=1)\n",
    "    \n",
    "    \n",
    "    return trainFeature, testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature Selection using Variance Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_Selection_using_Variance_Encoding(trainFeature, testFeature):\n",
    "    data = trainFeature.append(testFeature)\n",
    "    \n",
    "    #['sig_id','cp_type','cp_time','cp_dose']を除いたfeatureで低い分散の特徴量を除去\n",
    "    data_transformed = prp.tidalVarianceThrs(data.iloc[:, 4:], threshold=0.5)\n",
    "    \n",
    "    \n",
    "    trainFeature_transformed = data_transformed[ : trainFeature.shape[0]]\n",
    "    testFeature_transformed = data_transformed[-testFeature.shape[0] : ]\n",
    "    \n",
    "    trainFeature = trainFeature[['sig_id','cp_type','cp_time','cp_dose']]\n",
    "    trainFeature = pd.concat([trainFeature, pd.DataFrame(trainFeature_transformed)], axis=1)\n",
    "    \n",
    "    testFeature = testFeature[['sig_id','cp_type','cp_time','cp_dose']]\n",
    "    testFeature = pd.concat([testFeature, pd.DataFrame(testFeature_transformed)], axis=1)\n",
    "\n",
    "    \n",
    "    return trainFeature, testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting(モデルに突っ込むデータ形式に整形)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cp_type = ctl_vehicleのレコードを削除 & One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__※提出用データ(test)も同様に一部レコードを削除するが、こちらは最後submittionデータを作る際に0埋めを行う。__<br>\n",
    "__（CV_Evaluation(), Submit()参照。）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collecting(trainFeature, testFeature, trainTargetScored):\n",
    "    #Pkey(sig_id)でfeatureとtargetを内部結合。\n",
    "    train = trainFeature.merge(trainTargetScored, on='sig_id')\n",
    "    test = testFeature.merge(sample_submission, on='sig_id')\n",
    "    #件のレコードを削除。\n",
    "    train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "    test = test[test['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "    #cp_typeは使用しない。(今となっては全て同じ特徴量(trt_cp)であるため)\n",
    "    train = train.drop('cp_type', axis=1)\n",
    "    test = test.drop('cp_type', axis=1)\n",
    "    \n",
    "    target = train[trainTargetScored.columns]\n",
    "    \n",
    "    \n",
    "    #One-Hot Encoding(カテゴリデータをすべてOne-Hot化)\n",
    "    feature_name = ['cp_time','cp_dose']\n",
    "    train, test = prp.OneHot_encode(train, test, feature_name)\n",
    "    \n",
    "    \n",
    "    return train, test, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLSMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__MULTI SMOTE: 頻度の少ないターゲットに当たるTrainDataをAugumentする手法__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MlSmote(train, target, numAugmentSamples):\n",
    "    #trainについている['sig_id']を除いたfeatureを使う。\n",
    "    #(targetも除く)\n",
    "    trainFeatureSMOTE = train.drop(target.columns.values.tolist(), axis=1)\n",
    "    #targetについている['sig_id']を除去。\n",
    "    targetSMOTE = target.iloc[:,1:]\n",
    "    \n",
    "    #MLSMOTE実行\n",
    "    X_sub, y_sub = prp.get_minority_samples(trainFeatureSMOTE, targetSMOTE)  # ターゲットの頻度が不足のデータを返す。\n",
    "    trainFeatureAug, targetAug = prp.MLSMOTE(X_sub, y_sub, numAugmentSamples, neigh=5)  # Applying MLSMOTE to augment the dataframe\n",
    "    \n",
    "    #cp_time_*, cp_dose_*で絶対値の大きなものを1,それ以外を0に変更。\n",
    "    \n",
    "    #train,targetの形に成形(targetにsig_idを付与。trainにtargetをくっ付ける。)\n",
    "    #1.targetにsig_idを付与\n",
    "    targetAug[\"sig_id\"] = \"\"\n",
    "    for i in range(len(trainFeatureAug)):\n",
    "        addedId = \"id_MLSMOTE\"+str(i)\n",
    "        targetAug.iloc[i,-1]= addedId\n",
    "    #2.trainにtargetをくっ付ける。\n",
    "    trainAug = pd.concat([trainFeatureAug, targetAug], axis=1)\n",
    "    \n",
    "    #AugmentDataを元のデータにくっ付ける.\n",
    "    train = train.append(trainAug)\n",
    "    target = target.append(targetAug)\n",
    "    \n",
    "    #インデックス整理\n",
    "    train = train.reset_index(drop=True)\n",
    "    target = target.reset_index(drop=True)\n",
    "    \n",
    "    return train, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(param, trainFeature, testFeature, trainTargetScored):\n",
    "    \n",
    "    #PCA成分付与\n",
    "    trainFeature, testFeature = PCA_features_add(trainFeature, testFeature)\n",
    "    \n",
    "    #低分散特徴量除去\n",
    "    trainFeature, testFeature = feature_Selection_using_Variance_Encoding(trainFeature, testFeature)\n",
    "    \n",
    "    #cp_type = ctl_vehicleのレコードを削除 & One-Hot Encoding\n",
    "    train, test, target = Collecting(trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #Multi SMOTEによるデータのAugment\n",
    "    numAugmentSamples=param['numAugmentSamples']\n",
    "    train, target = MlSmote(train, target, numAugmentSamples)\n",
    "    \n",
    "    \n",
    "    return train, test, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {'hidden_size1': 512, \n",
    "               'hidden_size2': 512, \n",
    "               'hidden_size3': 512, \n",
    "               'dropOutRate1': 0.20393004966355735, \n",
    "               'dropOutRate2': 0.39170486751620137, \n",
    "               'numAugmentSamples': 10000, \n",
    "              }\n",
    "trainVsl, testVsl, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTargetScored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>cp_time_24</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "      <th>cp_dose_D1</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31928</th>\n",
       "      <td>id_MLSMOTE9980</td>\n",
       "      <td>2.016956</td>\n",
       "      <td>-1.743677</td>\n",
       "      <td>0.027115</td>\n",
       "      <td>-0.402436</td>\n",
       "      <td>-0.504137</td>\n",
       "      <td>1.774406</td>\n",
       "      <td>-0.731145</td>\n",
       "      <td>-2.470725</td>\n",
       "      <td>6.554182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.816836</td>\n",
       "      <td>-0.816836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31929</th>\n",
       "      <td>id_MLSMOTE9981</td>\n",
       "      <td>-0.139411</td>\n",
       "      <td>-0.509652</td>\n",
       "      <td>-0.232636</td>\n",
       "      <td>0.171926</td>\n",
       "      <td>-0.118366</td>\n",
       "      <td>0.042430</td>\n",
       "      <td>-0.263138</td>\n",
       "      <td>0.491470</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.030710</td>\n",
       "      <td>-0.030710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31930</th>\n",
       "      <td>id_MLSMOTE9982</td>\n",
       "      <td>0.400454</td>\n",
       "      <td>0.774668</td>\n",
       "      <td>-0.363241</td>\n",
       "      <td>-0.921948</td>\n",
       "      <td>-0.814444</td>\n",
       "      <td>-0.139847</td>\n",
       "      <td>0.078427</td>\n",
       "      <td>0.082585</td>\n",
       "      <td>-0.492942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31931</th>\n",
       "      <td>id_MLSMOTE9983</td>\n",
       "      <td>0.876520</td>\n",
       "      <td>0.855526</td>\n",
       "      <td>0.721946</td>\n",
       "      <td>-0.748718</td>\n",
       "      <td>-0.821323</td>\n",
       "      <td>1.821056</td>\n",
       "      <td>-1.116692</td>\n",
       "      <td>-0.295320</td>\n",
       "      <td>2.045011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.544349</td>\n",
       "      <td>-0.544349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31932</th>\n",
       "      <td>id_MLSMOTE9984</td>\n",
       "      <td>1.050052</td>\n",
       "      <td>-0.091008</td>\n",
       "      <td>0.037679</td>\n",
       "      <td>-0.406557</td>\n",
       "      <td>0.293035</td>\n",
       "      <td>0.490078</td>\n",
       "      <td>-0.588561</td>\n",
       "      <td>0.745600</td>\n",
       "      <td>-0.349460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31933</th>\n",
       "      <td>id_MLSMOTE9985</td>\n",
       "      <td>0.249148</td>\n",
       "      <td>-0.302736</td>\n",
       "      <td>0.921724</td>\n",
       "      <td>-0.581269</td>\n",
       "      <td>-0.909616</td>\n",
       "      <td>2.283745</td>\n",
       "      <td>1.144156</td>\n",
       "      <td>-0.624967</td>\n",
       "      <td>0.940115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.220610</td>\n",
       "      <td>1.220610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31934</th>\n",
       "      <td>id_MLSMOTE9986</td>\n",
       "      <td>0.389054</td>\n",
       "      <td>-0.594343</td>\n",
       "      <td>1.023173</td>\n",
       "      <td>-1.263593</td>\n",
       "      <td>0.486781</td>\n",
       "      <td>-0.071013</td>\n",
       "      <td>-0.086883</td>\n",
       "      <td>-0.310463</td>\n",
       "      <td>-1.238562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.026722</td>\n",
       "      <td>-0.026722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31935</th>\n",
       "      <td>id_MLSMOTE9987</td>\n",
       "      <td>0.097947</td>\n",
       "      <td>-0.134478</td>\n",
       "      <td>0.124050</td>\n",
       "      <td>-0.223335</td>\n",
       "      <td>0.119550</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>-0.075782</td>\n",
       "      <td>0.109195</td>\n",
       "      <td>0.278707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.223670</td>\n",
       "      <td>1.223670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31936</th>\n",
       "      <td>id_MLSMOTE9988</td>\n",
       "      <td>1.991262</td>\n",
       "      <td>-1.241687</td>\n",
       "      <td>-1.778847</td>\n",
       "      <td>0.880202</td>\n",
       "      <td>0.837369</td>\n",
       "      <td>-5.358338</td>\n",
       "      <td>1.017443</td>\n",
       "      <td>-1.071072</td>\n",
       "      <td>1.212637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31937</th>\n",
       "      <td>id_MLSMOTE9989</td>\n",
       "      <td>0.585305</td>\n",
       "      <td>0.263818</td>\n",
       "      <td>0.383915</td>\n",
       "      <td>0.390705</td>\n",
       "      <td>-0.382312</td>\n",
       "      <td>-0.021445</td>\n",
       "      <td>-0.282176</td>\n",
       "      <td>-0.549592</td>\n",
       "      <td>0.467248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.118470</td>\n",
       "      <td>-0.118470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31938</th>\n",
       "      <td>id_MLSMOTE9990</td>\n",
       "      <td>-0.160902</td>\n",
       "      <td>0.689199</td>\n",
       "      <td>0.661262</td>\n",
       "      <td>-1.051570</td>\n",
       "      <td>0.388245</td>\n",
       "      <td>-1.335357</td>\n",
       "      <td>0.029427</td>\n",
       "      <td>0.769478</td>\n",
       "      <td>-0.032552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.202431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.202431</td>\n",
       "      <td>-0.202431</td>\n",
       "      <td>1.202431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31939</th>\n",
       "      <td>id_MLSMOTE9991</td>\n",
       "      <td>-0.715293</td>\n",
       "      <td>-1.183395</td>\n",
       "      <td>-0.116599</td>\n",
       "      <td>0.222853</td>\n",
       "      <td>-0.306261</td>\n",
       "      <td>1.749071</td>\n",
       "      <td>-0.750184</td>\n",
       "      <td>-0.149822</td>\n",
       "      <td>-0.771827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31940</th>\n",
       "      <td>id_MLSMOTE9992</td>\n",
       "      <td>-1.139517</td>\n",
       "      <td>1.209926</td>\n",
       "      <td>-0.346147</td>\n",
       "      <td>-0.767289</td>\n",
       "      <td>0.115844</td>\n",
       "      <td>-0.741290</td>\n",
       "      <td>-0.019106</td>\n",
       "      <td>1.063146</td>\n",
       "      <td>-0.325340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.182235</td>\n",
       "      <td>1.182235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31941</th>\n",
       "      <td>id_MLSMOTE9993</td>\n",
       "      <td>-0.893344</td>\n",
       "      <td>-2.067910</td>\n",
       "      <td>-1.161525</td>\n",
       "      <td>-0.529340</td>\n",
       "      <td>-0.760299</td>\n",
       "      <td>0.398954</td>\n",
       "      <td>1.166006</td>\n",
       "      <td>-0.909478</td>\n",
       "      <td>-0.244643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31942</th>\n",
       "      <td>id_MLSMOTE9994</td>\n",
       "      <td>-0.168747</td>\n",
       "      <td>-0.870126</td>\n",
       "      <td>-0.216647</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.940373</td>\n",
       "      <td>-0.309234</td>\n",
       "      <td>-0.596970</td>\n",
       "      <td>1.598383</td>\n",
       "      <td>0.085566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.481884</td>\n",
       "      <td>1.481884</td>\n",
       "      <td>-0.481884</td>\n",
       "      <td>1.481884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31943</th>\n",
       "      <td>id_MLSMOTE9995</td>\n",
       "      <td>0.161468</td>\n",
       "      <td>-0.854128</td>\n",
       "      <td>-2.410903</td>\n",
       "      <td>-0.037989</td>\n",
       "      <td>0.960636</td>\n",
       "      <td>1.742138</td>\n",
       "      <td>-1.457136</td>\n",
       "      <td>-0.825134</td>\n",
       "      <td>2.471415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31944</th>\n",
       "      <td>id_MLSMOTE9996</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>0.063903</td>\n",
       "      <td>-0.784118</td>\n",
       "      <td>-0.182720</td>\n",
       "      <td>-0.175654</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>-1.152777</td>\n",
       "      <td>1.508508</td>\n",
       "      <td>0.051818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.512810</td>\n",
       "      <td>1.512810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31945</th>\n",
       "      <td>id_MLSMOTE9997</td>\n",
       "      <td>1.558322</td>\n",
       "      <td>0.401711</td>\n",
       "      <td>1.756124</td>\n",
       "      <td>-4.705453</td>\n",
       "      <td>-0.500768</td>\n",
       "      <td>-1.774824</td>\n",
       "      <td>4.260324</td>\n",
       "      <td>-0.202718</td>\n",
       "      <td>2.330475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.870687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.870687</td>\n",
       "      <td>-0.870687</td>\n",
       "      <td>1.870687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31946</th>\n",
       "      <td>id_MLSMOTE9998</td>\n",
       "      <td>2.038177</td>\n",
       "      <td>-0.192013</td>\n",
       "      <td>0.084321</td>\n",
       "      <td>-0.332896</td>\n",
       "      <td>0.678826</td>\n",
       "      <td>-1.883271</td>\n",
       "      <td>-0.877889</td>\n",
       "      <td>1.143248</td>\n",
       "      <td>0.085950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31947</th>\n",
       "      <td>id_MLSMOTE9999</td>\n",
       "      <td>0.518748</td>\n",
       "      <td>-0.360903</td>\n",
       "      <td>3.123444</td>\n",
       "      <td>-1.465203</td>\n",
       "      <td>-0.414444</td>\n",
       "      <td>-3.383622</td>\n",
       "      <td>0.068642</td>\n",
       "      <td>0.500057</td>\n",
       "      <td>-0.778384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.801594</td>\n",
       "      <td>-0.801594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.801594</td>\n",
       "      <td>1.801594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sig_id         0         1         2         3         4  \\\n",
       "31928  id_MLSMOTE9980  2.016956 -1.743677  0.027115 -0.402436 -0.504137   \n",
       "31929  id_MLSMOTE9981 -0.139411 -0.509652 -0.232636  0.171926 -0.118366   \n",
       "31930  id_MLSMOTE9982  0.400454  0.774668 -0.363241 -0.921948 -0.814444   \n",
       "31931  id_MLSMOTE9983  0.876520  0.855526  0.721946 -0.748718 -0.821323   \n",
       "31932  id_MLSMOTE9984  1.050052 -0.091008  0.037679 -0.406557  0.293035   \n",
       "31933  id_MLSMOTE9985  0.249148 -0.302736  0.921724 -0.581269 -0.909616   \n",
       "31934  id_MLSMOTE9986  0.389054 -0.594343  1.023173 -1.263593  0.486781   \n",
       "31935  id_MLSMOTE9987  0.097947 -0.134478  0.124050 -0.223335  0.119550   \n",
       "31936  id_MLSMOTE9988  1.991262 -1.241687 -1.778847  0.880202  0.837369   \n",
       "31937  id_MLSMOTE9989  0.585305  0.263818  0.383915  0.390705 -0.382312   \n",
       "31938  id_MLSMOTE9990 -0.160902  0.689199  0.661262 -1.051570  0.388245   \n",
       "31939  id_MLSMOTE9991 -0.715293 -1.183395 -0.116599  0.222853 -0.306261   \n",
       "31940  id_MLSMOTE9992 -1.139517  1.209926 -0.346147 -0.767289  0.115844   \n",
       "31941  id_MLSMOTE9993 -0.893344 -2.067910 -1.161525 -0.529340 -0.760299   \n",
       "31942  id_MLSMOTE9994 -0.168747 -0.870126 -0.216647  0.191176  0.940373   \n",
       "31943  id_MLSMOTE9995  0.161468 -0.854128 -2.410903 -0.037989  0.960636   \n",
       "31944  id_MLSMOTE9996  0.696545  0.063903 -0.784118 -0.182720 -0.175654   \n",
       "31945  id_MLSMOTE9997  1.558322  0.401711  1.756124 -4.705453 -0.500768   \n",
       "31946  id_MLSMOTE9998  2.038177 -0.192013  0.084321 -0.332896  0.678826   \n",
       "31947  id_MLSMOTE9999  0.518748 -0.360903  3.123444 -1.465203 -0.414444   \n",
       "\n",
       "              5         6         7         8  ...  \\\n",
       "31928  1.774406 -0.731145 -2.470725  6.554182  ...   \n",
       "31929  0.042430 -0.263138  0.491470  0.009255  ...   \n",
       "31930 -0.139847  0.078427  0.082585 -0.492942  ...   \n",
       "31931  1.821056 -1.116692 -0.295320  2.045011  ...   \n",
       "31932  0.490078 -0.588561  0.745600 -0.349460  ...   \n",
       "31933  2.283745  1.144156 -0.624967  0.940115  ...   \n",
       "31934 -0.071013 -0.086883 -0.310463 -1.238562  ...   \n",
       "31935  0.939507 -0.075782  0.109195  0.278707  ...   \n",
       "31936 -5.358338  1.017443 -1.071072  1.212637  ...   \n",
       "31937 -0.021445 -0.282176 -0.549592  0.467248  ...   \n",
       "31938 -1.335357  0.029427  0.769478 -0.032552  ...   \n",
       "31939  1.749071 -0.750184 -0.149822 -0.771827  ...   \n",
       "31940 -0.741290 -0.019106  1.063146 -0.325340  ...   \n",
       "31941  0.398954  1.166006 -0.909478 -0.244643  ...   \n",
       "31942 -0.309234 -0.596970  1.598383  0.085566  ...   \n",
       "31943  1.742138 -1.457136 -0.825134  2.471415  ...   \n",
       "31944  0.002176 -1.152777  1.508508  0.051818  ...   \n",
       "31945 -1.774824  4.260324 -0.202718  2.330475  ...   \n",
       "31946 -1.883271 -0.877889  1.143248  0.085950  ...   \n",
       "31947 -3.383622  0.068642  0.500057 -0.778384  ...   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "31928                                    0.0              0.0        0.0   \n",
       "31929                                    0.0              0.0        0.0   \n",
       "31930                                    0.0              0.0        0.0   \n",
       "31931                                    0.0              0.0        0.0   \n",
       "31932                                    0.0              0.0        0.0   \n",
       "31933                                    0.0              0.0        0.0   \n",
       "31934                                    0.0              0.0        0.0   \n",
       "31935                                    0.0              0.0        0.0   \n",
       "31936                                    0.0              0.0        0.0   \n",
       "31937                                    0.0              0.0        0.0   \n",
       "31938                                    0.0              0.0        0.0   \n",
       "31939                                    0.0              0.0        0.0   \n",
       "31940                                    0.0              0.0        0.0   \n",
       "31941                                    0.0              0.0        0.0   \n",
       "31942                                    0.0              0.0        0.0   \n",
       "31943                                    0.0              0.0        0.0   \n",
       "31944                                    0.0              0.0        0.0   \n",
       "31945                                    0.0              0.0        1.0   \n",
       "31946                                    0.0              0.0        0.0   \n",
       "31947                                    0.0              0.0        0.0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  cp_time_24  cp_time_48  \\\n",
       "31928                         0.0            0.0    0.000000    0.000000   \n",
       "31929                         0.0            0.0    0.000000    1.030710   \n",
       "31930                         0.0            0.0    0.000000    1.000000   \n",
       "31931                         0.0            0.0    0.000000    1.544349   \n",
       "31932                         0.0            0.0    0.000000    0.000000   \n",
       "31933                         0.0            0.0   -0.220610    1.220610   \n",
       "31934                         0.0            0.0    1.026722   -0.026722   \n",
       "31935                         0.0            0.0    0.000000    1.000000   \n",
       "31936                         0.0            0.0    0.000000    0.000000   \n",
       "31937                         0.0            0.0    1.118470   -0.118470   \n",
       "31938                         0.0            0.0   -0.202431    0.000000   \n",
       "31939                         0.0            0.0    0.000000    0.000000   \n",
       "31940                         0.0            0.0   -0.182235    1.182235   \n",
       "31941                         0.0            0.0    0.000000    1.000000   \n",
       "31942                         0.0            0.0    0.000000   -0.481884   \n",
       "31943                         0.0            0.0    0.000000    0.000000   \n",
       "31944                         0.0            0.0    0.000000   -0.512810   \n",
       "31945                         0.0            0.0    1.870687    0.000000   \n",
       "31946                         0.0            0.0    0.000000    0.000000   \n",
       "31947                         0.0            0.0    1.801594   -0.801594   \n",
       "\n",
       "       cp_time_72  cp_dose_D1  cp_dose_D2  \n",
       "31928    1.000000    1.816836   -0.816836  \n",
       "31929   -0.030710    1.000000    0.000000  \n",
       "31930    0.000000    0.000000    1.000000  \n",
       "31931   -0.544349    1.000000    0.000000  \n",
       "31932    1.000000    1.000000    0.000000  \n",
       "31933    0.000000    1.000000    0.000000  \n",
       "31934    0.000000    0.000000    1.000000  \n",
       "31935    0.000000   -0.223670    1.223670  \n",
       "31936    1.000000    0.000000    1.000000  \n",
       "31937    0.000000    1.000000    0.000000  \n",
       "31938    1.202431   -0.202431    1.202431  \n",
       "31939    1.000000    1.000000    0.000000  \n",
       "31940    0.000000    0.000000    1.000000  \n",
       "31941    0.000000    0.000000    1.000000  \n",
       "31942    1.481884   -0.481884    1.481884  \n",
       "31943    1.000000    1.000000    0.000000  \n",
       "31944    1.512810    0.000000    1.000000  \n",
       "31945   -0.870687   -0.870687    1.870687  \n",
       "31946    1.000000    1.000000    0.000000  \n",
       "31947    0.000000   -0.801594    1.801594  \n",
       "\n",
       "[20 rows x 1139 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVsl.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>cp_time_24</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "      <th>cp_dose_D1</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>-0.2140</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>-0.3260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>-1.8820</td>\n",
       "      <td>0.4022</td>\n",
       "      <td>-0.3528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>-0.1799</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.5128</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_006fc47b8</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>-0.6898</td>\n",
       "      <td>-1.6270</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>-0.3832</td>\n",
       "      <td>-0.4653</td>\n",
       "      <td>1.0070</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id       0       1       2       3       4       5       6  \\\n",
       "0  id_0004d9e33 -0.5458  0.1306 -0.5135  0.4408  1.5500 -0.1644 -0.2140   \n",
       "1  id_001897cda -0.1829  0.2320  1.2080 -0.4522 -0.3652 -0.3319 -1.8820   \n",
       "2  id_00276f245  0.4828  0.1955  0.3825  0.4244 -0.5855 -1.2020  0.5998   \n",
       "3  id_0027f1083 -0.3979 -1.2680  1.9130  0.2057 -0.5864 -0.0166  0.5128   \n",
       "4  id_006fc47b8  0.3658  0.5536 -0.6898 -1.6270  0.5239 -0.3832 -0.4653   \n",
       "\n",
       "        7       8  ...  ubiquitin_specific_protease_inhibitor  \\\n",
       "0  0.2221 -0.3260  ...                                    0.5   \n",
       "1  0.4022 -0.3528  ...                                    0.5   \n",
       "2 -0.1799  0.9365  ...                                    0.5   \n",
       "3  0.6365  0.2611  ...                                    0.5   \n",
       "4  1.0070  0.3726  ...                                    0.5   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0              0.5        0.5                         0.5            0.5   \n",
       "1              0.5        0.5                         0.5            0.5   \n",
       "2              0.5        0.5                         0.5            0.5   \n",
       "3              0.5        0.5                         0.5            0.5   \n",
       "4              0.5        0.5                         0.5            0.5   \n",
       "\n",
       "   cp_time_24  cp_time_48  cp_time_72  cp_dose_D1  cp_dose_D2  \n",
       "0           1           0           0           1           0  \n",
       "1           0           0           1           1           0  \n",
       "2           1           0           0           0           1  \n",
       "3           0           1           0           1           0  \n",
       "4           0           1           0           0           1  \n",
       "\n",
       "[5 rows x 1139 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_000644bb2                          0.0                     0.0   \n",
       "1  id_000779bfc                          0.0                     0.0   \n",
       "2  id_000a6266a                          0.0                     0.0   \n",
       "3  id_0015fd391                          0.0                     0.0   \n",
       "4  id_001626bd3                          0.0                     0.0   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0             0.0                             0.0   \n",
       "1             0.0                             0.0   \n",
       "2             0.0                             0.0   \n",
       "3             0.0                             0.0   \n",
       "4             0.0                             0.0   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                0.0                             0.0   \n",
       "1                                0.0                             0.0   \n",
       "2                                0.0                             0.0   \n",
       "3                                0.0                             0.0   \n",
       "4                                0.0                             0.0   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                         0.0                            0.0   \n",
       "1                         0.0                            0.0   \n",
       "2                         0.0                            0.0   \n",
       "3                         0.0                            0.0   \n",
       "4                         0.0                            0.0   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                         0.0  ...                                    0.0   \n",
       "1                         0.0  ...                                    0.0   \n",
       "2                         0.0  ...                                    0.0   \n",
       "3                         0.0  ...                                    0.0   \n",
       "4                         0.0  ...                                    0.0   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0           0.0              0.0                0.0   \n",
       "1           0.0              0.0                0.0   \n",
       "2           0.0              0.0                0.0   \n",
       "3           0.0              0.0                0.0   \n",
       "4           0.0              0.0                0.0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                        0.0                                    0.0   \n",
       "1                        0.0                                    0.0   \n",
       "2                        0.0                                    0.0   \n",
       "3                        0.0                                    0.0   \n",
       "4                        0.0                                    0.0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0              0.0        0.0                         0.0            0.0  \n",
       "1              0.0        0.0                         0.0            0.0  \n",
       "2              0.0        0.0                         0.0            0.0  \n",
       "3              0.0        0.0                         0.0            0.0  \n",
       "4              0.0        0.0                         0.0            0.0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                          0.5                     0.5   \n",
       "1  id_001897cda                          0.5                     0.5   \n",
       "2  id_002429b5b                          0.5                     0.5   \n",
       "3  id_00276f245                          0.5                     0.5   \n",
       "4  id_0027f1083                          0.5                     0.5   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0             0.5                             0.5   \n",
       "1             0.5                             0.5   \n",
       "2             0.5                             0.5   \n",
       "3             0.5                             0.5   \n",
       "4             0.5                             0.5   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                0.5                             0.5   \n",
       "1                                0.5                             0.5   \n",
       "2                                0.5                             0.5   \n",
       "3                                0.5                             0.5   \n",
       "4                                0.5                             0.5   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                         0.5                            0.5   \n",
       "1                         0.5                            0.5   \n",
       "2                         0.5                            0.5   \n",
       "3                         0.5                            0.5   \n",
       "4                         0.5                            0.5   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                         0.5  ...                                    0.5   \n",
       "1                         0.5  ...                                    0.5   \n",
       "2                         0.5  ...                                    0.5   \n",
       "3                         0.5  ...                                    0.5   \n",
       "4                         0.5  ...                                    0.5   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0           0.5              0.5                0.5   \n",
       "1           0.5              0.5                0.5   \n",
       "2           0.5              0.5                0.5   \n",
       "3           0.5              0.5                0.5   \n",
       "4           0.5              0.5                0.5   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                        0.5                                    0.5   \n",
       "1                        0.5                                    0.5   \n",
       "2                        0.5                                    0.5   \n",
       "3                        0.5                                    0.5   \n",
       "4                        0.5                                    0.5   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0              0.5        0.5                         0.5            0.5  \n",
       "1              0.5        0.5                         0.5            0.5  \n",
       "2              0.5        0.5                         0.5            0.5  \n",
       "3              0.5        0.5                         0.5            0.5  \n",
       "4              0.5        0.5                         0.5            0.5  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (31948, 1139)\n",
      "Test: (3624, 1139)\n",
      "Target: (31948, 207)\n",
      "sample_submission: (3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \"+ str(trainVsl.shape))\n",
    "print(\"Test: \"+ str(testVsl.shape))\n",
    "print(\"Target: \"+ str(targetVsl.shape))\n",
    "print(\"sample_submission: \"+ str(sample_submission.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config about Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configは辞書化しておく。\n",
    "def Config_about_Fitting(train, test, target, folds):\n",
    "    confFitting = {}\n",
    "    \n",
    "    #Fitするときに\"y\"として使う列の列名配列\n",
    "    confFitting[\"target_cols\"] = target.drop('sig_id', axis=1).columns.values.tolist()\n",
    "    #Fitするときに\"X\"として使う列の列名配列\n",
    "    #kfold, id等はここで削除。\n",
    "    feature_cols = [c for c in folds.columns if c not in confFitting[\"target_cols\"]]\n",
    "    confFitting[\"feature_cols\"] = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "    #特徴量、ターゲットのサイズ\n",
    "    confFitting[\"num_features\"]=len(confFitting[\"feature_cols\"])\n",
    "    confFitting[\"num_targets\"]=len(confFitting[\"target_cols\"])\n",
    "    \n",
    "    return confFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train,Valid用のデータクラス\n",
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #torch.DataLoaderに入れるための形式\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "#Test用のデータクラス\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            #torch.DataLoaderに入れるための形式\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: Fitting, Evaluation, Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, param):\n",
    "        super(Model, self).__init__()\n",
    "        #hyperoptによる被探索パラメータ\n",
    "        hidden_size1=param['hidden_size1']\n",
    "        hidden_size2=param['hidden_size2']\n",
    "        hidden_size3=param['hidden_size3']\n",
    "        dropOutRate1=param['dropOutRate1']\n",
    "        dropOutRate2=param['dropOutRate2']\n",
    "        #dropOutRate3=param['dropOutRate3']\n",
    "        #dropOutRate4=param['dropOutRate4']\n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(dropOutRate1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size1))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.dropout2 = nn.Dropout(dropOutRate1)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size1, hidden_size2))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size2)\n",
    "        self.dropout3 = nn.Dropout(dropOutRate2)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size2, hidden_size3))\n",
    "        \n",
    "        self.batch_norm4 = nn.BatchNorm1d(hidden_size3)\n",
    "        self.dropout4 = nn.Dropout(dropOutRate2)\n",
    "        self.dense4 = nn.utils.weight_norm(nn.Linear(hidden_size3, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.dense3(x))\n",
    "        \n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.dense4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds(train, target):\n",
    "    folds = train.copy()\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "    \n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "        folds.loc[v_idx, 'kfold'] = int(f)\n",
    "    \n",
    "    folds['kfold'] = folds['kfold'].astype(int)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>cp_time_24</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "      <th>cp_dose_D1</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>-0.4047</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>-0.1321</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>-0.8789</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id       0       1       2       3       4       5       6  \\\n",
       "0  id_000644bb2  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120 -1.0220   \n",
       "1  id_000779bfc  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207  0.2341   \n",
       "2  id_000a6266a  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390  0.1715   \n",
       "3  id_0015fd391 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095 -1.9590   \n",
       "4  id_001626bd3 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244 -0.2800   \n",
       "\n",
       "        7       8  ...  vegfr_inhibitor  vitamin_b  \\\n",
       "0 -0.0326  0.5548  ...                0          0   \n",
       "1  0.3372 -0.4047  ...                0          0   \n",
       "2  0.2155  0.0065  ...                0          0   \n",
       "3  0.1792 -0.1321  ...                0          0   \n",
       "4 -0.1498 -0.8789  ...                0          0   \n",
       "\n",
       "   vitamin_d_receptor_agonist  wnt_inhibitor  cp_time_24  cp_time_48  \\\n",
       "0                           0              0           1           0   \n",
       "1                           0              0           0           0   \n",
       "2                           0              0           0           1   \n",
       "3                           0              0           0           1   \n",
       "4                           0              0           0           0   \n",
       "\n",
       "   cp_time_72  cp_dose_D1  cp_dose_D2  kfold  \n",
       "0           0           1           0      0  \n",
       "1           1           1           0      2  \n",
       "2           0           1           0      1  \n",
       "3           0           1           0      2  \n",
       "4           1           0           1      2  \n",
       "\n",
       "[5 rows x 1140 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing Data\n",
    "trainVsl, testVsl, targetVsl = preprocessing(trainFeature, testFeature, trainTargetScored)\n",
    "#CV folds\n",
    "foldsVsl = CV_folds(trainVsl, targetVsl)\n",
    "\n",
    "foldsVsl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(confFitting, Tester, fold, seed, param,\n",
    "                 folds, train, test, target):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = folds\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[confFitting[\"feature_cols\"]].values, train_df[confFitting[\"target_cols\"]].values\n",
    "    x_valid, y_valid =  valid_df[confFitting[\"feature_cols\"]].values, valid_df[confFitting[\"target_cols\"]].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    ##### 評価関数 ######\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        if Tester:\n",
    "            print(\"EPOCH: {:03}: | train_loss: {:.3f}: | valid_loss: {:.3f}\".format(epoch, train_loss, valid_loss))\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"{SAVEMODEL}FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                if Tester:\n",
    "                    print('Early stopping. Best Val loss: {:.3f}'.format(best_loss))\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"{SAVEMODEL}FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(Tester, NFOLDS, seed, param,\n",
    "              folds, train, test, target, confFitting):\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        oof_, pred_ = run_training(confFitting, Tester, fold, seed, param,\n",
    "                                   folds, train, test, target)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    " def CV_Evaluation(confFitting, oof, train, target):\n",
    "    #CV score : OOFの評価結果。\n",
    "    #OOF(学習モデルによるtrain dataの予測)\n",
    "    train[confFitting[\"target_cols\"]] = oof\n",
    "    #target(予測結果)：ここで処理「cp_type = ctl_vehicleのレコードを削除」で抜けたところに0を入れている。\n",
    "    valid_results = trainTargetScored.drop(columns=confFitting[\"target_cols\"]).merge(train[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    \n",
    "    y_true = trainTargetScored[confFitting[\"target_cols\"]].values\n",
    "    y_pred = valid_results[confFitting[\"target_cols\"]].values\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(confFitting[\"num_targets\"]):\n",
    "        score_ = log_loss(y_true[:, i], y_pred[:, i]) #問題の評価指標によって変わる。\n",
    "        score += score_ / target.shape[1]\n",
    "        \n",
    "    print(\"CV log_loss: \", score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特になし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Submit(confFitting, predictions, test):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Exec(param):\n",
    "    \n",
    "    #Tester(True/False)\n",
    "    Tester = True\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 0 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.561: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.561: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.561: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.562: | valid_loss: 0.046\n",
      "EPOCH: 001: | train_loss: 0.026: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.019\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.560: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.024\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.017: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 1 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.566: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 023: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.563: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.564: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.020\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.563: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.560: | valid_loss: 0.051\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.022\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.016: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.017\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 2 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.565: | valid_loss: 0.047\n",
      "EPOCH: 001: | train_loss: 0.026: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.562: | valid_loss: 0.045\n",
      "EPOCH: 001: | train_loss: 0.026: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.563: | valid_loss: 0.046\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 011: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.563: | valid_loss: 0.049\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.018\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 010: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 011: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 012: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 013: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 014: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 015: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 016: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 017: | train_loss: 0.017: | valid_loss: 0.017\n",
      "EPOCH: 018: | train_loss: 0.017: | valid_loss: 0.016\n",
      "EPOCH: 019: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 020: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 021: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 022: | train_loss: 0.016: | valid_loss: 0.016\n",
      "EPOCH: 023: | train_loss: 0.015: | valid_loss: 0.016\n",
      "EPOCH: 024: | train_loss: 0.015: | valid_loss: 0.016\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.562: | valid_loss: 0.048\n",
      "EPOCH: 001: | train_loss: 0.025: | valid_loss: 0.021\n",
      "EPOCH: 002: | train_loss: 0.020: | valid_loss: 0.019\n",
      "EPOCH: 003: | train_loss: 0.019: | valid_loss: 0.018\n",
      "EPOCH: 004: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 005: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 006: | train_loss: 0.018: | valid_loss: 0.018\n",
      "EPOCH: 007: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 008: | train_loss: 0.018: | valid_loss: 0.017\n",
      "EPOCH: 009: | train_loss: 0.018: | valid_loss: 0.017\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-85cddf704fb4>\u001b[0m in \u001b[0;36mExec\u001b[0;34m(param)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SEED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'~'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n\u001b[0;32m---> 24\u001b[0;31m                                        folds, train, test, target, confFitting)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moof\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moof_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredictions_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-51f2fa5e5a41>\u001b[0m in \u001b[0;36mrun_k_fold\u001b[0;34m(Tester, NFOLDS, seed, param, folds, train, test, target, confFitting)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         oof_, pred_ = run_training(confFitting, Tester, fold, seed, param,\n\u001b[0;32m---> 10\u001b[0;31m                                    folds, train, test, target)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mNFOLDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-e35955191646>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(confFitting, Tester, fold, seed, param, folds, train, test, target)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-47a4a9317138>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, optimizer, scheduler, loss_fn, dataloader, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_space = {'hidden_size1': 512, \n",
    "               'hidden_size2': 512, \n",
    "               'hidden_size3': 512, \n",
    "               'dropOutRate1': 0.20393004966355735, \n",
    "               'dropOutRate2': 0.39170486751620137, \n",
    "               'numAugmentSamples': 10000, \n",
    "              }\n",
    "score = Exec(param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-7b47415f70a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ec64381242b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#hyperopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'"
     ]
    }
   ],
   "source": [
    "#hyperopt\n",
    "from hyperopt import fmin, tpe, hp, rand, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOptExec(param):\n",
    "    \n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    #Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [5:59:33<00:00, 719.13s/trial, best loss: 0.014635599916671092]  \n",
      "CPU times: user 6h 37min 46s, sys: 4min 8s, total: 6h 41min 55s\n",
      "Wall time: 5h 59min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_space = {'hidden_size1': hp.choice('hidden_size1', [2048, 1024, 512]), \n",
    "               'hidden_size2': hp.choice('hidden_size2', [2048, 1024, 512]), \n",
    "               'hidden_size3': hp.choice('hidden_size3', [2048, 1024, 512]), \n",
    "               'dropOutRate1': hp.uniform('dropOutRate1', 0.2, 0.6), \n",
    "               'dropOutRate2': hp.uniform('dropOutRate2', 0.2, 0.6), \n",
    "               #'dropOutRate3': hp.uniform('dropOutRate3', 0.2, 0.6), \n",
    "              }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "hopt = fmin(fn = HOptExec, \n",
    "            space = param_space, \n",
    "            algo = tpe.suggest, \n",
    "            max_evals = 30, \n",
    "            #timeout = 8.9 * 60 * 60, \n",
    "            trials = trials, \n",
    "           )\n",
    "\n",
    "print(hopt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
