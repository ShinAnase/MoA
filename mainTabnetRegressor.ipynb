{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Tabnet \n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "#model save\n",
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tidalUtl.PrpUtl as prp\n",
    "import tidalUtl.EdaUtl as eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/tidalryoku/new-baseline-pytorch-moa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ver1__<br>\n",
    "baseline：CV:0.01465 LB:0.01874<br>\n",
    "__ver2__<br>\n",
    "Hyperopt, 2Layer：CV:0.01460 LB:0.01869<br>\n",
    "__ver3__<br>\n",
    "3Layer：CV:0.01464 LB:0.01868<br>\n",
    "__ver4__<br>\n",
    "MLSMOTE baseline：CV:0.01476 LB:0.01978<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"/home/tidal/ML_Data/MoA/lish-moa\"\n",
    "OUTPUT = \"/home/tidal/ML_Data/MoA/output\"\n",
    "#INPUT = \"/Users/hfuis/ML_Data/MoA/lish-moa\"\n",
    "#OUTPUT = \"/Users/hfuis/ML_Data/MoA/output\"\n",
    "\n",
    "SUBMIT = OUTPUT + \"/submittion/\"\n",
    "SAVEMODEL = OUTPUT + \"/model/tabnet_regressor/\"\n",
    "SAVEOOF = OUTPUT + \"/OOF/tabnet_regressor/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading\n",
    "trainFeature = pd.read_csv(INPUT + '/train_features.csv')\n",
    "testFeature = pd.read_csv(INPUT + '/test_features.csv')\n",
    "trainTargetScored = pd.read_csv(INPUT + '/train_targets_scored.csv')\n",
    "sample_submission = pd.read_csv(INPUT + '/sample_submission.csv')\n",
    "drug = pd.read_csv(INPUT + '/train_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in trainFeature.columns if col.startswith('g-')] #gから始まる列名のセット\n",
    "CELLS = [col for col in trainFeature.columns if col.startswith('c-')] #cから始まる列名のセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed固定\n",
    "def seed_everything(seed=42):\n",
    "    #data取得についてのランダム性固定\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #cudnnによる演算の安定化(評価値の安定)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter\n",
    "param_space = {'hidden_size1': 512, \n",
    "               'hidden_size2': 512, \n",
    "               'dropOutRate1': 0.20393004966355735, \n",
    "               'dropOutRate2': 0.39170486751620137,\n",
    "               'n_d':8,\n",
    "               'n_a':8,\n",
    "               'n_steps':3,\n",
    "               'gamma':1.3,\n",
    "               'cat_idxs':[],\n",
    "               'cat_dims':[],\n",
    "               'cat_emb_dim':1,\n",
    "               'n_independent':2,\n",
    "               'n_shared':2,\n",
    "               'epsilon':1e-15,\n",
    "               'virtual_batch_size':128,\n",
    "               'momentum':0.02,\n",
    "               'device_name':'cuda',\n",
    "               'mask_type':'sparsemax',\n",
    "               'rankGauss_n_quantiles': 488.0393350201078,\n",
    "               'leakyReluSlope': 0.01973893854348531,\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: In & Out Type is DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA features add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_features_add(trainFeature, testFeature):\n",
    "    # GENES\n",
    "    n_comp = 50\n",
    "    \n",
    "    inTrain = trainFeature[GENES]\n",
    "    inTest = testFeature[GENES]\n",
    "    \n",
    "    #PCA実行＆変換後のデータ作成\n",
    "    pca_train, pca_test, _ = prp.tidalPCA(inTrain, inTest, Dim=n_comp, random_state=42)\n",
    "    \n",
    "    #columの名前付け\n",
    "    trainTmp = pd.DataFrame(pca_train, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "    testTmp = pd.DataFrame(pca_test, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "    \n",
    "    #データに付け足し\n",
    "    trainFeature = pd.concat((trainFeature, trainTmp), axis=1)\n",
    "    testFeature = pd.concat((testFeature, testTmp), axis=1)\n",
    "    \n",
    "    \n",
    "    # CELLS\n",
    "    # CELLSもGENESと同様。\n",
    "    n_comp = 15\n",
    "    \n",
    "    inTrain = trainFeature[CELLS]\n",
    "    inTest = testFeature[CELLS]\n",
    "    \n",
    "    pca_train, pca_test, _ = prp.tidalPCA(inTrain, inTest, Dim=n_comp, random_state=42)\n",
    "    \n",
    "    trainTmp = pd.DataFrame(pca_train, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "    testTmp = pd.DataFrame(pca_test, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "    \n",
    "    trainFeature = pd.concat((trainFeature, trainTmp), axis=1)\n",
    "    testFeature = pd.concat((testFeature, testTmp), axis=1)\n",
    "    \n",
    "    \n",
    "    return trainFeature, testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature Selection using Variance Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_Selection_using_Variance_Encoding(trainFeature, testFeature):\n",
    "    data = trainFeature.append(testFeature)\n",
    "    \n",
    "    #['sig_id','cp_type','cp_time','cp_dose']を除いたfeatureで低い分散の特徴量を除去\n",
    "    #列名は連番になる。\n",
    "    data_transformed = prp.tidalVarianceThrs(data.iloc[:, 4:], threshold=0.5)\n",
    "    \n",
    "    \n",
    "    trainFeature_transformed = data_transformed[ : trainFeature.shape[0]]\n",
    "    testFeature_transformed = data_transformed[-testFeature.shape[0] : ]\n",
    "    \n",
    "    trainFeature = trainFeature[['sig_id','cp_type','cp_time','cp_dose']]\n",
    "    trainFeature = pd.concat([trainFeature, pd.DataFrame(trainFeature_transformed)], axis=1)\n",
    "    \n",
    "    testFeature = testFeature[['sig_id','cp_type','cp_time','cp_dose']]\n",
    "    testFeature = pd.concat([testFeature, pd.DataFrame(testFeature_transformed)], axis=1)\n",
    "\n",
    "    \n",
    "    return trainFeature, testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cp_type = ctl_vehicleのレコードを削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__※提出用データ(test)も同様に一部レコードを削除するが、こちらは最後submittionデータを作る際に0埋めを行う。__<br>\n",
    "__（CV_Evaluation(), Submit()参照。）__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_ctl_vehicle(trainFeature, testFeature, trainTargetScored):\n",
    "    \n",
    "    #Pkey(sig_id)でfeatureとtargetを内部結合。\n",
    "    train = trainFeature.merge(trainTargetScored, on='sig_id')\n",
    "    test = testFeature.merge(sample_submission, on='sig_id')\n",
    "    \n",
    "    #件のレコードを削除。\n",
    "    train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "    test = test[test['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "    target = train[trainTargetScored.columns]\n",
    "    \n",
    "    #cp_typeは使用しない。(今となっては全て同じ特徴量(trt_cp)であるため)\n",
    "    train = train.drop('cp_type', axis=1)\n",
    "    test = test.drop('cp_type', axis=1)\n",
    "    \n",
    "    #trainFeature,testFeatureに戻す\n",
    "    tmpTraget = trainTargetScored.drop('sig_id', axis=1)\n",
    "    trainFeature = train.drop(tmpTraget.columns, axis=1)\n",
    "    testFeature = test.drop(tmpTraget.columns, axis=1)\n",
    "    \n",
    "    \n",
    "    return trainFeature, testFeature, target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoding(train, test):\n",
    "    #One-Hot Encoding(カテゴリデータをすべてOne-Hot化)\n",
    "    feature_name = ['cp_time','cp_dose']\n",
    "    train, test = prp.OneHot_encode(train, test, feature_name)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLSMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__MULTI SMOTE: 頻度の少ないターゲットに当たるTrainDataをAugumentする手法__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MlSmote(train, target, thrsQlMin):\n",
    "    #trainについている['sig_id']を除いたfeatureを使う。\n",
    "    #(targetも除く)\n",
    "    trainFeatureSMOTE = train.drop(target.columns.values.tolist(), axis=1)\n",
    "    #targetについている['sig_id']を除去。\n",
    "    targetSMOTE = target.iloc[:,1:]\n",
    "    \n",
    "    #MLSMOTE実行\n",
    "    X_sub, y_sub = prp.get_minority_samples(trainFeatureSMOTE, targetSMOTE, ql=[thrsQlMin, 1.])  # ターゲットの頻度が不足のデータを返す。\n",
    "    trainFeatureAug, targetAug = prp.MLSMOTE(X_sub, y_sub, len(X_sub), neigh=5)  # Applying MLSMOTE to augment the dataframe\n",
    "    \n",
    "    #cp_time_*, cp_dose_*で絶対値の大きなものを1,それ以外を0に変更。\n",
    "    \n",
    "    #train,targetの形に成形(targetにsig_idを付与。trainにtargetをくっ付ける。)\n",
    "    #1.targetにsig_idを付与\n",
    "    targetAug[\"sig_id\"] = \"\"\n",
    "    for i in range(len(trainFeatureAug)):\n",
    "        addedId = \"id_MLSMOTE\"+str(i)\n",
    "        targetAug.iloc[i,-1]= addedId\n",
    "    #2.trainにtargetをくっ付ける。\n",
    "    trainAug = pd.concat([trainFeatureAug, targetAug], axis=1)\n",
    "    \n",
    "    #AugmentDataを元のデータにくっ付ける.\n",
    "    train = train.append(trainAug)\n",
    "    target = target.append(targetAug)\n",
    "    \n",
    "    #インデックス整理\n",
    "    train = train.reset_index(drop=True)\n",
    "    target = target.reset_index(drop=True)\n",
    "    \n",
    "    return train, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rankGauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankGauss(trainFeature, testFeature, n_quantiles):\n",
    "    dfTrain = trainFeature.copy()\n",
    "    dfTest = testFeature.copy()\n",
    "    #'g-','c-'が対象。\n",
    "    for col in (GENES + CELLS):\n",
    "        dfTrain[[col]], dfTest[[col]] = prp.rankGauss(trainFeature[[col]], testFeature[[col]],n_quantiles=n_quantiles)\n",
    "    \n",
    "    return dfTrain, dfTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## createCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCluster(trainFeature, testFeature, n_clusters_g=35, n_clusters_c=5):\n",
    "    #\"g-\"と\"c-\"でそれぞれクラスター分析を行う。\n",
    "    features_g = list(trainFeature.columns[4:776])\n",
    "    features_c = list(trainFeature.columns[776:876])\n",
    "    \n",
    "    train = trainFeature.copy()\n",
    "    test = testFeature.copy()\n",
    "    \n",
    "    #実行。\n",
    "    train, test = eda.createClusterKmeans(train, test, features_g, n_clusters=n_clusters_g, kind = 'cluster_g', seed = 0)\n",
    "    train, test = eda.createClusterKmeans(train, test, features_c, n_clusters=n_clusters_c, kind = 'cluster_c', seed = 0)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statsAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statsAdd(trainFeature, testFeature):\n",
    "    features_g = list(trainFeature.columns[4:776])\n",
    "    features_c = list(trainFeature.columns[776:876])\n",
    "    \n",
    "    for df in trainFeature, testFeature:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "    return trainFeature, testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scaling(trainFeature, testFeature):\n",
    "    features = trainFeature.columns[3:]\n",
    "    \n",
    "    #Scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(pd.concat([trainFeature[features], testFeature[features]], axis = 0))\n",
    "    \n",
    "    trainFeature[features] = scaler.transform(trainFeature[features])\n",
    "    testFeature[features] = scaler.transform(testFeature[features])\n",
    "    \n",
    "    return trainFeature, testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train,testにターゲット値も連結__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collecting(trainFeature, testFeature, trainTargetScored):\n",
    "    #Pkey(sig_id)でfeatureとtargetを内部結合。\n",
    "    train = trainFeature.merge(trainTargetScored, on='sig_id')\n",
    "    test = testFeature.merge(sample_submission, on='sig_id')\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(param, trainFeature, testFeature, trainTargetScored):\n",
    "    rankGauss_n_quantiles=int(param['rankGauss_n_quantiles'])\n",
    "    \n",
    "    #statsAdd\n",
    "    trainFeature, testFeature = statsAdd(trainFeature, testFeature)\n",
    "\n",
    "    #createCluster\n",
    "    trainFeature, testFeature = createCluster(trainFeature, testFeature, n_clusters_g=35, n_clusters_c=5)\n",
    "    \n",
    "    #rankGauss\n",
    "    trainFeature, testFeature = rankGauss(trainFeature, testFeature, rankGauss_n_quantiles)\n",
    "    \n",
    "    #PCA成分付与\n",
    "    trainFeature, testFeature = PCA_features_add(trainFeature, testFeature)\n",
    "    \n",
    "    #低分散特徴量除去\n",
    "    trainFeature, testFeature = feature_Selection_using_Variance_Encoding(trainFeature, testFeature)\n",
    "    \n",
    "    #cp_type = ctl_vehicleのレコードを削除.\n",
    "    trainFeature, testFeature, target = drop_ctl_vehicle(trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #Scaler候補２\n",
    "    #trainFeature, testFeature = Scaling(trainFeature, testFeature)\n",
    "    #print(\"trainFeature.shape:\")\n",
    "    #print(trainFeature.shape)\n",
    "    #print(\"trainFeature.column:\")\n",
    "    #print(trainFeature.columns.values.tolist())\n",
    "    \n",
    "    #One-Hot Encoding\n",
    "    trainFeature, testFeature = oneHotEncoding(trainFeature, testFeature)\n",
    "    \n",
    "    #train,testにターゲット値を連結。\n",
    "    train, test = Collecting(trainFeature, testFeature, target)\n",
    "    \n",
    "    \n",
    "    return train, test, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 3s, sys: 1.99 s, total: 2min 5s\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainVsl, testVsl, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTargetScored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>-0.781655</td>\n",
       "      <td>0.261690</td>\n",
       "      <td>-0.779696</td>\n",
       "      <td>0.639290</td>\n",
       "      <td>1.530035</td>\n",
       "      <td>-0.190445</td>\n",
       "      <td>-0.290313</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>-0.438749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>-0.245179</td>\n",
       "      <td>0.416399</td>\n",
       "      <td>1.169205</td>\n",
       "      <td>-0.708885</td>\n",
       "      <td>-0.516660</td>\n",
       "      <td>-0.390634</td>\n",
       "      <td>-2.248303</td>\n",
       "      <td>0.658783</td>\n",
       "      <td>-0.471261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.628909</td>\n",
       "      <td>0.360378</td>\n",
       "      <td>0.366456</td>\n",
       "      <td>0.616820</td>\n",
       "      <td>-0.839884</td>\n",
       "      <td>-1.149103</td>\n",
       "      <td>0.763434</td>\n",
       "      <td>-0.252542</td>\n",
       "      <td>1.089884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>-0.564344</td>\n",
       "      <td>-1.450582</td>\n",
       "      <td>1.657585</td>\n",
       "      <td>0.303089</td>\n",
       "      <td>-0.841500</td>\n",
       "      <td>-0.001290</td>\n",
       "      <td>0.656935</td>\n",
       "      <td>1.007719</td>\n",
       "      <td>0.315749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_006fc47b8</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.901397</td>\n",
       "      <td>-1.025140</td>\n",
       "      <td>-2.118510</td>\n",
       "      <td>0.741403</td>\n",
       "      <td>-0.449726</td>\n",
       "      <td>-0.637563</td>\n",
       "      <td>1.562304</td>\n",
       "      <td>0.458562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id         0         1         2         3         4         5  \\\n",
       "0  id_0004d9e33 -0.781655  0.261690 -0.779696  0.639290  1.530035 -0.190445   \n",
       "1  id_001897cda -0.245179  0.416399  1.169205 -0.708885 -0.516660 -0.390634   \n",
       "2  id_00276f245  0.628909  0.360378  0.366456  0.616820 -0.839884 -1.149103   \n",
       "3  id_0027f1083 -0.564344 -1.450582  1.657585  0.303089 -0.841500 -0.001290   \n",
       "4  id_006fc47b8  0.490500  0.901397 -1.025140 -2.118510  0.741403 -0.449726   \n",
       "\n",
       "          6         7         8  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0 -0.290313  0.375362 -0.438749  ...                                    0.5   \n",
       "1 -2.248303  0.658783 -0.471261  ...                                    0.5   \n",
       "2  0.763434 -0.252542  1.089884  ...                                    0.5   \n",
       "3  0.656935  1.007719  0.315749  ...                                    0.5   \n",
       "4 -0.637563  1.562304  0.458562  ...                                    0.5   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0           0.5              0.5                0.5   \n",
       "1           0.5              0.5                0.5   \n",
       "2           0.5              0.5                0.5   \n",
       "3           0.5              0.5                0.5   \n",
       "4           0.5              0.5                0.5   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                        0.5                                    0.5   \n",
       "1                        0.5                                    0.5   \n",
       "2                        0.5                                    0.5   \n",
       "3                        0.5                                    0.5   \n",
       "4                        0.5                                    0.5   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0              0.5        0.5                         0.5            0.5  \n",
       "1              0.5        0.5                         0.5            0.5  \n",
       "2              0.5        0.5                         0.5            0.5  \n",
       "3              0.5        0.5                         0.5            0.5  \n",
       "4              0.5        0.5                         0.5            0.5  \n",
       "\n",
       "[5 rows x 1159 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_000644bb2                            0                       0   \n",
       "1  id_000779bfc                            0                       0   \n",
       "2  id_000a6266a                            0                       0   \n",
       "3  id_0015fd391                            0                       0   \n",
       "4  id_001626bd3                            0                       0   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0               0                               0   \n",
       "1               0                               0   \n",
       "2               0                               0   \n",
       "3               0                               0   \n",
       "4               0                               0   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                           0  ...                                      0   \n",
       "1                           0  ...                                      0   \n",
       "2                           0  ...                                      0   \n",
       "3                           0  ...                                      0   \n",
       "4                           0  ...                                      0   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0             0                0                  0   \n",
       "1             0                0                  0   \n",
       "2             0                0                  0   \n",
       "3             0                0                  0   \n",
       "4             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                0          0                           0              0  \n",
       "1                0          0                           0              0  \n",
       "2                0          0                           0              0  \n",
       "3                0          0                           0              0  \n",
       "4                0          0                           0              0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                          0.5                     0.5   \n",
       "1  id_001897cda                          0.5                     0.5   \n",
       "2  id_002429b5b                          0.5                     0.5   \n",
       "3  id_00276f245                          0.5                     0.5   \n",
       "4  id_0027f1083                          0.5                     0.5   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0             0.5                             0.5   \n",
       "1             0.5                             0.5   \n",
       "2             0.5                             0.5   \n",
       "3             0.5                             0.5   \n",
       "4             0.5                             0.5   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                0.5                             0.5   \n",
       "1                                0.5                             0.5   \n",
       "2                                0.5                             0.5   \n",
       "3                                0.5                             0.5   \n",
       "4                                0.5                             0.5   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                         0.5                            0.5   \n",
       "1                         0.5                            0.5   \n",
       "2                         0.5                            0.5   \n",
       "3                         0.5                            0.5   \n",
       "4                         0.5                            0.5   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                         0.5  ...                                    0.5   \n",
       "1                         0.5  ...                                    0.5   \n",
       "2                         0.5  ...                                    0.5   \n",
       "3                         0.5  ...                                    0.5   \n",
       "4                         0.5  ...                                    0.5   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0           0.5              0.5                0.5   \n",
       "1           0.5              0.5                0.5   \n",
       "2           0.5              0.5                0.5   \n",
       "3           0.5              0.5                0.5   \n",
       "4           0.5              0.5                0.5   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                        0.5                                    0.5   \n",
       "1                        0.5                                    0.5   \n",
       "2                        0.5                                    0.5   \n",
       "3                        0.5                                    0.5   \n",
       "4                        0.5                                    0.5   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0              0.5        0.5                         0.5            0.5  \n",
       "1              0.5        0.5                         0.5            0.5  \n",
       "2              0.5        0.5                         0.5            0.5  \n",
       "3              0.5        0.5                         0.5            0.5  \n",
       "4              0.5        0.5                         0.5            0.5  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (21948, 1159)\n",
      "Test: (3624, 1159)\n",
      "Target: (21948, 207)\n",
      "sample_submission: (3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \"+ str(trainVsl.shape))\n",
    "print(\"Test: \"+ str(testVsl.shape))\n",
    "print(\"Target: \"+ str(targetVsl.shape))\n",
    "print(\"sample_submission: \"+ str(sample_submission.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config about Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configは辞書化しておく。\n",
    "def Config_about_Fitting(train, test, target, folds):\n",
    "    confFitting = {}\n",
    "    \n",
    "    #Fitするときに\"y\"として使う列の列名配列\n",
    "    confFitting[\"target_cols\"] = target.drop('sig_id', axis=1).columns.values.tolist()\n",
    "    #Fitするときに\"X\"として使う列の列名配列\n",
    "    #kfold, id等はここで削除。\n",
    "    feature_cols = [c for c in folds.columns if c not in confFitting[\"target_cols\"]]\n",
    "    confFitting[\"feature_cols\"] = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "    #特徴量、ターゲットのサイズ\n",
    "    confFitting[\"num_features\"]=len(confFitting[\"feature_cols\"])\n",
    "    confFitting[\"num_targets\"]=len(confFitting[\"target_cols\"])\n",
    "    \n",
    "    return confFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "class LogitsLogLoss(Metric):\n",
    "    \"\"\"\n",
    "    LogLoss with sigmoid applied\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute LogLoss of predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true: np.ndarray\n",
    "            Target matrix or vector\n",
    "        y_score: np.ndarray\n",
    "            Score matrix or vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            float\n",
    "            LogLoss of predictions vs targets.\n",
    "        \"\"\"\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "    def forward(self, x, target, smoothing=0.0001):\n",
    "        confidence = 1. - smoothing\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        bcs_loss = F.binary_cross_entropy_with_logits(x, target)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = confidence * bcs_loss + smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 20\n",
    "EARLY_STOP = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds(train, target):\n",
    "    folds = train.copy()\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "    \n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "        folds.loc[v_idx, 'kfold'] = int(f)\n",
    "    \n",
    "    folds['kfold'] = folds['kfold'].astype(int)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds_drug_id(train, target):\n",
    "    ###drug_idを考慮####\n",
    "    \n",
    "    targets = target.columns[1:]\n",
    "    \n",
    "    # foldsにdrug_id付与\n",
    "    folds = train.copy()\n",
    "    folds = folds.merge(drug, on='sig_id', how='left') \n",
    "    \n",
    "    # LOCATE DRUGS\n",
    "    vc = folds.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc<=18].index.sort_values()\n",
    "    vc2 = vc.loc[vc>18].index.sort_values()\n",
    "    \n",
    "    # STRATIFY DRUGS 18X OR LESS\n",
    "    dct1 = {}; dct2 = {}\n",
    "    skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, \n",
    "              random_state=42)\n",
    "    tmp = folds.groupby('drug_id')[targets].mean().loc[vc1]\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.index[idxV].values}\n",
    "        dct1.update(dd)\n",
    "    \n",
    "    # STRATIFY DRUGS MORE THAN 18X\n",
    "    skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, \n",
    "              random_state=42)\n",
    "    tmp = folds.loc[folds.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "        dct2.update(dd)\n",
    "    \n",
    "    # ASSIGN NFOLDS\n",
    "    folds['kfold'] = folds.drug_id.map(dct1)\n",
    "    folds.loc[folds.kfold.isna(),'kfold'] =\\\n",
    "        folds.loc[folds.kfold.isna(),'sig_id'].map(dct2)\n",
    "    folds.kfold = folds.kfold.astype('int8')\n",
    "    \n",
    "    folds = folds.drop('drug_id', axis=1)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 1.49 s, total: 2min 11s\n",
      "Wall time: 24.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1.134936</td>\n",
       "      <td>0.907607</td>\n",
       "      <td>-0.416090</td>\n",
       "      <td>-0.968042</td>\n",
       "      <td>-0.255626</td>\n",
       "      <td>-1.015203</td>\n",
       "      <td>-1.367034</td>\n",
       "      <td>-0.024938</td>\n",
       "      <td>0.679054</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0.119254</td>\n",
       "      <td>0.682062</td>\n",
       "      <td>0.272262</td>\n",
       "      <td>0.080347</td>\n",
       "      <td>1.203946</td>\n",
       "      <td>0.686698</td>\n",
       "      <td>0.314550</td>\n",
       "      <td>0.554765</td>\n",
       "      <td>-0.537428</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0.779855</td>\n",
       "      <td>0.945910</td>\n",
       "      <td>1.425056</td>\n",
       "      <td>-0.131341</td>\n",
       "      <td>-0.006697</td>\n",
       "      <td>1.492670</td>\n",
       "      <td>0.234401</td>\n",
       "      <td>0.364718</td>\n",
       "      <td>-0.005477</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.735029</td>\n",
       "      <td>-0.274233</td>\n",
       "      <td>-0.438096</td>\n",
       "      <td>0.760073</td>\n",
       "      <td>2.454070</td>\n",
       "      <td>-0.859297</td>\n",
       "      <td>-2.302074</td>\n",
       "      <td>0.308738</td>\n",
       "      <td>-0.192191</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.451791</td>\n",
       "      <td>-0.476988</td>\n",
       "      <td>0.972928</td>\n",
       "      <td>0.971070</td>\n",
       "      <td>1.462687</td>\n",
       "      <td>-0.870623</td>\n",
       "      <td>-0.375908</td>\n",
       "      <td>-0.204468</td>\n",
       "      <td>-1.064448</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id         0         1         2         3         4         5  \\\n",
       "0  id_000644bb2  1.134936  0.907607 -0.416090 -0.968042 -0.255626 -1.015203   \n",
       "1  id_000779bfc  0.119254  0.682062  0.272262  0.080347  1.203946  0.686698   \n",
       "2  id_000a6266a  0.779855  0.945910  1.425056 -0.131341 -0.006697  1.492670   \n",
       "3  id_0015fd391 -0.735029 -0.274233 -0.438096  0.760073  2.454070 -0.859297   \n",
       "4  id_001626bd3 -0.451791 -0.476988  0.972928  0.971070  1.462687 -0.870623   \n",
       "\n",
       "          6         7         8  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0 -1.367034 -0.024938  0.679054  ...             0                0   \n",
       "1  0.314550  0.554765 -0.537428  ...             0                0   \n",
       "2  0.234401  0.364718 -0.005477  ...             0                0   \n",
       "3 -2.302074  0.308738 -0.192191  ...             0                0   \n",
       "4 -0.375908 -0.204468 -1.064448  ...             0                0   \n",
       "\n",
       "   tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                  0                          0   \n",
       "1                  0                          0   \n",
       "2                  0                          0   \n",
       "3                  0                          0   \n",
       "4                  0                          0   \n",
       "\n",
       "   ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                      0                0          0   \n",
       "1                                      0                0          0   \n",
       "2                                      0                0          0   \n",
       "3                                      0                0          0   \n",
       "4                                      0                0          0   \n",
       "\n",
       "   vitamin_d_receptor_agonist  wnt_inhibitor  kfold  \n",
       "0                           0              0      4  \n",
       "1                           0              0      2  \n",
       "2                           0              0      4  \n",
       "3                           0              0      0  \n",
       "4                           0              0      1  \n",
       "\n",
       "[5 rows x 1160 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Preprocessing Data\n",
    "trainVsl, testVsl, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTargetScored)\n",
    "#CV folds\n",
    "foldsVsl = CV_folds_drug_id(trainVsl, targetVsl)\n",
    "\n",
    "foldsVsl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(confFitting, Tester, fold, seed, param,\n",
    "                 folds, train, test, target):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = folds\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[confFitting[\"feature_cols\"]].values, train_df[confFitting[\"target_cols\"]].values\n",
    "    x_valid, y_valid =  valid_df[confFitting[\"feature_cols\"]].values, valid_df[confFitting[\"target_cols\"]].values\n",
    "    \n",
    "    ### Model ###\n",
    "    model_params = dict(\n",
    "        n_d = 32,\n",
    "        n_a = 32,\n",
    "        n_steps = 1,\n",
    "        gamma = 1.3,\n",
    "        lambda_sparse = 0,\n",
    "        optimizer_fn = optim.Adam,\n",
    "        optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n",
    "        mask_type = \"entmax\",\n",
    "        scheduler_params = dict(\n",
    "            mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n",
    "        scheduler_fn = ReduceLROnPlateau,\n",
    "        seed = seed,\n",
    "        verbose = 10)\n",
    "    model = TabNetRegressor(**model_params)\n",
    "    \n",
    "    ##### 評価関数 ######\n",
    "    #train_loss_fn = LabelSmoothingCrossEntropy()\n",
    "    \n",
    "    ### Fit ###\n",
    "    # Another change to the original code\n",
    "    # virtual_batch_size of 32 instead of 128\n",
    "    model.fit(\n",
    "        X_train = x_train,\n",
    "        y_train = y_train,\n",
    "        eval_set = [(x_valid, y_valid)],\n",
    "        eval_name = [\"val\"],\n",
    "        eval_metric = [\"logits_ll\"],\n",
    "        max_epochs = EPOCHS,\n",
    "        patience = EARLY_STOPPING_STEPS,\n",
    "        batch_size = BATCH_SIZE, \n",
    "        virtual_batch_size = 32,\n",
    "        num_workers = 1,\n",
    "        drop_last = False,\n",
    "        # To use binary cross entropy because this is not a regression problem\n",
    "        loss_fn = F.binary_cross_entropy_with_logits\n",
    "        #loss_fn = train_loss_fn\n",
    "    )\n",
    "    \n",
    "    ### Save ###\n",
    "    #dump(model, f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\")\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    oof[val_idx] = 1 / (1 + np.exp(-model.predict(x_valid))) #回帰器なのでsigmoidを通さないといけない？\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    \n",
    "    predictions = np.zeros((len(test), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = 1 / (1 + np.exp(-model.predict(x_test)))\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(Tester, NFOLDS, seed, param,\n",
    "              folds, train, test, target, confFitting):\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        oof_, pred_ = run_training(confFitting, Tester, fold, seed, param,\n",
    "                                   folds, train, test, target)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " def CV_Evaluation(confFitting, oof, train, target):\n",
    "    #CV score : OOFの評価結果。\n",
    "    #OOF(学習モデルによるtrain dataの予測)\n",
    "    train[confFitting[\"target_cols\"]] = oof\n",
    "    #target(予測結果)：ここで処理「cp_type = ctl_vehicleのレコードを削除」で抜けたところに0を入れている。\n",
    "    valid_results = trainTargetScored.drop(columns=confFitting[\"target_cols\"]).merge(train[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    \n",
    "    y_true = trainTargetScored[confFitting[\"target_cols\"]].values\n",
    "    y_pred = valid_results[confFitting[\"target_cols\"]].values\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(confFitting[\"num_targets\"]):\n",
    "        score_ = log_loss(y_true[:, i], y_pred[:, i]) #問題の評価指標によって変わる。\n",
    "        score += score_ / target.shape[1]\n",
    "        \n",
    "    print(\"CV log_loss: \", score)\n",
    "    \n",
    "    #OOF save\n",
    "    np.save(SAVEOOF + 'oof', y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特になし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Submit(confFitting, predictions, test):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Exec(param):\n",
    "    \n",
    "    #Tester(True/False)\n",
    "    Tester = True\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds_drug_id(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3, 4, 5]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 0 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37418 | val_logits_ll: 0.03969 |  0:00:00s\n",
      "epoch 10 | loss: 0.01871 | val_logits_ll: 0.02129 |  0:00:09s\n",
      "epoch 20 | loss: 0.01745 | val_logits_ll: 0.02213 |  0:00:17s\n",
      "epoch 30 | loss: 0.01712 | val_logits_ll: 0.019   |  0:00:26s\n",
      "epoch 40 | loss: 0.01701 | val_logits_ll: 0.01836 |  0:00:34s\n",
      "epoch 50 | loss: 0.01636 | val_logits_ll: 0.01828 |  0:00:43s\n",
      "epoch 60 | loss: 0.01617 | val_logits_ll: 0.01797 |  0:00:52s\n",
      "epoch 70 | loss: 0.01585 | val_logits_ll: 0.01855 |  0:01:00s\n",
      "epoch 80 | loss: 0.01557 | val_logits_ll: 0.01811 |  0:01:09s\n",
      "\n",
      "Early stopping occured at epoch 82 with best_epoch = 62 and best_val_logits_ll = 0.01785\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37348 | val_logits_ll: 0.03868 |  0:00:00s\n",
      "epoch 10 | loss: 0.01905 | val_logits_ll: 0.02062 |  0:00:09s\n",
      "epoch 20 | loss: 0.01753 | val_logits_ll: 0.02188 |  0:00:18s\n",
      "epoch 30 | loss: 0.01694 | val_logits_ll: 0.01926 |  0:00:26s\n",
      "epoch 40 | loss: 0.01639 | val_logits_ll: 0.01761 |  0:00:35s\n",
      "epoch 50 | loss: 0.01619 | val_logits_ll: 0.01926 |  0:00:43s\n",
      "epoch 60 | loss: 0.01573 | val_logits_ll: 0.0176  |  0:00:52s\n",
      "\n",
      "Early stopping occured at epoch 68 with best_epoch = 48 and best_val_logits_ll = 0.01724\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37545 | val_logits_ll: 0.03966 |  0:00:00s\n",
      "epoch 10 | loss: 0.0192  | val_logits_ll: 0.01923 |  0:00:09s\n",
      "epoch 20 | loss: 0.01764 | val_logits_ll: 0.01843 |  0:00:18s\n",
      "epoch 30 | loss: 0.01689 | val_logits_ll: 0.01787 |  0:00:26s\n",
      "epoch 40 | loss: 0.01685 | val_logits_ll: 0.01828 |  0:00:35s\n",
      "epoch 50 | loss: 0.01627 | val_logits_ll: 0.01788 |  0:00:43s\n",
      "epoch 60 | loss: 0.0159  | val_logits_ll: 0.01792 |  0:00:52s\n",
      "\n",
      "Early stopping occured at epoch 65 with best_epoch = 45 and best_val_logits_ll = 0.01761\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3741  | val_logits_ll: 0.04147 |  0:00:00s\n",
      "epoch 10 | loss: 0.01924 | val_logits_ll: 0.01903 |  0:00:09s\n",
      "epoch 20 | loss: 0.01745 | val_logits_ll: 0.0204  |  0:00:18s\n",
      "epoch 30 | loss: 0.01683 | val_logits_ll: 0.01815 |  0:00:26s\n",
      "epoch 40 | loss: 0.01678 | val_logits_ll: 0.01814 |  0:00:35s\n",
      "epoch 50 | loss: 0.01647 | val_logits_ll: 0.01757 |  0:00:44s\n",
      "epoch 60 | loss: 0.01562 | val_logits_ll: 0.01801 |  0:00:52s\n",
      "\n",
      "Early stopping occured at epoch 65 with best_epoch = 45 and best_val_logits_ll = 0.01749\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37443 | val_logits_ll: 0.0393  |  0:00:00s\n",
      "epoch 10 | loss: 0.01945 | val_logits_ll: 0.01957 |  0:00:09s\n",
      "epoch 20 | loss: 0.01751 | val_logits_ll: 0.0214  |  0:00:17s\n",
      "epoch 30 | loss: 0.01703 | val_logits_ll: 0.01798 |  0:00:26s\n",
      "epoch 40 | loss: 0.01681 | val_logits_ll: 0.01867 |  0:00:34s\n",
      "epoch 50 | loss: 0.01631 | val_logits_ll: 0.01836 |  0:00:43s\n",
      "epoch 60 | loss: 0.01624 | val_logits_ll: 0.01774 |  0:00:52s\n",
      "epoch 70 | loss: 0.01564 | val_logits_ll: 0.01811 |  0:01:00s\n",
      "epoch 80 | loss: 0.01539 | val_logits_ll: 0.01786 |  0:01:08s\n",
      "\n",
      "Early stopping occured at epoch 83 with best_epoch = 63 and best_val_logits_ll = 0.01762\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 1 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.39205 | val_logits_ll: 0.04735 |  0:00:00s\n",
      "epoch 10 | loss: 0.01925 | val_logits_ll: 0.0218  |  0:00:09s\n",
      "epoch 20 | loss: 0.01745 | val_logits_ll: 0.02274 |  0:00:17s\n",
      "epoch 30 | loss: 0.01707 | val_logits_ll: 0.0184  |  0:00:26s\n",
      "epoch 40 | loss: 0.01663 | val_logits_ll: 0.01815 |  0:00:35s\n",
      "epoch 50 | loss: 0.0162  | val_logits_ll: 0.01813 |  0:00:43s\n",
      "epoch 60 | loss: 0.01609 | val_logits_ll: 0.01824 |  0:00:52s\n",
      "epoch 70 | loss: 0.01559 | val_logits_ll: 0.01783 |  0:01:00s\n",
      "epoch 80 | loss: 0.01525 | val_logits_ll: 0.018   |  0:01:09s\n",
      "\n",
      "Early stopping occured at epoch 89 with best_epoch = 69 and best_val_logits_ll = 0.01776\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38563 | val_logits_ll: 0.04573 |  0:00:00s\n",
      "epoch 10 | loss: 0.01928 | val_logits_ll: 0.0192  |  0:00:09s\n",
      "epoch 20 | loss: 0.01762 | val_logits_ll: 0.01806 |  0:00:17s\n",
      "epoch 30 | loss: 0.01733 | val_logits_ll: 0.01882 |  0:00:26s\n",
      "epoch 40 | loss: 0.01687 | val_logits_ll: 0.01784 |  0:00:35s\n",
      "epoch 50 | loss: 0.01642 | val_logits_ll: 0.0174  |  0:00:44s\n",
      "epoch 60 | loss: 0.01612 | val_logits_ll: 0.01761 |  0:00:53s\n",
      "\n",
      "Early stopping occured at epoch 63 with best_epoch = 43 and best_val_logits_ll = 0.01733\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38475 | val_logits_ll: 0.04451 |  0:00:00s\n",
      "epoch 10 | loss: 0.01891 | val_logits_ll: 0.01896 |  0:00:09s\n",
      "epoch 20 | loss: 0.01748 | val_logits_ll: 0.01808 |  0:00:18s\n",
      "epoch 30 | loss: 0.01697 | val_logits_ll: 0.01792 |  0:00:26s\n",
      "epoch 40 | loss: 0.01644 | val_logits_ll: 0.01792 |  0:00:35s\n",
      "epoch 50 | loss: 0.01654 | val_logits_ll: 0.01779 |  0:00:44s\n",
      "epoch 60 | loss: 0.0162  | val_logits_ll: 0.01827 |  0:00:52s\n",
      "epoch 70 | loss: 0.01546 | val_logits_ll: 0.018   |  0:01:01s\n",
      "\n",
      "Early stopping occured at epoch 74 with best_epoch = 54 and best_val_logits_ll = 0.01756\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38276 | val_logits_ll: 0.04244 |  0:00:00s\n",
      "epoch 10 | loss: 0.01942 | val_logits_ll: 0.01918 |  0:00:09s\n",
      "epoch 20 | loss: 0.01747 | val_logits_ll: 0.02234 |  0:00:18s\n",
      "epoch 30 | loss: 0.01704 | val_logits_ll: 0.01811 |  0:00:26s\n",
      "epoch 40 | loss: 0.01664 | val_logits_ll: 0.01767 |  0:00:35s\n",
      "epoch 50 | loss: 0.01647 | val_logits_ll: 0.01783 |  0:00:43s\n",
      "epoch 60 | loss: 0.01606 | val_logits_ll: 0.01771 |  0:00:52s\n",
      "\n",
      "Early stopping occured at epoch 66 with best_epoch = 46 and best_val_logits_ll = 0.01751\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38464 | val_logits_ll: 0.0445  |  0:00:00s\n",
      "epoch 10 | loss: 0.01942 | val_logits_ll: 0.02163 |  0:00:09s\n",
      "epoch 20 | loss: 0.01763 | val_logits_ll: 0.02231 |  0:00:17s\n",
      "epoch 30 | loss: 0.01722 | val_logits_ll: 0.0184  |  0:00:26s\n",
      "epoch 40 | loss: 0.01671 | val_logits_ll: 0.01807 |  0:00:34s\n",
      "epoch 50 | loss: 0.01645 | val_logits_ll: 0.018   |  0:00:43s\n",
      "epoch 60 | loss: 0.01594 | val_logits_ll: 0.01799 |  0:00:52s\n",
      "epoch 70 | loss: 0.01567 | val_logits_ll: 0.01783 |  0:01:00s\n",
      "epoch 80 | loss: 0.01531 | val_logits_ll: 0.01785 |  0:01:09s\n",
      "\n",
      "Early stopping occured at epoch 87 with best_epoch = 67 and best_val_logits_ll = 0.01761\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 2 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37767 | val_logits_ll: 0.0406  |  0:00:00s\n",
      "epoch 10 | loss: 0.01911 | val_logits_ll: 0.02031 |  0:00:09s\n",
      "epoch 20 | loss: 0.0178  | val_logits_ll: 0.02245 |  0:00:18s\n",
      "epoch 30 | loss: 0.01729 | val_logits_ll: 0.02096 |  0:00:26s\n",
      "epoch 40 | loss: 0.01706 | val_logits_ll: 0.01849 |  0:00:35s\n",
      "epoch 50 | loss: 0.01643 | val_logits_ll: 0.01811 |  0:00:43s\n",
      "epoch 60 | loss: 0.01621 | val_logits_ll: 0.01819 |  0:00:52s\n",
      "epoch 70 | loss: 0.01595 | val_logits_ll: 0.01799 |  0:01:01s\n",
      "\n",
      "Early stopping occured at epoch 74 with best_epoch = 54 and best_val_logits_ll = 0.01781\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38126 | val_logits_ll: 0.04181 |  0:00:00s\n",
      "epoch 10 | loss: 0.0196  | val_logits_ll: 0.01893 |  0:00:09s\n",
      "epoch 20 | loss: 0.01784 | val_logits_ll: 0.01988 |  0:00:18s\n",
      "epoch 30 | loss: 0.01734 | val_logits_ll: 0.01779 |  0:00:26s\n",
      "epoch 40 | loss: 0.01712 | val_logits_ll: 0.01778 |  0:00:35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 | loss: 0.01669 | val_logits_ll: 0.01753 |  0:00:43s\n",
      "epoch 60 | loss: 0.01642 | val_logits_ll: 0.01736 |  0:00:52s\n",
      "\n",
      "Early stopping occured at epoch 68 with best_epoch = 48 and best_val_logits_ll = 0.01726\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38265 | val_logits_ll: 0.04597 |  0:00:00s\n",
      "epoch 10 | loss: 0.01944 | val_logits_ll: 0.01968 |  0:00:09s\n",
      "epoch 20 | loss: 0.01753 | val_logits_ll: 0.02239 |  0:00:18s\n",
      "epoch 30 | loss: 0.01682 | val_logits_ll: 0.01797 |  0:00:26s\n",
      "epoch 40 | loss: 0.01667 | val_logits_ll: 0.01819 |  0:00:35s\n",
      "epoch 50 | loss: 0.01636 | val_logits_ll: 0.01779 |  0:00:44s\n",
      "epoch 60 | loss: 0.01615 | val_logits_ll: 0.0177  |  0:00:52s\n",
      "epoch 70 | loss: 0.01599 | val_logits_ll: 0.01767 |  0:01:01s\n",
      "epoch 80 | loss: 0.0155  | val_logits_ll: 0.01751 |  0:01:10s\n",
      "\n",
      "Early stopping occured at epoch 84 with best_epoch = 64 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38268 | val_logits_ll: 0.04462 |  0:00:00s\n",
      "epoch 10 | loss: 0.01938 | val_logits_ll: 0.01898 |  0:00:09s\n",
      "epoch 20 | loss: 0.01764 | val_logits_ll: 0.02149 |  0:00:18s\n",
      "epoch 30 | loss: 0.01674 | val_logits_ll: 0.01795 |  0:00:27s\n",
      "epoch 40 | loss: 0.01648 | val_logits_ll: 0.01804 |  0:00:35s\n",
      "epoch 50 | loss: 0.01641 | val_logits_ll: 0.01751 |  0:00:44s\n",
      "epoch 60 | loss: 0.01582 | val_logits_ll: 0.01754 |  0:00:53s\n",
      "epoch 70 | loss: 0.01552 | val_logits_ll: 0.01767 |  0:01:01s\n",
      "\n",
      "Early stopping occured at epoch 79 with best_epoch = 59 and best_val_logits_ll = 0.01739\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38514 | val_logits_ll: 0.04558 |  0:00:00s\n",
      "epoch 10 | loss: 0.01955 | val_logits_ll: 0.02069 |  0:00:09s\n",
      "epoch 20 | loss: 0.01781 | val_logits_ll: 0.01993 |  0:00:18s\n",
      "epoch 30 | loss: 0.01742 | val_logits_ll: 0.01806 |  0:00:26s\n",
      "epoch 40 | loss: 0.01672 | val_logits_ll: 0.01805 |  0:00:35s\n",
      "epoch 50 | loss: 0.01626 | val_logits_ll: 0.01778 |  0:00:43s\n",
      "epoch 60 | loss: 0.01597 | val_logits_ll: 0.01817 |  0:00:52s\n",
      "epoch 70 | loss: 0.01577 | val_logits_ll: 0.01783 |  0:01:01s\n",
      "epoch 80 | loss: 0.01575 | val_logits_ll: 0.01768 |  0:01:09s\n",
      "epoch 90 | loss: 0.01491 | val_logits_ll: 0.01806 |  0:01:18s\n",
      "\n",
      "Early stopping occured at epoch 93 with best_epoch = 73 and best_val_logits_ll = 0.01765\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 3 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.35813 | val_logits_ll: 0.03638 |  0:00:00s\n",
      "epoch 10 | loss: 0.01916 | val_logits_ll: 0.01995 |  0:00:09s\n",
      "epoch 20 | loss: 0.0177  | val_logits_ll: 0.02157 |  0:00:18s\n",
      "epoch 30 | loss: 0.01717 | val_logits_ll: 0.01858 |  0:00:26s\n",
      "epoch 40 | loss: 0.01689 | val_logits_ll: 0.01816 |  0:00:35s\n",
      "epoch 50 | loss: 0.0166  | val_logits_ll: 0.01788 |  0:00:44s\n",
      "epoch 60 | loss: 0.01621 | val_logits_ll: 0.01813 |  0:00:53s\n",
      "epoch 70 | loss: 0.01572 | val_logits_ll: 0.01791 |  0:01:01s\n",
      "epoch 80 | loss: 0.01539 | val_logits_ll: 0.01789 |  0:01:10s\n",
      "\n",
      "Early stopping occured at epoch 86 with best_epoch = 66 and best_val_logits_ll = 0.01778\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3578  | val_logits_ll: 0.03641 |  0:00:00s\n",
      "epoch 10 | loss: 0.01909 | val_logits_ll: 0.01928 |  0:00:10s\n",
      "epoch 20 | loss: 0.01767 | val_logits_ll: 0.01889 |  0:00:20s\n",
      "epoch 30 | loss: 0.0172  | val_logits_ll: 0.01771 |  0:00:30s\n",
      "epoch 40 | loss: 0.01672 | val_logits_ll: 0.01753 |  0:00:39s\n",
      "epoch 50 | loss: 0.01648 | val_logits_ll: 0.01788 |  0:00:49s\n",
      "epoch 60 | loss: 0.01618 | val_logits_ll: 0.01778 |  0:00:59s\n",
      "epoch 70 | loss: 0.01598 | val_logits_ll: 0.01775 |  0:01:09s\n",
      "\n",
      "Early stopping occured at epoch 79 with best_epoch = 59 and best_val_logits_ll = 0.01727\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.35554 | val_logits_ll: 0.03563 |  0:00:00s\n",
      "epoch 10 | loss: 0.01893 | val_logits_ll: 0.01987 |  0:00:10s\n",
      "epoch 20 | loss: 0.01743 | val_logits_ll: 0.02149 |  0:00:19s\n",
      "epoch 30 | loss: 0.01691 | val_logits_ll: 0.01789 |  0:00:29s\n",
      "epoch 40 | loss: 0.01652 | val_logits_ll: 0.01807 |  0:00:38s\n",
      "epoch 50 | loss: 0.01614 | val_logits_ll: 0.01774 |  0:00:48s\n",
      "epoch 60 | loss: 0.01585 | val_logits_ll: 0.01782 |  0:00:57s\n",
      "epoch 70 | loss: 0.01543 | val_logits_ll: 0.01764 |  0:01:07s\n",
      "\n",
      "Early stopping occured at epoch 75 with best_epoch = 55 and best_val_logits_ll = 0.01747\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.35454 | val_logits_ll: 0.03627 |  0:00:00s\n",
      "epoch 10 | loss: 0.01895 | val_logits_ll: 0.01892 |  0:00:09s\n",
      "epoch 20 | loss: 0.01773 | val_logits_ll: 0.01966 |  0:00:18s\n",
      "epoch 30 | loss: 0.01677 | val_logits_ll: 0.01873 |  0:00:26s\n",
      "epoch 40 | loss: 0.01634 | val_logits_ll: 0.01763 |  0:00:35s\n",
      "epoch 50 | loss: 0.01607 | val_logits_ll: 0.01769 |  0:00:44s\n",
      "epoch 60 | loss: 0.01576 | val_logits_ll: 0.01746 |  0:00:52s\n",
      "\n",
      "Early stopping occured at epoch 69 with best_epoch = 49 and best_val_logits_ll = 0.01738\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36025 | val_logits_ll: 0.03908 |  0:00:00s\n",
      "epoch 10 | loss: 0.01917 | val_logits_ll: 0.0193  |  0:00:09s\n",
      "epoch 20 | loss: 0.01758 | val_logits_ll: 0.02085 |  0:00:17s\n",
      "epoch 30 | loss: 0.01705 | val_logits_ll: 0.01794 |  0:00:26s\n",
      "epoch 40 | loss: 0.01689 | val_logits_ll: 0.01824 |  0:00:34s\n",
      "epoch 50 | loss: 0.01625 | val_logits_ll: 0.01786 |  0:00:43s\n",
      "epoch 60 | loss: 0.01603 | val_logits_ll: 0.018   |  0:00:51s\n",
      "epoch 70 | loss: 0.01547 | val_logits_ll: 0.01787 |  0:01:00s\n",
      "\n",
      "Early stopping occured at epoch 76 with best_epoch = 56 and best_val_logits_ll = 0.01769\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 4 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37894 | val_logits_ll: 0.04418 |  0:00:00s\n",
      "epoch 10 | loss: 0.0197  | val_logits_ll: 0.02199 |  0:00:09s\n",
      "epoch 20 | loss: 0.01746 | val_logits_ll: 0.0186  |  0:00:17s\n",
      "epoch 30 | loss: 0.01714 | val_logits_ll: 0.01844 |  0:00:26s\n",
      "epoch 40 | loss: 0.0167  | val_logits_ll: 0.01828 |  0:00:34s\n",
      "epoch 50 | loss: 0.01635 | val_logits_ll: 0.01796 |  0:00:43s\n",
      "epoch 60 | loss: 0.01623 | val_logits_ll: 0.01787 |  0:00:51s\n",
      "epoch 70 | loss: 0.01575 | val_logits_ll: 0.01788 |  0:01:00s\n",
      "\n",
      "Early stopping occured at epoch 77 with best_epoch = 57 and best_val_logits_ll = 0.01773\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3815  | val_logits_ll: 0.046   |  0:00:00s\n",
      "epoch 10 | loss: 0.0192  | val_logits_ll: 0.02093 |  0:00:09s\n",
      "epoch 20 | loss: 0.01774 | val_logits_ll: 0.02073 |  0:00:17s\n",
      "epoch 30 | loss: 0.01701 | val_logits_ll: 0.02047 |  0:00:26s\n",
      "epoch 40 | loss: 0.01668 | val_logits_ll: 0.01775 |  0:00:35s\n",
      "epoch 50 | loss: 0.01615 | val_logits_ll: 0.01781 |  0:00:43s\n",
      "epoch 60 | loss: 0.01594 | val_logits_ll: 0.01816 |  0:00:52s\n",
      "epoch 70 | loss: 0.01552 | val_logits_ll: 0.01774 |  0:01:01s\n",
      "\n",
      "Early stopping occured at epoch 74 with best_epoch = 54 and best_val_logits_ll = 0.01741\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38122 | val_logits_ll: 0.04479 |  0:00:00s\n",
      "epoch 10 | loss: 0.01989 | val_logits_ll: 0.01993 |  0:00:09s\n",
      "epoch 20 | loss: 0.01791 | val_logits_ll: 0.01863 |  0:00:18s\n",
      "epoch 30 | loss: 0.01703 | val_logits_ll: 0.01821 |  0:00:26s\n",
      "epoch 40 | loss: 0.01668 | val_logits_ll: 0.01774 |  0:00:35s\n",
      "epoch 50 | loss: 0.01649 | val_logits_ll: 0.01782 |  0:00:44s\n",
      "epoch 60 | loss: 0.01601 | val_logits_ll: 0.01777 |  0:00:52s\n",
      "\n",
      "Early stopping occured at epoch 68 with best_epoch = 48 and best_val_logits_ll = 0.0176\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38114 | val_logits_ll: 0.04662 |  0:00:00s\n",
      "epoch 10 | loss: 0.01974 | val_logits_ll: 0.01979 |  0:00:09s\n",
      "epoch 20 | loss: 0.01775 | val_logits_ll: 0.02166 |  0:00:18s\n",
      "epoch 30 | loss: 0.01709 | val_logits_ll: 0.01798 |  0:00:26s\n",
      "epoch 40 | loss: 0.01658 | val_logits_ll: 0.01774 |  0:00:35s\n",
      "epoch 50 | loss: 0.01621 | val_logits_ll: 0.01757 |  0:00:43s\n",
      "epoch 60 | loss: 0.01606 | val_logits_ll: 0.01767 |  0:00:52s\n",
      "epoch 70 | loss: 0.01579 | val_logits_ll: 0.01787 |  0:01:01s\n",
      "\n",
      "Early stopping occured at epoch 79 with best_epoch = 59 and best_val_logits_ll = 0.01744\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37815 | val_logits_ll: 0.04261 |  0:00:00s\n",
      "epoch 10 | loss: 0.01909 | val_logits_ll: 0.01918 |  0:00:09s\n",
      "epoch 20 | loss: 0.01763 | val_logits_ll: 0.01811 |  0:00:18s\n",
      "epoch 30 | loss: 0.01702 | val_logits_ll: 0.02186 |  0:00:27s\n",
      "epoch 40 | loss: 0.01675 | val_logits_ll: 0.0184  |  0:00:36s\n",
      "epoch 50 | loss: 0.01608 | val_logits_ll: 0.01775 |  0:00:45s\n",
      "epoch 60 | loss: 0.01581 | val_logits_ll: 0.01773 |  0:00:53s\n",
      "epoch 70 | loss: 0.01568 | val_logits_ll: 0.01777 |  0:01:02s\n",
      "epoch 80 | loss: 0.01512 | val_logits_ll: 0.01793 |  0:01:11s\n",
      "\n",
      "Early stopping occured at epoch 86 with best_epoch = 66 and best_val_logits_ll = 0.0176\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 5 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36691 | val_logits_ll: 0.0398  |  0:00:00s\n",
      "epoch 10 | loss: 0.01923 | val_logits_ll: 0.02154 |  0:00:09s\n",
      "epoch 20 | loss: 0.0177  | val_logits_ll: 0.01842 |  0:00:18s\n",
      "epoch 30 | loss: 0.01739 | val_logits_ll: 0.01814 |  0:00:27s\n",
      "epoch 40 | loss: 0.01697 | val_logits_ll: 0.01811 |  0:00:36s\n",
      "epoch 50 | loss: 0.01674 | val_logits_ll: 0.01819 |  0:00:45s\n",
      "epoch 60 | loss: 0.01645 | val_logits_ll: 0.01786 |  0:00:53s\n",
      "epoch 70 | loss: 0.01633 | val_logits_ll: 0.01807 |  0:01:02s\n",
      "epoch 80 | loss: 0.01607 | val_logits_ll: 0.0182  |  0:01:11s\n",
      "epoch 90 | loss: 0.01588 | val_logits_ll: 0.01787 |  0:01:20s\n",
      "epoch 100| loss: 0.01552 | val_logits_ll: 0.01784 |  0:01:29s\n",
      "\n",
      "Early stopping occured at epoch 104 with best_epoch = 84 and best_val_logits_ll = 0.01777\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36951 | val_logits_ll: 0.03955 |  0:00:00s\n",
      "epoch 10 | loss: 0.01942 | val_logits_ll: 0.019   |  0:00:09s\n",
      "epoch 20 | loss: 0.01763 | val_logits_ll: 0.02073 |  0:00:18s\n",
      "epoch 30 | loss: 0.01714 | val_logits_ll: 0.01771 |  0:00:27s\n",
      "epoch 40 | loss: 0.01686 | val_logits_ll: 0.01748 |  0:00:36s\n",
      "epoch 50 | loss: 0.01647 | val_logits_ll: 0.01766 |  0:00:44s\n",
      "epoch 60 | loss: 0.01617 | val_logits_ll: 0.01757 |  0:00:53s\n",
      "epoch 70 | loss: 0.01594 | val_logits_ll: 0.01776 |  0:01:01s\n",
      "\n",
      "Early stopping occured at epoch 78 with best_epoch = 58 and best_val_logits_ll = 0.0174\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3684  | val_logits_ll: 0.04059 |  0:00:00s\n",
      "epoch 10 | loss: 0.01935 | val_logits_ll: 0.01945 |  0:00:09s\n",
      "epoch 20 | loss: 0.01775 | val_logits_ll: 0.021   |  0:00:18s\n",
      "epoch 30 | loss: 0.0171  | val_logits_ll: 0.01839 |  0:00:26s\n",
      "epoch 40 | loss: 0.01669 | val_logits_ll: 0.01793 |  0:00:35s\n",
      "epoch 50 | loss: 0.01636 | val_logits_ll: 0.01786 |  0:00:44s\n",
      "epoch 60 | loss: 0.01612 | val_logits_ll: 0.01778 |  0:00:52s\n",
      "epoch 70 | loss: 0.01581 | val_logits_ll: 0.0178  |  0:01:01s\n",
      "\n",
      "Early stopping occured at epoch 74 with best_epoch = 54 and best_val_logits_ll = 0.01755\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36728 | val_logits_ll: 0.03916 |  0:00:00s\n",
      "epoch 10 | loss: 0.0194  | val_logits_ll: 0.01908 |  0:00:09s\n",
      "epoch 20 | loss: 0.01764 | val_logits_ll: 0.02121 |  0:00:18s\n",
      "epoch 30 | loss: 0.01707 | val_logits_ll: 0.01774 |  0:00:26s\n",
      "epoch 40 | loss: 0.01689 | val_logits_ll: 0.01806 |  0:00:35s\n",
      "epoch 50 | loss: 0.01641 | val_logits_ll: 0.01748 |  0:00:43s\n",
      "epoch 60 | loss: 0.01613 | val_logits_ll: 0.01752 |  0:00:52s\n",
      "epoch 70 | loss: 0.01582 | val_logits_ll: 0.01763 |  0:01:01s\n",
      "\n",
      "Early stopping occured at epoch 76 with best_epoch = 56 and best_val_logits_ll = 0.01744\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36822 | val_logits_ll: 0.04255 |  0:00:00s\n",
      "epoch 10 | loss: 0.01905 | val_logits_ll: 0.02085 |  0:00:09s\n",
      "epoch 20 | loss: 0.01756 | val_logits_ll: 0.02011 |  0:00:18s\n",
      "epoch 30 | loss: 0.01688 | val_logits_ll: 0.01792 |  0:00:26s\n",
      "epoch 40 | loss: 0.01661 | val_logits_ll: 0.01799 |  0:00:35s\n",
      "epoch 50 | loss: 0.01628 | val_logits_ll: 0.0179  |  0:00:43s\n",
      "epoch 60 | loss: 0.01586 | val_logits_ll: 0.01798 |  0:00:52s\n",
      "\n",
      "Early stopping occured at epoch 66 with best_epoch = 46 and best_val_logits_ll = 0.01774\n",
      "Best weights from best epoch are automatically used!\n",
      "CV log_loss:  0.015624473906583655\n",
      "sub.shape(3982, 207)\n",
      "CPU times: user 32min 9s, sys: 2min 40s, total: 34min 50s\n",
      "Wall time: 34min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score= Exec(param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.015624473906583655\n"
     ]
    }
   ],
   "source": [
    "print(\"score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 0 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37286 | val_logits_ll: 0.04157 |  0:00:00s\n",
      "epoch 10 | loss: 0.01955 | val_logits_ll: 0.01907 |  0:00:10s\n",
      "epoch 20 | loss: 0.01769 | val_logits_ll: 0.01921 |  0:00:18s\n",
      "epoch 30 | loss: 0.01728 | val_logits_ll: 0.01861 |  0:00:27s\n",
      "epoch 40 | loss: 0.01692 | val_logits_ll: 0.0173  |  0:00:36s\n",
      "epoch 50 | loss: 0.01659 | val_logits_ll: 0.01697 |  0:00:45s\n",
      "epoch 60 | loss: 0.01637 | val_logits_ll: 0.01687 |  0:00:53s\n",
      "epoch 70 | loss: 0.0161  | val_logits_ll: 0.01752 |  0:01:02s\n",
      "epoch 80 | loss: 0.01565 | val_logits_ll: 0.01665 |  0:01:11s\n",
      "epoch 90 | loss: 0.01547 | val_logits_ll: 0.01666 |  0:01:20s\n",
      "epoch 100| loss: 0.01493 | val_logits_ll: 0.01685 |  0:01:29s\n",
      "\n",
      "Early stopping occured at epoch 106 with best_epoch = 86 and best_val_logits_ll = 0.01657\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37356 | val_logits_ll: 0.04124 |  0:00:00s\n",
      "epoch 10 | loss: 0.01927 | val_logits_ll: 0.01897 |  0:00:09s\n",
      "epoch 20 | loss: 0.01765 | val_logits_ll: 0.02289 |  0:00:18s\n",
      "epoch 30 | loss: 0.01731 | val_logits_ll: 0.01765 |  0:00:27s\n",
      "epoch 40 | loss: 0.01713 | val_logits_ll: 0.01748 |  0:00:36s\n",
      "epoch 50 | loss: 0.01696 | val_logits_ll: 0.01709 |  0:00:45s\n",
      "epoch 60 | loss: 0.01666 | val_logits_ll: 0.01708 |  0:00:54s\n",
      "epoch 70 | loss: 0.01635 | val_logits_ll: 0.01701 |  0:01:02s\n",
      "epoch 80 | loss: 0.01639 | val_logits_ll: 0.01692 |  0:01:11s\n",
      "epoch 90 | loss: 0.01607 | val_logits_ll: 0.01677 |  0:01:20s\n",
      "epoch 100| loss: 0.01607 | val_logits_ll: 0.01693 |  0:01:29s\n",
      "epoch 110| loss: 0.01602 | val_logits_ll: 0.01689 |  0:01:38s\n",
      "epoch 120| loss: 0.01564 | val_logits_ll: 0.01672 |  0:01:46s\n",
      "epoch 130| loss: 0.0154  | val_logits_ll: 0.01676 |  0:01:55s\n",
      "epoch 140| loss: 0.01516 | val_logits_ll: 0.0169  |  0:02:04s\n",
      "\n",
      "Early stopping occured at epoch 142 with best_epoch = 122 and best_val_logits_ll = 0.01671\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37592 | val_logits_ll: 0.03824 |  0:00:00s\n",
      "epoch 10 | loss: 0.01896 | val_logits_ll: 0.01932 |  0:00:09s\n",
      "epoch 20 | loss: 0.01749 | val_logits_ll: 0.02134 |  0:00:18s\n",
      "epoch 30 | loss: 0.0172  | val_logits_ll: 0.01873 |  0:00:27s\n",
      "epoch 40 | loss: 0.0168  | val_logits_ll: 0.01718 |  0:00:36s\n",
      "epoch 50 | loss: 0.01643 | val_logits_ll: 0.017   |  0:00:45s\n",
      "epoch 60 | loss: 0.01634 | val_logits_ll: 0.01703 |  0:00:54s\n",
      "epoch 70 | loss: 0.01603 | val_logits_ll: 0.01696 |  0:01:02s\n",
      "epoch 80 | loss: 0.01578 | val_logits_ll: 0.01687 |  0:01:11s\n",
      "epoch 90 | loss: 0.01541 | val_logits_ll: 0.01665 |  0:01:20s\n",
      "epoch 100| loss: 0.01524 | val_logits_ll: 0.01698 |  0:01:30s\n",
      "\n",
      "Early stopping occured at epoch 102 with best_epoch = 82 and best_val_logits_ll = 0.01665\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37527 | val_logits_ll: 0.04095 |  0:00:00s\n",
      "epoch 10 | loss: 0.0195  | val_logits_ll: 0.0195  |  0:00:09s\n",
      "epoch 20 | loss: 0.01778 | val_logits_ll: 0.02022 |  0:00:18s\n",
      "epoch 30 | loss: 0.01736 | val_logits_ll: 0.02004 |  0:00:27s\n",
      "epoch 40 | loss: 0.01687 | val_logits_ll: 0.01912 |  0:00:36s\n",
      "epoch 50 | loss: 0.01641 | val_logits_ll: 0.01695 |  0:00:45s\n",
      "epoch 60 | loss: 0.01636 | val_logits_ll: 0.01703 |  0:00:54s\n",
      "epoch 70 | loss: 0.01598 | val_logits_ll: 0.01694 |  0:01:03s\n",
      "epoch 80 | loss: 0.01581 | val_logits_ll: 0.01684 |  0:01:12s\n",
      "epoch 90 | loss: 0.01553 | val_logits_ll: 0.01682 |  0:01:21s\n",
      "epoch 100| loss: 0.01508 | val_logits_ll: 0.0169  |  0:01:30s\n",
      "epoch 110| loss: 0.01473 | val_logits_ll: 0.01697 |  0:01:39s\n",
      "\n",
      "Early stopping occured at epoch 119 with best_epoch = 99 and best_val_logits_ll = 0.01675\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37564 | val_logits_ll: 0.04145 |  0:00:00s\n",
      "epoch 10 | loss: 0.01902 | val_logits_ll: 0.0196  |  0:00:09s\n",
      "epoch 20 | loss: 0.0178  | val_logits_ll: 0.02292 |  0:00:19s\n",
      "epoch 30 | loss: 0.01739 | val_logits_ll: 0.01989 |  0:00:28s\n",
      "epoch 40 | loss: 0.01682 | val_logits_ll: 0.01755 |  0:00:37s\n",
      "epoch 50 | loss: 0.01659 | val_logits_ll: 0.01711 |  0:00:46s\n",
      "epoch 60 | loss: 0.01621 | val_logits_ll: 0.01714 |  0:00:55s\n",
      "epoch 70 | loss: 0.01614 | val_logits_ll: 0.01692 |  0:01:04s\n",
      "epoch 80 | loss: 0.01581 | val_logits_ll: 0.01685 |  0:01:13s\n",
      "epoch 90 | loss: 0.01556 | val_logits_ll: 0.01687 |  0:01:22s\n",
      "epoch 100| loss: 0.01531 | val_logits_ll: 0.01681 |  0:01:31s\n",
      "epoch 110| loss: 0.01491 | val_logits_ll: 0.01685 |  0:01:40s\n",
      "\n",
      "Early stopping occured at epoch 112 with best_epoch = 92 and best_val_logits_ll = 0.01673\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 1 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38766 | val_logits_ll: 0.04614 |  0:00:00s\n",
      "epoch 10 | loss: 0.01966 | val_logits_ll: 0.01944 |  0:00:10s\n",
      "epoch 20 | loss: 0.0177  | val_logits_ll: 0.01807 |  0:00:19s\n",
      "epoch 30 | loss: 0.01739 | val_logits_ll: 0.01778 |  0:00:28s\n",
      "epoch 40 | loss: 0.01707 | val_logits_ll: 0.01724 |  0:00:37s\n",
      "epoch 50 | loss: 0.01656 | val_logits_ll: 0.01699 |  0:00:47s\n",
      "epoch 60 | loss: 0.01642 | val_logits_ll: 0.01673 |  0:00:56s\n",
      "epoch 70 | loss: 0.01609 | val_logits_ll: 0.01684 |  0:01:05s\n",
      "epoch 80 | loss: 0.01594 | val_logits_ll: 0.01665 |  0:01:14s\n",
      "epoch 90 | loss: 0.01554 | val_logits_ll: 0.01688 |  0:01:23s\n",
      "epoch 100| loss: 0.01531 | val_logits_ll: 0.01661 |  0:01:32s\n",
      "\n",
      "Early stopping occured at epoch 106 with best_epoch = 86 and best_val_logits_ll = 0.01643\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38798 | val_logits_ll: 0.04819 |  0:00:00s\n",
      "epoch 10 | loss: 0.01915 | val_logits_ll: 0.01918 |  0:00:09s\n",
      "epoch 20 | loss: 0.01741 | val_logits_ll: 0.02103 |  0:00:18s\n",
      "epoch 30 | loss: 0.01707 | val_logits_ll: 0.01752 |  0:00:27s\n",
      "epoch 40 | loss: 0.0167  | val_logits_ll: 0.01901 |  0:00:36s\n",
      "epoch 50 | loss: 0.01653 | val_logits_ll: 0.01722 |  0:00:45s\n",
      "epoch 60 | loss: 0.0161  | val_logits_ll: 0.01866 |  0:00:54s\n",
      "epoch 70 | loss: 0.01593 | val_logits_ll: 0.01694 |  0:01:03s\n",
      "epoch 80 | loss: 0.01605 | val_logits_ll: 0.01696 |  0:01:12s\n",
      "epoch 90 | loss: 0.01544 | val_logits_ll: 0.01688 |  0:01:21s\n",
      "epoch 100| loss: 0.01523 | val_logits_ll: 0.01706 |  0:01:30s\n",
      "\n",
      "Early stopping occured at epoch 102 with best_epoch = 82 and best_val_logits_ll = 0.01674\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38675 | val_logits_ll: 0.04472 |  0:00:00s\n",
      "epoch 10 | loss: 0.01885 | val_logits_ll: 0.01867 |  0:00:09s\n",
      "epoch 20 | loss: 0.0177  | val_logits_ll: 0.0197  |  0:00:18s\n",
      "epoch 30 | loss: 0.01722 | val_logits_ll: 0.01813 |  0:00:28s\n",
      "epoch 40 | loss: 0.01659 | val_logits_ll: 0.01736 |  0:00:37s\n",
      "epoch 50 | loss: 0.01633 | val_logits_ll: 0.017   |  0:00:46s\n",
      "epoch 60 | loss: 0.0163  | val_logits_ll: 0.01705 |  0:00:55s\n",
      "epoch 70 | loss: 0.01603 | val_logits_ll: 0.01681 |  0:01:03s\n",
      "epoch 80 | loss: 0.0158  | val_logits_ll: 0.01696 |  0:01:12s\n",
      "epoch 90 | loss: 0.01538 | val_logits_ll: 0.01678 |  0:01:21s\n",
      "\n",
      "Early stopping occured at epoch 92 with best_epoch = 72 and best_val_logits_ll = 0.01667\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38641 | val_logits_ll: 0.04893 |  0:00:00s\n",
      "epoch 10 | loss: 0.01909 | val_logits_ll: 0.01883 |  0:00:09s\n",
      "epoch 20 | loss: 0.01777 | val_logits_ll: 0.02054 |  0:00:18s\n",
      "epoch 30 | loss: 0.0172  | val_logits_ll: 0.01752 |  0:00:27s\n",
      "epoch 40 | loss: 0.01684 | val_logits_ll: 0.01827 |  0:00:36s\n",
      "epoch 50 | loss: 0.01643 | val_logits_ll: 0.01693 |  0:00:45s\n",
      "epoch 60 | loss: 0.01627 | val_logits_ll: 0.01701 |  0:00:54s\n",
      "epoch 70 | loss: 0.01579 | val_logits_ll: 0.01701 |  0:01:03s\n",
      "epoch 80 | loss: 0.01548 | val_logits_ll: 0.01697 |  0:01:12s\n",
      "epoch 90 | loss: 0.01544 | val_logits_ll: 0.01704 |  0:01:21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100| loss: 0.01483 | val_logits_ll: 0.01717 |  0:01:30s\n",
      "\n",
      "Early stopping occured at epoch 104 with best_epoch = 84 and best_val_logits_ll = 0.0168\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38771 | val_logits_ll: 0.04644 |  0:00:00s\n",
      "epoch 10 | loss: 0.01924 | val_logits_ll: 0.01904 |  0:00:09s\n",
      "epoch 20 | loss: 0.01759 | val_logits_ll: 0.02048 |  0:00:19s\n",
      "epoch 30 | loss: 0.01702 | val_logits_ll: 0.02055 |  0:00:28s\n",
      "epoch 40 | loss: 0.01678 | val_logits_ll: 0.01731 |  0:00:36s\n",
      "epoch 50 | loss: 0.01669 | val_logits_ll: 0.0172  |  0:00:45s\n",
      "epoch 60 | loss: 0.0164  | val_logits_ll: 0.01714 |  0:00:54s\n",
      "epoch 70 | loss: 0.01606 | val_logits_ll: 0.0169  |  0:01:03s\n",
      "epoch 80 | loss: 0.01582 | val_logits_ll: 0.01682 |  0:01:12s\n",
      "epoch 90 | loss: 0.01575 | val_logits_ll: 0.0168  |  0:01:21s\n",
      "epoch 100| loss: 0.01567 | val_logits_ll: 0.01706 |  0:01:30s\n",
      "epoch 110| loss: 0.01507 | val_logits_ll: 0.01678 |  0:01:39s\n",
      "epoch 120| loss: 0.01507 | val_logits_ll: 0.01672 |  0:01:48s\n",
      "\n",
      "Early stopping occured at epoch 122 with best_epoch = 102 and best_val_logits_ll = 0.01668\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 2 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38676 | val_logits_ll: 0.04907 |  0:00:00s\n",
      "epoch 10 | loss: 0.01964 | val_logits_ll: 0.01918 |  0:00:09s\n",
      "epoch 20 | loss: 0.01766 | val_logits_ll: 0.02097 |  0:00:18s\n",
      "epoch 30 | loss: 0.01725 | val_logits_ll: 0.01793 |  0:00:27s\n",
      "epoch 40 | loss: 0.017   | val_logits_ll: 0.01755 |  0:00:36s\n",
      "epoch 50 | loss: 0.01692 | val_logits_ll: 0.01845 |  0:00:45s\n",
      "epoch 60 | loss: 0.01643 | val_logits_ll: 0.01679 |  0:00:54s\n",
      "epoch 70 | loss: 0.01615 | val_logits_ll: 0.01661 |  0:01:03s\n",
      "epoch 80 | loss: 0.01594 | val_logits_ll: 0.0166  |  0:01:12s\n",
      "epoch 90 | loss: 0.01579 | val_logits_ll: 0.01661 |  0:01:21s\n",
      "epoch 100| loss: 0.01563 | val_logits_ll: 0.01656 |  0:01:30s\n",
      "epoch 110| loss: 0.01547 | val_logits_ll: 0.01651 |  0:01:39s\n",
      "epoch 120| loss: 0.01524 | val_logits_ll: 0.01659 |  0:01:47s\n",
      "epoch 130| loss: 0.0147  | val_logits_ll: 0.01672 |  0:01:56s\n",
      "\n",
      "Early stopping occured at epoch 132 with best_epoch = 112 and best_val_logits_ll = 0.01646\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38046 | val_logits_ll: 0.04202 |  0:00:00s\n",
      "epoch 10 | loss: 0.01916 | val_logits_ll: 0.01891 |  0:00:09s\n",
      "epoch 20 | loss: 0.01782 | val_logits_ll: 0.01793 |  0:00:19s\n",
      "epoch 30 | loss: 0.01719 | val_logits_ll: 0.01767 |  0:00:28s\n",
      "epoch 40 | loss: 0.01689 | val_logits_ll: 0.01723 |  0:00:37s\n",
      "epoch 50 | loss: 0.01668 | val_logits_ll: 0.01725 |  0:00:46s\n",
      "epoch 60 | loss: 0.01632 | val_logits_ll: 0.01681 |  0:00:55s\n",
      "epoch 70 | loss: 0.01629 | val_logits_ll: 0.01699 |  0:01:04s\n",
      "epoch 80 | loss: 0.01572 | val_logits_ll: 0.0169  |  0:01:13s\n",
      "epoch 90 | loss: 0.01565 | val_logits_ll: 0.01688 |  0:01:22s\n",
      "\n",
      "Early stopping occured at epoch 99 with best_epoch = 79 and best_val_logits_ll = 0.01669\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38396 | val_logits_ll: 0.04552 |  0:00:00s\n",
      "epoch 10 | loss: 0.01941 | val_logits_ll: 0.01912 |  0:00:09s\n",
      "epoch 20 | loss: 0.01777 | val_logits_ll: 0.0229  |  0:00:18s\n",
      "epoch 30 | loss: 0.01719 | val_logits_ll: 0.01878 |  0:00:27s\n",
      "epoch 40 | loss: 0.01677 | val_logits_ll: 0.0173  |  0:00:36s\n",
      "epoch 50 | loss: 0.01692 | val_logits_ll: 0.01706 |  0:00:45s\n",
      "epoch 60 | loss: 0.01633 | val_logits_ll: 0.01683 |  0:00:54s\n",
      "epoch 70 | loss: 0.01605 | val_logits_ll: 0.01673 |  0:01:03s\n",
      "epoch 80 | loss: 0.01578 | val_logits_ll: 0.01683 |  0:01:12s\n",
      "epoch 90 | loss: 0.01556 | val_logits_ll: 0.01673 |  0:01:21s\n",
      "epoch 100| loss: 0.01548 | val_logits_ll: 0.01686 |  0:01:30s\n",
      "epoch 110| loss: 0.01529 | val_logits_ll: 0.01701 |  0:01:39s\n",
      "epoch 120| loss: 0.01483 | val_logits_ll: 0.01684 |  0:01:48s\n",
      "\n",
      "Early stopping occured at epoch 126 with best_epoch = 106 and best_val_logits_ll = 0.01667\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38334 | val_logits_ll: 0.04623 |  0:00:00s\n",
      "epoch 10 | loss: 0.01928 | val_logits_ll: 0.01986 |  0:00:09s\n",
      "epoch 20 | loss: 0.01766 | val_logits_ll: 0.02259 |  0:00:18s\n",
      "epoch 30 | loss: 0.01729 | val_logits_ll: 0.0174  |  0:00:27s\n",
      "epoch 40 | loss: 0.01705 | val_logits_ll: 0.01724 |  0:00:36s\n",
      "epoch 50 | loss: 0.01672 | val_logits_ll: 0.01745 |  0:00:45s\n",
      "epoch 60 | loss: 0.01639 | val_logits_ll: 0.01709 |  0:00:54s\n",
      "epoch 70 | loss: 0.01622 | val_logits_ll: 0.01686 |  0:01:03s\n",
      "epoch 80 | loss: 0.01589 | val_logits_ll: 0.01687 |  0:01:12s\n",
      "epoch 90 | loss: 0.01606 | val_logits_ll: 0.01686 |  0:01:21s\n",
      "epoch 100| loss: 0.01561 | val_logits_ll: 0.01675 |  0:01:29s\n",
      "epoch 110| loss: 0.01528 | val_logits_ll: 0.0168  |  0:01:38s\n",
      "epoch 120| loss: 0.01499 | val_logits_ll: 0.01668 |  0:01:47s\n",
      "\n",
      "Early stopping occured at epoch 129 with best_epoch = 109 and best_val_logits_ll = 0.01667\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38495 | val_logits_ll: 0.04579 |  0:00:00s\n",
      "epoch 10 | loss: 0.01899 | val_logits_ll: 0.01913 |  0:00:10s\n",
      "epoch 20 | loss: 0.01769 | val_logits_ll: 0.02064 |  0:00:19s\n",
      "epoch 30 | loss: 0.01717 | val_logits_ll: 0.02068 |  0:00:28s\n",
      "epoch 40 | loss: 0.01687 | val_logits_ll: 0.01751 |  0:00:37s\n",
      "epoch 50 | loss: 0.01673 | val_logits_ll: 0.01716 |  0:00:46s\n",
      "epoch 60 | loss: 0.01647 | val_logits_ll: 0.017   |  0:00:55s\n",
      "epoch 70 | loss: 0.01616 | val_logits_ll: 0.01687 |  0:01:04s\n",
      "epoch 80 | loss: 0.01599 | val_logits_ll: 0.01693 |  0:01:13s\n",
      "epoch 90 | loss: 0.01563 | val_logits_ll: 0.01707 |  0:01:22s\n",
      "epoch 100| loss: 0.01552 | val_logits_ll: 0.01681 |  0:01:31s\n",
      "epoch 110| loss: 0.01513 | val_logits_ll: 0.01661 |  0:01:40s\n",
      "epoch 120| loss: 0.01491 | val_logits_ll: 0.0168  |  0:01:49s\n",
      "epoch 130| loss: 0.01481 | val_logits_ll: 0.01692 |  0:01:58s\n",
      "\n",
      "Early stopping occured at epoch 130 with best_epoch = 110 and best_val_logits_ll = 0.01661\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 3 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.35557 | val_logits_ll: 0.03625 |  0:00:00s\n",
      "epoch 10 | loss: 0.01946 | val_logits_ll: 0.01925 |  0:00:09s\n",
      "epoch 20 | loss: 0.01764 | val_logits_ll: 0.02009 |  0:00:18s\n",
      "epoch 30 | loss: 0.0172  | val_logits_ll: 0.01713 |  0:00:27s\n",
      "epoch 40 | loss: 0.01701 | val_logits_ll: 0.01704 |  0:00:36s\n",
      "epoch 50 | loss: 0.01651 | val_logits_ll: 0.0174  |  0:00:45s\n",
      "epoch 60 | loss: 0.01635 | val_logits_ll: 0.01684 |  0:00:54s\n",
      "epoch 70 | loss: 0.01604 | val_logits_ll: 0.01678 |  0:01:03s\n",
      "epoch 80 | loss: 0.0158  | val_logits_ll: 0.01664 |  0:01:12s\n",
      "epoch 90 | loss: 0.01555 | val_logits_ll: 0.0166  |  0:01:21s\n",
      "epoch 100| loss: 0.01529 | val_logits_ll: 0.01685 |  0:01:30s\n",
      "\n",
      "Early stopping occured at epoch 108 with best_epoch = 88 and best_val_logits_ll = 0.01651\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.35614 | val_logits_ll: 0.03895 |  0:00:00s\n",
      "epoch 10 | loss: 0.01934 | val_logits_ll: 0.01903 |  0:00:09s\n",
      "epoch 20 | loss: 0.01759 | val_logits_ll: 0.01978 |  0:00:18s\n",
      "epoch 30 | loss: 0.01734 | val_logits_ll: 0.01748 |  0:00:28s\n",
      "epoch 40 | loss: 0.01679 | val_logits_ll: 0.01769 |  0:00:37s\n",
      "epoch 50 | loss: 0.01637 | val_logits_ll: 0.01689 |  0:00:46s\n",
      "epoch 60 | loss: 0.01601 | val_logits_ll: 0.01702 |  0:00:55s\n",
      "epoch 70 | loss: 0.0158  | val_logits_ll: 0.01684 |  0:01:04s\n",
      "epoch 80 | loss: 0.01591 | val_logits_ll: 0.01706 |  0:01:13s\n",
      "epoch 90 | loss: 0.01539 | val_logits_ll: 0.01694 |  0:01:22s\n",
      "epoch 100| loss: 0.01491 | val_logits_ll: 0.01701 |  0:01:31s\n",
      "\n",
      "Early stopping occured at epoch 107 with best_epoch = 87 and best_val_logits_ll = 0.01673\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.35885 | val_logits_ll: 0.03873 |  0:00:00s\n",
      "epoch 10 | loss: 0.01913 | val_logits_ll: 0.02003 |  0:00:10s\n",
      "epoch 20 | loss: 0.01754 | val_logits_ll: 0.01971 |  0:00:18s\n",
      "epoch 30 | loss: 0.0171  | val_logits_ll: 0.0173  |  0:00:28s\n",
      "epoch 40 | loss: 0.01672 | val_logits_ll: 0.01718 |  0:00:37s\n",
      "epoch 50 | loss: 0.01647 | val_logits_ll: 0.01706 |  0:00:46s\n",
      "epoch 60 | loss: 0.01673 | val_logits_ll: 0.01691 |  0:00:55s\n",
      "epoch 70 | loss: 0.01621 | val_logits_ll: 0.01687 |  0:01:04s\n",
      "epoch 80 | loss: 0.01597 | val_logits_ll: 0.01672 |  0:01:13s\n",
      "epoch 90 | loss: 0.01576 | val_logits_ll: 0.01689 |  0:01:22s\n",
      "epoch 100| loss: 0.01537 | val_logits_ll: 0.01668 |  0:01:31s\n",
      "\n",
      "Early stopping occured at epoch 106 with best_epoch = 86 and best_val_logits_ll = 0.01664\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.35464 | val_logits_ll: 0.03489 |  0:00:01s\n",
      "epoch 10 | loss: 0.01923 | val_logits_ll: 0.02104 |  0:00:11s\n",
      "epoch 20 | loss: 0.01758 | val_logits_ll: 0.01958 |  0:00:21s\n",
      "epoch 30 | loss: 0.01736 | val_logits_ll: 0.01777 |  0:00:31s\n",
      "epoch 40 | loss: 0.01654 | val_logits_ll: 0.01779 |  0:00:41s\n",
      "epoch 50 | loss: 0.01628 | val_logits_ll: 0.01702 |  0:00:51s\n",
      "epoch 60 | loss: 0.01634 | val_logits_ll: 0.01686 |  0:01:02s\n",
      "epoch 70 | loss: 0.01607 | val_logits_ll: 0.01679 |  0:01:12s\n",
      "epoch 80 | loss: 0.01586 | val_logits_ll: 0.0168  |  0:01:22s\n",
      "epoch 90 | loss: 0.01548 | val_logits_ll: 0.01674 |  0:01:32s\n",
      "epoch 100| loss: 0.01525 | val_logits_ll: 0.01688 |  0:01:42s\n",
      "epoch 110| loss: 0.01477 | val_logits_ll: 0.01689 |  0:01:52s\n",
      "\n",
      "Early stopping occured at epoch 110 with best_epoch = 90 and best_val_logits_ll = 0.01674\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.35702 | val_logits_ll: 0.03907 |  0:00:00s\n",
      "epoch 10 | loss: 0.0191  | val_logits_ll: 0.01894 |  0:00:09s\n",
      "epoch 20 | loss: 0.01776 | val_logits_ll: 0.02176 |  0:00:18s\n",
      "epoch 30 | loss: 0.01707 | val_logits_ll: 0.01791 |  0:00:27s\n",
      "epoch 40 | loss: 0.01671 | val_logits_ll: 0.01728 |  0:00:36s\n",
      "epoch 50 | loss: 0.01657 | val_logits_ll: 0.01719 |  0:00:45s\n",
      "epoch 60 | loss: 0.01613 | val_logits_ll: 0.01702 |  0:00:54s\n",
      "epoch 70 | loss: 0.01622 | val_logits_ll: 0.01683 |  0:01:03s\n",
      "epoch 80 | loss: 0.01584 | val_logits_ll: 0.0168  |  0:01:12s\n",
      "epoch 90 | loss: 0.01543 | val_logits_ll: 0.0168  |  0:01:21s\n",
      "epoch 100| loss: 0.01528 | val_logits_ll: 0.01675 |  0:01:29s\n",
      "epoch 110| loss: 0.01488 | val_logits_ll: 0.01681 |  0:01:38s\n",
      "epoch 120| loss: 0.01461 | val_logits_ll: 0.01707 |  0:01:47s\n",
      "\n",
      "Early stopping occured at epoch 128 with best_epoch = 108 and best_val_logits_ll = 0.01666\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 4 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38082 | val_logits_ll: 0.04989 |  0:00:00s\n",
      "epoch 10 | loss: 0.0195  | val_logits_ll: 0.01892 |  0:00:09s\n",
      "epoch 20 | loss: 0.01775 | val_logits_ll: 0.02131 |  0:00:18s\n",
      "epoch 30 | loss: 0.01727 | val_logits_ll: 0.01747 |  0:00:27s\n",
      "epoch 40 | loss: 0.01695 | val_logits_ll: 0.01703 |  0:00:36s\n",
      "epoch 50 | loss: 0.0168  | val_logits_ll: 0.01736 |  0:00:45s\n",
      "epoch 60 | loss: 0.0164  | val_logits_ll: 0.0169  |  0:00:54s\n",
      "epoch 70 | loss: 0.01634 | val_logits_ll: 0.01659 |  0:01:03s\n",
      "epoch 80 | loss: 0.01592 | val_logits_ll: 0.01645 |  0:01:11s\n",
      "epoch 90 | loss: 0.0157  | val_logits_ll: 0.01661 |  0:01:20s\n",
      "\n",
      "Early stopping occured at epoch 93 with best_epoch = 73 and best_val_logits_ll = 0.0164\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38037 | val_logits_ll: 0.04279 |  0:00:00s\n",
      "epoch 10 | loss: 0.01927 | val_logits_ll: 0.02072 |  0:00:09s\n",
      "epoch 20 | loss: 0.0175  | val_logits_ll: 0.02129 |  0:00:18s\n",
      "epoch 30 | loss: 0.01716 | val_logits_ll: 0.01744 |  0:00:27s\n",
      "epoch 40 | loss: 0.01676 | val_logits_ll: 0.01944 |  0:00:36s\n",
      "epoch 50 | loss: 0.01661 | val_logits_ll: 0.01694 |  0:00:45s\n",
      "epoch 60 | loss: 0.01627 | val_logits_ll: 0.01685 |  0:00:54s\n",
      "epoch 70 | loss: 0.01598 | val_logits_ll: 0.0168  |  0:01:03s\n",
      "epoch 80 | loss: 0.01593 | val_logits_ll: 0.01684 |  0:01:12s\n",
      "epoch 90 | loss: 0.01567 | val_logits_ll: 0.01674 |  0:01:21s\n",
      "epoch 100| loss: 0.01542 | val_logits_ll: 0.01687 |  0:01:30s\n",
      "epoch 110| loss: 0.01528 | val_logits_ll: 0.017   |  0:01:39s\n",
      "\n",
      "Early stopping occured at epoch 118 with best_epoch = 98 and best_val_logits_ll = 0.01667\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38133 | val_logits_ll: 0.04336 |  0:00:00s\n",
      "epoch 10 | loss: 0.01906 | val_logits_ll: 0.01898 |  0:00:09s\n",
      "epoch 20 | loss: 0.01759 | val_logits_ll: 0.02107 |  0:00:18s\n",
      "epoch 30 | loss: 0.01706 | val_logits_ll: 0.0174  |  0:00:27s\n",
      "epoch 40 | loss: 0.01685 | val_logits_ll: 0.01728 |  0:00:37s\n",
      "epoch 50 | loss: 0.0164  | val_logits_ll: 0.0175  |  0:00:46s\n",
      "epoch 60 | loss: 0.01621 | val_logits_ll: 0.0169  |  0:00:55s\n",
      "epoch 70 | loss: 0.01602 | val_logits_ll: 0.0172  |  0:01:04s\n",
      "epoch 80 | loss: 0.0157  | val_logits_ll: 0.01685 |  0:01:12s\n",
      "epoch 90 | loss: 0.01568 | val_logits_ll: 0.0168  |  0:01:21s\n",
      "epoch 100| loss: 0.01521 | val_logits_ll: 0.01692 |  0:01:30s\n",
      "\n",
      "Early stopping occured at epoch 104 with best_epoch = 84 and best_val_logits_ll = 0.01669\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.38006 | val_logits_ll: 0.04168 |  0:00:00s\n",
      "epoch 10 | loss: 0.01906 | val_logits_ll: 0.01884 |  0:00:10s\n",
      "epoch 20 | loss: 0.01762 | val_logits_ll: 0.02098 |  0:00:19s\n",
      "epoch 30 | loss: 0.01706 | val_logits_ll: 0.01866 |  0:00:28s\n",
      "epoch 40 | loss: 0.01677 | val_logits_ll: 0.01717 |  0:00:37s\n",
      "epoch 50 | loss: 0.01663 | val_logits_ll: 0.01707 |  0:00:46s\n",
      "epoch 60 | loss: 0.01634 | val_logits_ll: 0.017   |  0:00:55s\n",
      "epoch 70 | loss: 0.01631 | val_logits_ll: 0.01705 |  0:01:04s\n",
      "epoch 80 | loss: 0.01633 | val_logits_ll: 0.01695 |  0:01:13s\n",
      "epoch 90 | loss: 0.01593 | val_logits_ll: 0.01688 |  0:01:22s\n",
      "epoch 100| loss: 0.01603 | val_logits_ll: 0.01696 |  0:01:31s\n",
      "\n",
      "Early stopping occured at epoch 102 with best_epoch = 82 and best_val_logits_ll = 0.01673\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.37829 | val_logits_ll: 0.04205 |  0:00:00s\n",
      "epoch 10 | loss: 0.01928 | val_logits_ll: 0.02078 |  0:00:09s\n",
      "epoch 20 | loss: 0.01771 | val_logits_ll: 0.02112 |  0:00:18s\n",
      "epoch 30 | loss: 0.01717 | val_logits_ll: 0.01959 |  0:00:27s\n",
      "epoch 40 | loss: 0.01694 | val_logits_ll: 0.01768 |  0:00:36s\n",
      "epoch 50 | loss: 0.01656 | val_logits_ll: 0.01705 |  0:00:45s\n",
      "epoch 60 | loss: 0.01631 | val_logits_ll: 0.017   |  0:00:54s\n",
      "epoch 70 | loss: 0.01596 | val_logits_ll: 0.01714 |  0:01:03s\n",
      "epoch 80 | loss: 0.01572 | val_logits_ll: 0.01716 |  0:01:12s\n",
      "epoch 90 | loss: 0.01567 | val_logits_ll: 0.01694 |  0:01:21s\n",
      "\n",
      "Early stopping occured at epoch 99 with best_epoch = 79 and best_val_logits_ll = 0.01674\n",
      "Best weights from best epoch are automatically used!\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 5 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36516 | val_logits_ll: 0.0383  |  0:00:00s\n",
      "epoch 10 | loss: 0.01908 | val_logits_ll: 0.01893 |  0:00:09s\n",
      "epoch 20 | loss: 0.01778 | val_logits_ll: 0.02189 |  0:00:18s\n",
      "epoch 30 | loss: 0.01733 | val_logits_ll: 0.01837 |  0:00:27s\n",
      "epoch 40 | loss: 0.01687 | val_logits_ll: 0.0181  |  0:00:36s\n",
      "epoch 50 | loss: 0.01665 | val_logits_ll: 0.01723 |  0:00:45s\n",
      "epoch 60 | loss: 0.01641 | val_logits_ll: 0.01665 |  0:00:54s\n",
      "epoch 70 | loss: 0.01622 | val_logits_ll: 0.01667 |  0:01:03s\n",
      "epoch 80 | loss: 0.01602 | val_logits_ll: 0.01653 |  0:01:12s\n",
      "epoch 90 | loss: 0.01571 | val_logits_ll: 0.01653 |  0:01:21s\n",
      "epoch 100| loss: 0.01534 | val_logits_ll: 0.01655 |  0:01:30s\n",
      "epoch 110| loss: 0.01498 | val_logits_ll: 0.01671 |  0:01:39s\n",
      "epoch 120| loss: 0.01464 | val_logits_ll: 0.01677 |  0:01:48s\n",
      "\n",
      "Early stopping occured at epoch 121 with best_epoch = 101 and best_val_logits_ll = 0.01646\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36492 | val_logits_ll: 0.03749 |  0:00:00s\n",
      "epoch 10 | loss: 0.01903 | val_logits_ll: 0.02098 |  0:00:09s\n",
      "epoch 20 | loss: 0.01757 | val_logits_ll: 0.02055 |  0:00:18s\n",
      "epoch 30 | loss: 0.01711 | val_logits_ll: 0.01991 |  0:00:27s\n",
      "epoch 40 | loss: 0.01664 | val_logits_ll: 0.01714 |  0:00:37s\n",
      "epoch 50 | loss: 0.01654 | val_logits_ll: 0.01717 |  0:00:46s\n",
      "epoch 60 | loss: 0.01621 | val_logits_ll: 0.01732 |  0:00:55s\n",
      "epoch 70 | loss: 0.0159  | val_logits_ll: 0.01683 |  0:01:04s\n",
      "epoch 80 | loss: 0.01574 | val_logits_ll: 0.0168  |  0:01:13s\n",
      "epoch 90 | loss: 0.01543 | val_logits_ll: 0.01692 |  0:01:22s\n",
      "\n",
      "Early stopping occured at epoch 93 with best_epoch = 73 and best_val_logits_ll = 0.01676\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 2 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36461 | val_logits_ll: 0.03832 |  0:00:00s\n",
      "epoch 10 | loss: 0.01907 | val_logits_ll: 0.02199 |  0:00:09s\n",
      "epoch 20 | loss: 0.01771 | val_logits_ll: 0.02122 |  0:00:19s\n",
      "epoch 30 | loss: 0.01719 | val_logits_ll: 0.01845 |  0:00:28s\n",
      "epoch 40 | loss: 0.01682 | val_logits_ll: 0.0174  |  0:00:37s\n",
      "epoch 50 | loss: 0.01667 | val_logits_ll: 0.01721 |  0:00:45s\n",
      "epoch 60 | loss: 0.01634 | val_logits_ll: 0.017   |  0:00:54s\n",
      "epoch 70 | loss: 0.01607 | val_logits_ll: 0.01702 |  0:01:03s\n",
      "epoch 80 | loss: 0.01598 | val_logits_ll: 0.01688 |  0:01:12s\n",
      "epoch 90 | loss: 0.0157  | val_logits_ll: 0.01684 |  0:01:21s\n",
      "\n",
      "Early stopping occured at epoch 94 with best_epoch = 74 and best_val_logits_ll = 0.01669\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 3 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36436 | val_logits_ll: 0.03849 |  0:00:00s\n",
      "epoch 10 | loss: 0.01942 | val_logits_ll: 0.01914 |  0:00:09s\n",
      "epoch 20 | loss: 0.0178  | val_logits_ll: 0.02015 |  0:00:18s\n",
      "epoch 30 | loss: 0.01711 | val_logits_ll: 0.02035 |  0:00:27s\n",
      "epoch 40 | loss: 0.01684 | val_logits_ll: 0.01901 |  0:00:36s\n",
      "epoch 50 | loss: 0.01658 | val_logits_ll: 0.01709 |  0:00:45s\n",
      "epoch 60 | loss: 0.01638 | val_logits_ll: 0.01709 |  0:00:54s\n",
      "epoch 70 | loss: 0.01613 | val_logits_ll: 0.01686 |  0:01:03s\n",
      "epoch 80 | loss: 0.01595 | val_logits_ll: 0.01682 |  0:01:12s\n",
      "epoch 90 | loss: 0.01572 | val_logits_ll: 0.01701 |  0:01:21s\n",
      "epoch 100| loss: 0.01562 | val_logits_ll: 0.0169  |  0:01:29s\n",
      "epoch 110| loss: 0.01512 | val_logits_ll: 0.01681 |  0:01:38s\n",
      "epoch 120| loss: 0.01466 | val_logits_ll: 0.01684 |  0:01:47s\n",
      "\n",
      "Early stopping occured at epoch 124 with best_epoch = 104 and best_val_logits_ll = 0.01667\n",
      "Best weights from best epoch are automatically used!\n",
      "==================== Fold 4 ====================\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.36853 | val_logits_ll: 0.04236 |  0:00:00s\n",
      "epoch 10 | loss: 0.01938 | val_logits_ll: 0.01926 |  0:00:10s\n",
      "epoch 20 | loss: 0.01771 | val_logits_ll: 0.02047 |  0:00:19s\n",
      "epoch 30 | loss: 0.01698 | val_logits_ll: 0.02039 |  0:00:28s\n",
      "epoch 40 | loss: 0.0166  | val_logits_ll: 0.01722 |  0:00:37s\n",
      "epoch 50 | loss: 0.01634 | val_logits_ll: 0.01711 |  0:00:45s\n",
      "epoch 60 | loss: 0.01623 | val_logits_ll: 0.01688 |  0:00:54s\n",
      "epoch 70 | loss: 0.01581 | val_logits_ll: 0.01688 |  0:01:03s\n",
      "\n",
      "Early stopping occured at epoch 75 with best_epoch = 55 and best_val_logits_ll = 0.0168\n",
      "Best weights from best epoch are automatically used!\n",
      "CV log_loss:  0.01478125867998373\n",
      "sub.shape(3982, 207)\n",
      "CPU times: user 44min 24s, sys: 4min 51s, total: 49min 16s\n",
      "Wall time: 50min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score= Exec(param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.01478125867998373\n"
     ]
    }
   ],
   "source": [
    "print(\"score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(confFitting, param, test, target, fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    \n",
    "    model = load(f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\")\n",
    "    \n",
    "    predictions = np.zeros((len(test), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = 1 / (1 + np.exp(-model.predict(x_test)))\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed):\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        pred_ = run_predict(confFitting, param, test, target, fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitPredict(confFitting, predictions, test, prefix):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}{prefix}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = True\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        predictions_ = run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    # 課題提出\n",
    "    prefix = \"TabnetRegressor\"\n",
    "    SubmitPredict(confFitting, predictions, test, prefix)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 0 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "==================== Fold 1 ====================\n",
      "==================== Fold 2 ====================\n",
      "==================== Fold 3 ====================\n",
      "==================== Fold 4 ====================\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 1 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "==================== Fold 1 ====================\n",
      "==================== Fold 2 ====================\n",
      "==================== Fold 3 ====================\n",
      "==================== Fold 4 ====================\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 2 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "==================== Fold 1 ====================\n",
      "==================== Fold 2 ====================\n",
      "==================== Fold 3 ====================\n",
      "==================== Fold 4 ====================\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 3 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "==================== Fold 1 ====================\n",
      "==================== Fold 2 ====================\n",
      "==================== Fold 3 ====================\n",
      "==================== Fold 4 ====================\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 4 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "==================== Fold 1 ====================\n",
      "==================== Fold 2 ====================\n",
      "==================== Fold 3 ====================\n",
      "==================== Fold 4 ====================\n",
      "~~~~~~~~~~~~~~~~~~~~ SEED 5 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "==================== Fold 1 ====================\n",
      "==================== Fold 2 ====================\n",
      "==================== Fold 3 ====================\n",
      "==================== Fold 4 ====================\n",
      "sub.shape(3982, 207)\n",
      "CPU times: user 2min 28s, sys: 1.88 s, total: 2min 30s\n",
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Predict(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperopt\n",
    "from hyperopt import fmin, tpe, hp, rand, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOptExec(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    #Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trials' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trials' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "hopt = fmin(fn = HOptExec, \n",
    "            space = PARAMSPACE, \n",
    "            algo = tpe.suggest, \n",
    "            max_evals = 15, \n",
    "            #timeout = 8.9 * 60 * 60, \n",
    "            trials = trials, \n",
    "           )\n",
    "\n",
    "print(hopt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
